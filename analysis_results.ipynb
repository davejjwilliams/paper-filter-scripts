{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4934af8f",
   "metadata": {},
   "source": [
    "# Final Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696fadbe",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab58f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "065c21a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Shape: (173, 27)\n",
      "Papers About Contamination Shape: (3, 45)\n",
      "All Papers Shape: (692, 11)\n"
     ]
    }
   ],
   "source": [
    "df_relevant = pd.read_excel('results/final/test.xlsx', sheet_name='relevant_papers')\n",
    "df_contamination = pd.read_excel('results/final/test.xlsx', sheet_name='papers_about_contamination')\n",
    "df_all_papers = pd.read_csv('results/ICSE_all_papers.csv')\n",
    "\n",
    "print(\"Relevant Shape:\", df_relevant.shape)\n",
    "print(\"Papers About Contamination Shape:\", df_contamination.shape)\n",
    "print(\"All Papers Shape:\", df_all_papers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66cce569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>relevant</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>abstract</th>\n",
       "      <th>artifact_available</th>\n",
       "      <th>artifact_reusable</th>\n",
       "      <th>artifact_functional</th>\n",
       "      <th>ai</th>\n",
       "      <th>ignore_task</th>\n",
       "      <th>task</th>\n",
       "      <th>non_llm_approaches</th>\n",
       "      <th>ignore_budget_fair</th>\n",
       "      <th>ignore_open_commercial</th>\n",
       "      <th>models_open_closed</th>\n",
       "      <th>ignore_num_models</th>\n",
       "      <th>num_models</th>\n",
       "      <th>ignore_model_names</th>\n",
       "      <th>model_families</th>\n",
       "      <th>model_scale</th>\n",
       "      <th>model_size_free_text</th>\n",
       "      <th>model_sizes_reported</th>\n",
       "      <th>ignore_model_versions</th>\n",
       "      <th>ignore_model_config</th>\n",
       "      <th>model_config</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>ignore_programming_language</th>\n",
       "      <th>programming_language</th>\n",
       "      <th>ignore_num_datasets</th>\n",
       "      <th>ignore_dataset_names</th>\n",
       "      <th>ignore_size_dataset</th>\n",
       "      <th>ignore_size_dataset_free_text</th>\n",
       "      <th>ignore_training_same_as_eval</th>\n",
       "      <th>ignore_data_version</th>\n",
       "      <th>ignore_cost</th>\n",
       "      <th>cost</th>\n",
       "      <th>cost_free_text</th>\n",
       "      <th>ignore_artefact_manual</th>\n",
       "      <th>artefact_manual</th>\n",
       "      <th>ignore_artefact_license</th>\n",
       "      <th>contamination</th>\n",
       "      <th>contamination_free_text</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DW</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2025</td>\n",
       "      <td>Decoding Secret Memorization in Code LLMs Thro...</td>\n",
       "      <td>Nie, Yuqing, Wang, Chong, Wang, Kailong, Xu, G...</td>\n",
       "      <td>https://doi.org/10.1109/ICSE55347.2025.00229</td>\n",
       "      <td>Code Large Language Models (LLMs) have demonst...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>secret memorization analysis</td>\n",
       "      <td>code memorisation detection</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OPEN SOURCE</td>\n",
       "      <td>open</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>StableCode-3B,3B;CodeGen2.5-7B-multi,7B;DeepSe...</td>\n",
       "      <td>TODAVE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In the online decoding, the beam search size B...</td>\n",
       "      <td>inference</td>\n",
       "      <td>code</td>\n",
       "      <td>HTML, Java, JavaScript, PHP, Python</td>\n",
       "      <td>HTML; Java; JavaScript; Python</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GPU Usage</td>\n",
       "      <td>gpu</td>\n",
       "      <td>All the experiments are conducted on a server ...</td>\n",
       "      <td>https://github.com/jiangsha97/DESEC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Training Data Decontamination. Data cleaning s...</td>\n",
       "      <td>This paper is about contamination/memorisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DW</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2024</td>\n",
       "      <td>Traces of Memorisation in Large Language Model...</td>\n",
       "      <td>Al-Kaswan, Ali, Izadi, Maliheh, van Deursen, Arie</td>\n",
       "      <td>https://doi.org/10.1145/3597503.3639133</td>\n",
       "      <td>Large language models have gained significant ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>(Memorisation of) Code Generation</td>\n",
       "      <td>code memorisation detection</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>OPEN SOURCE</td>\n",
       "      <td>open</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SKIP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TODAVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper is investigating contamiation/leaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MK</td>\n",
       "      <td>SPECIAL</td>\n",
       "      <td>2024</td>\n",
       "      <td>Unveiling Memorization in Code Models</td>\n",
       "      <td>Yang, Zhou, Zhao, Zhipeng, Wang, Chenyu, Shi, ...</td>\n",
       "      <td>https://doi.org/10.1145/3597503.3639074</td>\n",
       "      <td>The availability of large-scale datasets, adva...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>code generation (evaluation of the memorizatio...</td>\n",
       "      <td>code generation</td>\n",
       "      <td>False</td>\n",
       "      <td>-</td>\n",
       "      <td>OPEN SOURCE (see table 1 evaluation with CodeP...</td>\n",
       "      <td>open</td>\n",
       "      <td>4 (Table 1: CodeParrot, CodeParrot-small, Poly...</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CodeParrot; PolyCoder; GPT-NEO; InCoder; StarC...</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>CodeParrot is a GPT-2 model with 1.5 billion p...</td>\n",
       "      <td>TODAVE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>inference</td>\n",
       "      <td>code, documentation (text), configuration (tex...</td>\n",
       "      <td>Python</td>\n",
       "      <td>Python</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OpenAI’s HumanEval benchmark [21], https://hug...</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>after data cleaning, the processed\\ndataset is...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Environment with GPU, running time, temperature</td>\n",
       "      <td>time; gpu</td>\n",
       "      <td>... we run them an NVIDIA GeForce\\nA5000 GPU w...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRUE (MIT License)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>To mitigate this threat, we choose a state-of-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reviewer relevant  year                                              title  \\\n",
       "0       DW  SPECIAL  2025  Decoding Secret Memorization in Code LLMs Thro...   \n",
       "1       DW  SPECIAL  2024  Traces of Memorisation in Large Language Model...   \n",
       "2       MK  SPECIAL  2024              Unveiling Memorization in Code Models   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Nie, Yuqing, Wang, Chong, Wang, Kailong, Xu, G...   \n",
       "1  Al-Kaswan, Ali, Izadi, Maliheh, van Deursen, Arie   \n",
       "2  Yang, Zhou, Zhao, Zhipeng, Wang, Chenyu, Shi, ...   \n",
       "\n",
       "                                            url  \\\n",
       "0  https://doi.org/10.1109/ICSE55347.2025.00229   \n",
       "1       https://doi.org/10.1145/3597503.3639133   \n",
       "2       https://doi.org/10.1145/3597503.3639074   \n",
       "\n",
       "                                            abstract  artifact_available  \\\n",
       "0  Code Large Language Models (LLMs) have demonst...               False   \n",
       "1  Large language models have gained significant ...               False   \n",
       "2  The availability of large-scale datasets, adva...               False   \n",
       "\n",
       "   artifact_reusable  artifact_functional    ai  \\\n",
       "0              False                False  True   \n",
       "1              False                False  True   \n",
       "2              False                False  True   \n",
       "\n",
       "                                         ignore_task  \\\n",
       "0                       secret memorization analysis   \n",
       "1                  (Memorisation of) Code Generation   \n",
       "2  code generation (evaluation of the memorizatio...   \n",
       "\n",
       "                          task  non_llm_approaches ignore_budget_fair  \\\n",
       "0  code memorisation detection               False                NaN   \n",
       "1  code memorisation detection               False                  -   \n",
       "2              code generation               False                  -   \n",
       "\n",
       "                              ignore_open_commercial models_open_closed  \\\n",
       "0                                        OPEN SOURCE               open   \n",
       "1                                        OPEN SOURCE               open   \n",
       "2  OPEN SOURCE (see table 1 evaluation with CodeP...               open   \n",
       "\n",
       "                                   ignore_num_models num_models  \\\n",
       "0                                                  5          5   \n",
       "1                                                NaN       SKIP   \n",
       "2  4 (Table 1: CodeParrot, CodeParrot-small, Poly...          6   \n",
       "\n",
       "   ignore_model_names                                     model_families  \\\n",
       "0                 NaN                                                NaN   \n",
       "1                 NaN                                                NaN   \n",
       "2                 NaN  CodeParrot; PolyCoder; GPT-NEO; InCoder; StarC...   \n",
       "\n",
       "  model_scale                               model_size_free_text  \\\n",
       "0      MEDIUM  StableCode-3B,3B;CodeGen2.5-7B-multi,7B;DeepSe...   \n",
       "1         NaN                                                NaN   \n",
       "2       LARGE  CodeParrot is a GPT-2 model with 1.5 billion p...   \n",
       "\n",
       "  model_sizes_reported  ignore_model_versions  \\\n",
       "0               TODAVE                    1.0   \n",
       "1               TODAVE                    NaN   \n",
       "2               TODAVE                    1.0   \n",
       "\n",
       "                                 ignore_model_config model_config  \\\n",
       "0  In the online decoding, the beam search size B...    inference   \n",
       "1                                                NaN            -   \n",
       "2                                               True    inference   \n",
       "\n",
       "                                        dataset_type  \\\n",
       "0                                               code   \n",
       "1                                                NaN   \n",
       "2  code, documentation (text), configuration (tex...   \n",
       "\n",
       "           ignore_programming_language            programming_language  \\\n",
       "0  HTML, Java, JavaScript, PHP, Python  HTML; Java; JavaScript; Python   \n",
       "1                                  NaN                             NaN   \n",
       "2                               Python                          Python   \n",
       "\n",
       "   ignore_num_datasets                               ignore_dataset_names  \\\n",
       "0                  NaN                                                NaN   \n",
       "1                  NaN                                                NaN   \n",
       "2                  2.0  OpenAI’s HumanEval benchmark [21], https://hug...   \n",
       "\n",
       "  ignore_size_dataset                      ignore_size_dataset_free_text  \\\n",
       "0                 NaN                                                NaN   \n",
       "1                 NaN                                                NaN   \n",
       "2               LARGE  after data cleaning, the processed\\ndataset is...   \n",
       "\n",
       "   ignore_training_same_as_eval  ignore_data_version  \\\n",
       "0                           NaN                  NaN   \n",
       "1                           NaN                  NaN   \n",
       "2                           1.0                  0.0   \n",
       "\n",
       "                                       ignore_cost       cost  \\\n",
       "0                                        GPU Usage        gpu   \n",
       "1                                              NaN        NaN   \n",
       "2  Environment with GPU, running time, temperature  time; gpu   \n",
       "\n",
       "                                      cost_free_text  \\\n",
       "0  All the experiments are conducted on a server ...   \n",
       "1                                                NaN   \n",
       "2  ... we run them an NVIDIA GeForce\\nA5000 GPU w...   \n",
       "\n",
       "                ignore_artefact_manual  artefact_manual  \\\n",
       "0  https://github.com/jiangsha97/DESEC              1.0   \n",
       "1                                  NaN              NaN   \n",
       "2                                 True              1.0   \n",
       "\n",
       "  ignore_artefact_license  contamination  \\\n",
       "0                   False            1.0   \n",
       "1                     NaN            NaN   \n",
       "2      TRUE (MIT License)            1.0   \n",
       "\n",
       "                             contamination_free_text  \\\n",
       "0  Training Data Decontamination. Data cleaning s...   \n",
       "1                                                NaN   \n",
       "2  To mitigate this threat, we choose a state-of-...   \n",
       "\n",
       "                                         Unnamed: 44  \n",
       "0     This paper is about contamination/memorisation  \n",
       "1  This paper is investigating contamiation/leaka...  \n",
       "2                                                NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contamination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676387c9",
   "metadata": {},
   "source": [
    "### Creating Combined and Non-Relevant Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a29c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Paper List\n",
    "relevant_papers = df_relevant['title'].tolist()\n",
    "\n",
    "# Remove relevant papers from all papers to create final non-relevant set\n",
    "df_non_relevant = df_all_papers[~df_all_papers['title'].isin(relevant_papers)].copy()\n",
    "\n",
    "# Make sure all non-relevant papers are marked as such\n",
    "df_non_relevant['relevant'] = False\n",
    "\n",
    "# Re-order columns to match relevant dataframe\n",
    "common_columns = ['reviewer', 'relevant', 'year', 'title', 'authors', 'url', 'abstract', 'artifact_available', 'artifact_reusable', 'artifact_functional', 'ai']\n",
    "df_non_relevant = df_non_relevant[common_columns]\n",
    "\n",
    "# Add extra columns: 'task', 'non_llm_approaches', 'models_open_closed', 'num_models', 'model_families', 'model_scale', 'model_size_free_text', 'model_sizes_reported', 'model_config', 'dataset_type', 'programming_language', 'cost', 'cost_free_text', 'artefact_manual', 'contamination', 'contamination_free_text'\n",
    "extra_columns = ['task', 'non_llm_approaches', 'models_open_closed', 'num_models', 'model_families', 'model_scale', 'model_size_free_text', 'model_sizes_reported', 'model_config', 'dataset_type', 'programming_language', 'cost', 'cost_free_text', 'artefact_manual', 'contamination', 'contamination_free_text']\n",
    "for col in extra_columns:\n",
    "    df_non_relevant[col] = None\n",
    "\n",
    "# Contamination Paper List\n",
    "contamination_papers = df_contamination['title'].tolist()\n",
    "\n",
    "# Clean up contamination dataframe\n",
    "df_contamination = df_contamination[common_columns + extra_columns]\n",
    "\n",
    "# Remove contamination papers from non-relevant set to avoid duplication\n",
    "df_non_relevant = df_non_relevant[~df_non_relevant['title'].isin(contamination_papers)].copy()\n",
    "\n",
    "# Combine relevant, non-relevant and contamination dataframes\n",
    "df_combined = pd.concat([df_relevant, df_non_relevant], ignore_index=True)\n",
    "df_combined = pd.concat([df_combined, df_contamination], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4613e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Shape: (692, 27)\n",
      "Num Unique Papers: 692\n",
      "Num Relevant Papers in Combined DF: 173\n",
      "Num Unique Papers in Relevant DF: 173\n",
      "Num Contamination Papers in Combined DF: 3\n",
      "Num Unique Papers in Contamination DF: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined Shape:\", df_combined.shape)\n",
    "print(\"Num Unique Papers:\", df_combined['title'].nunique())\n",
    "print(\"Num Relevant Papers in Combined DF:\", df_combined[df_combined['relevant'] == True].shape[0])\n",
    "print(\"Num Unique Papers in Relevant DF:\", df_relevant['title'].nunique()) # Should match number above\n",
    "print(\"Num Contamination Papers in Combined DF:\", df_combined[df_combined['relevant'] == \"SPECIAL\"].shape[0])\n",
    "print(\"Num Unique Papers in Contamination DF:\", df_contamination['title'].nunique()) # Should match number above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100580d7",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "We now have access to four dataframes for analysis:\n",
    "\n",
    "- `df_combined`: contains all papers and final columns from our spreadsheet (non-relevant papers just have None values in the fields we completed for the relevant papers)\n",
    "- `df_relevant`: contains all relevant papers as rows and the final columns we intend to use for analysis\n",
    "- `df_contamination`: contains the three papers explicitly about investigating memorisation/contamination\n",
    "- `df_non_relevant`: contains all non-relevant papers. Our finals columns are present but all filled with None values as we didn't perform data extraction for these papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f64a7b",
   "metadata": {},
   "source": [
    "## Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719ef68",
   "metadata": {},
   "source": [
    "### Number of Papers at Each Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1275e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Papers in Combined DF: 692\n",
      "\n",
      "Total Papers from AI Keywords:\n",
      "ai\n",
      "False    395\n",
      "True     297\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total Papers from Relevant Keywords:\n",
      "relevant\n",
      "False      516\n",
      "True       173\n",
      "SPECIAL      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Total numbers\n",
    "print(\"Total Papers in Combined DF:\", df_combined.shape[0])\n",
    "print(\"\\nTotal Papers from AI Keywords:\")\n",
    "print(df_combined['ai'].value_counts())\n",
    "\n",
    "print(\"\\nTotal Papers from Relevant Keywords:\")\n",
    "print(df_combined['relevant'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77ef7884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers Per Year:\n",
      "year\n",
      "2023    210\n",
      "2024    236\n",
      "2025    246\n",
      "Name: title, dtype: int64\n",
      "\n",
      "AI Papers Per Year:\n",
      "year\n",
      "2023     55\n",
      "2024     96\n",
      "2025    146\n",
      "Name: title, dtype: int64\n",
      "\n",
      "Relevant Papers Per Year:\n",
      "year\n",
      "2023    30\n",
      "2024    53\n",
      "2025    90\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Per Year\n",
    "print(\"Papers Per Year:\")\n",
    "print(df_combined.groupby('year')['title'].nunique())\n",
    "\n",
    "print(\"\\nAI Papers Per Year:\")\n",
    "print(df_combined[df_combined['ai'] == True].groupby('year')['title'].nunique())\n",
    "\n",
    "print(\"\\nRelevant Papers Per Year:\")\n",
    "print(df_combined[df_combined['relevant'] == True].groupby('year')['title'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029cd15",
   "metadata": {},
   "source": [
    "### Numbers of Relevant Papers (Papers with LLM-based Empirical Studies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bfef7625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Relevant vs Non-Relevant Counts:\n",
      "relevant\n",
      "False      516\n",
      "True       173\n",
      "SPECIAL      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Relevant Papers by Year:\n",
      "year\n",
      "2025    90\n",
      "2024    53\n",
      "2023    30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall Relevant vs Non-Relevant Counts:\")\n",
    "print(df_combined[\"relevant\"].value_counts())\n",
    "\n",
    "print(\"\\n\\nRelevant Papers by Year:\")\n",
    "print(df_relevant[\"year\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe95f7",
   "metadata": {},
   "source": [
    "### Geo-location of SE Research Institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3577c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6e76ac",
   "metadata": {},
   "source": [
    "# RQ1 - What Tasks are being tackled in LLM SE studies, and are they fairly evaluated against existing non-LLM techniques?\n",
    "\n",
    "DF Columns to use:\n",
    "- 'task' (short-text)\n",
    "- 'non_llm_approaches' (bool)\n",
    "- 'dataset_type' (short-text)\n",
    "- programming_language (short-text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a225d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_list\n",
      "code generation                                   26\n",
      "test generation                                   24\n",
      "program repair                                    24\n",
      "vulnerability detection                           15\n",
      "bug detection                                     10\n",
      "code translation                                   6\n",
      "code completion                                    6\n",
      "log parsing                                        5\n",
      "code search                                        5\n",
      "type detection                                     5\n",
      "clone detection                                    5\n",
      "fuzzing                                            4\n",
      "bug reproduction                                   3\n",
      "code summarisation                                 3\n",
      "code summarization                                 3\n",
      "formal verification                                2\n",
      "test repair                                        2\n",
      "code reasoning                                     2\n",
      "traceability link recovery                         2\n",
      "program analysis                                   2\n",
      "fault localisation                                 2\n",
      "commit message generation                          2\n",
      "code memorisation detection                        2\n",
      "code comprehension                                 2\n",
      "security patch detection                           1\n",
      "SO post editing                                    1\n",
      "comment repair                                     1\n",
      "code refinement                                    1\n",
      "smart contract auditing                            1\n",
      "UI design repair                                   1\n",
      "bug report comprehension                           1\n",
      "inconsistency prediction in decentralised apps     1\n",
      "AI generated code detection                        1\n",
      "detection of code design issues                    1\n",
      "code understanding                                 1\n",
      "configuration validation                           1\n",
      "code optimisation                                  1\n",
      "code adaptation                                    1\n",
      "machine-generated code detection                   1\n",
      "security injection                                 1\n",
      "root cause analysis                                1\n",
      "clone detection, bug detection                     1\n",
      "model completion                                   1\n",
      "regression testing                                 1\n",
      "binary software composition analysis               1\n",
      "API misuse detection                               1\n",
      "figurative language detection                      1\n",
      "code idioms detection                              1\n",
      "program comprehension                              1\n",
      "exception handling recommender                     1\n",
      "code synthesis                                     1\n",
      "privacy inconsistencies detection                  1\n",
      "static analysis                                    1\n",
      "comment generation                                 1\n",
      "code review                                        1\n",
      "log understanding                                  1\n",
      "CI/CD workflow generation                          1\n",
      "log generation                                     1\n",
      "model extraction                                   1\n",
      "emotion-cause extraction                           1\n",
      "requirements analysis                              1\n",
      "code retrieval                                     1\n",
      "mutant generation                                  1\n",
      "question answering                                 1\n",
      "SO posts summarisation                             1\n",
      "code transalation                                  1\n",
      "code-to-code retrieval                             1\n",
      "assert generation                                  1\n",
      "algorithm classification                           1\n",
      "heterogeneous device mapping                       1\n",
      "vulnerability alert prediction                     1\n",
      "optimal threat coarsening factor                   1\n",
      "program translation                                1\n",
      "vulnerability repair                               1\n",
      "GUI test case migration                            1\n",
      "software effort estimation                         1\n",
      "Name: count, dtype: int64\n",
      "['vulnerability detection' 'test generation' 'test repair'\n",
      " 'code refinement' 'code generation' 'comment repair' 'program repair'\n",
      " 'SO post editing' 'code reasoning' 'code translation' 'bug detection'\n",
      " 'security patch detection' 'model completion' 'commit message generation'\n",
      " 'traceability link recovery' 'log parsing' 'AI generated code detection'\n",
      " 'code summarization' 'program analysis' 'regression testing'\n",
      " 'code search' 'fuzzing' 'inconsistency prediction in decentralised apps'\n",
      " 'formal verification' 'bug report comprehension' 'UI design repair'\n",
      " 'type detection' 'smart contract auditing' 'configuration validation'\n",
      " 'detection of code design issues' 'code understanding' 'code completion'\n",
      " 'clone detection' 'code adaptation' 'fault localisation'\n",
      " 'code optimisation' 'security injection'\n",
      " 'machine-generated code detection' 'root cause analysis'\n",
      " 'code summarisation' 'code comprehension'\n",
      " 'clone detection, bug detection' 'API misuse detection'\n",
      " 'binary software composition analysis' 'code idioms detection'\n",
      " 'privacy inconsistencies detection' 'figurative language detection'\n",
      " 'emotion-cause extraction' 'program comprehension'\n",
      " 'exception handling recommender' 'code synthesis' 'static analysis'\n",
      " 'comment generation' 'bug reproduction' 'code review' 'log understanding'\n",
      " 'CI/CD workflow generation' 'log generation' 'model extraction'\n",
      " 'requirements analysis' 'code retrieval' 'question answering'\n",
      " 'mutant generation' 'assert generation' 'SO posts summarisation'\n",
      " 'code transalation' 'code-to-code retrieval' 'algorithm classification'\n",
      " 'heterogeneous device mapping' 'optimal threat coarsening factor'\n",
      " 'vulnerability alert prediction' 'program translation'\n",
      " 'vulnerability repair' 'GUI test case migration'\n",
      " 'software effort estimation' 'code memorisation detection']\n"
     ]
    }
   ],
   "source": [
    "df_combined['task_list'] = df_combined['task'].apply(\n",
    "    lambda x: [task.strip() for task in str(x).split(';')] if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "print(df_combined['task_list'].explode().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8a1c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_llm_approaches\n",
      "True                                                                                                                                                                                                              91\n",
      "False                                                                                                                                                                                                             59\n",
      "FALSE (says TransCoder is not llm but a language modeling appraoch using transformers and seq2seq)                                                                                                                 1\n",
      "TRUE (FTLR, COMET, VSM, LSI,ArDoCode)                                                                                                                                                                              1\n",
      "TRUE (AEL, Drain)                                                                                                                                                                                                  1\n",
      "TRUE (Devign, IVDetect both using gated graph NNs)                                                                                                                                                                 1\n",
      "FALSE (because they compare with older transformers)                                                                                                                                                               1\n",
      "TRUE (see Table I: Apollo, REDriver, FixDriver)                                                                                                                                                                    1\n",
      "TRUE (comparison with other 4 fuzzing approaches)                                                                                                                                                                  1\n",
      "TRUE (code generation approaches: RawGPT, CodeT, Reflexion, and FlowGen - their approach. For the evaluations of all approaches, they use ChatGPT.)                                                                1\n",
      "TRUE (we also compare four state-of-the-art (SOTA)\\ncode generation approaches that operate during the decoding process)                                                                                           1\n",
      "TRUE (API-level fuzzers such as Free-\\nFuzz [13], DeepREL [64], NablaFuzz [14], TensorScope [15],\\nand TitanFuzz [21], while also considering model-level fuzzers\\nlike Muffin [18] and FUTURE their approach)     1\n",
      "TRUE (baselines: CodeExecutor, GPT-3.5, A variant of ORCA)                                                                                                                                                         1\n",
      "TRUE (deep code models use in three approaches ALERT, BeamAttack, ITGen for comparison. See Table II.)                                                                                                             1\n",
      "TRUE                                                                                                                                                                                                               1\n",
      "TRUE (QAQA; metamorphic testing for QA software)                                                                                                                                                                   1\n",
      "TRUE (e.g., the KNOD DL-based approach)                                                                                                                                                                            1\n",
      "TRUE (We choose seven baseline techniques. One of them is the Rust\\ncompiler (rustc), since it sometimes offers direct suggestions for\\nmodifying the program to pass compiler checks...)                          1\n",
      "TRUE (RQ4)                                                                                                                                                                                                         1\n",
      "TRUE (Table 3)                                                                                                                                                                                                     1\n",
      "YES (Table 2)                                                                                                                                                                                                      1\n",
      "TRUE (EvoCrash and Copy&Paste -> crash reproduction baselines)                                                                                                                                                     1\n",
      "TRUE (DynaMosa, CODEXONLY)                                                                                                                                                                                         1\n",
      "TRUE (Pyflakes -> static analysis tool, CommitGen -> RNN-based, NNGen -> Information Retrival-based, Fine-tuned CodeT5, Bugsplainer based on CodeT5-60M)                                                           1\n",
      "TRUE (see Table III)                                                                                                                                                                                               1\n",
      "TRUE (Transformers in RQ3)                                                                                                                                                                                         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_combined['non_llm_approaches'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b40c9",
   "metadata": {},
   "source": [
    "# RQ2 - What models are being used?\n",
    "\n",
    "DF Columns to use:\n",
    "- 'models_open_closed' (open/closed/both)\n",
    "- 'num_models' (int)\n",
    "- 'model_families' (list of short text)\n",
    "- 'model_sizes_reported' (NA/none/some/full - currently unfinished)\n",
    "- 'model_scale' (currently unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5c9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db94f1a0",
   "metadata": {},
   "source": [
    "# RQ3 - How well do authors tackle the problem of data leakage/contamination?\n",
    "\n",
    "DF Columns to use:\n",
    "- contamination (bool)\n",
    "- contamination_free_text (free text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d1ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eccfc14a",
   "metadata": {},
   "source": [
    "# RQ4 - How replicable are LLM-based studies?\n",
    "\n",
    "DF Columns to use:\n",
    "- 'model_config' (short-text list)\n",
    "- 'artifact_available' (bool)\n",
    "- 'artifact_reusable' (bool)\n",
    "- 'artifact_functional' (bool)\n",
    "- 'artefact_manual' (bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d775ea",
   "metadata": {},
   "source": [
    "## ACM Badge Artifact Availability - Relevant vs. Non-Relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96259443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of relevant papers with artifact available: 19.08% (33/173)\n",
      "Proportion of other papers with artifact available: 41.28% (213/516)\n"
     ]
    }
   ],
   "source": [
    "# Calculate proportions in the combined dataset\n",
    "total_relevant = df_relevant.shape[0]\n",
    "total_non_relevant = df_non_relevant.shape[0]\n",
    "\n",
    "relevant_with_artifact = df_relevant['artifact_available'].sum()\n",
    "non_relevant_with_artifact = df_non_relevant['artifact_available'].sum()\n",
    "\n",
    "prop_relevant = relevant_with_artifact / total_relevant\n",
    "prop_non_relevant = non_relevant_with_artifact / total_non_relevant\n",
    "\n",
    "print(f\"Proportion of relevant papers with artifact available: {prop_relevant:.2%} ({relevant_with_artifact}/{total_relevant})\")\n",
    "print(f\"Proportion of other papers with artifact available: {prop_non_relevant:.2%} ({non_relevant_with_artifact}/{total_non_relevant})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "637d335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Proportion of relevant papers with artifact available: 16.67% (5/30)\n",
      "2024 - Proportion of relevant papers with artifact available: 16.98% (9/53)\n",
      "2025 - Proportion of relevant papers with artifact available: 21.11% (19/90)\n"
     ]
    }
   ],
   "source": [
    "# Proportion of relevant papers with artifacts available per year\n",
    "total_relevant_2023 = df_relevant[df_relevant['year'] == 2023].shape[0]\n",
    "artifact_avail_2023 = df_relevant[(df_relevant['year'] == 2023) & (df_relevant['artifact_available'])].shape[0]\n",
    "prop_relevant_2023 = artifact_avail_2023 / total_relevant_2023\n",
    "print(f\"2023 - Proportion of relevant papers with artifact available: {prop_relevant_2023:.2%} ({artifact_avail_2023}/{total_relevant_2023})\")\n",
    "\n",
    "total_relevant_2024 = df_relevant[df_relevant['year'] == 2024].shape[0]\n",
    "artifact_avail_2024 = df_relevant[(df_relevant['year'] == 2024) & (df_relevant['artifact_available'])].shape[0]\n",
    "prop_relevant_2024 = artifact_avail_2024 / total_relevant_2024\n",
    "print(f\"2024 - Proportion of relevant papers with artifact available: {prop_relevant_2024:.2%} ({artifact_avail_2024}/{total_relevant_2024})\")\n",
    "\n",
    "total_relevant_2025 = df_relevant[df_relevant['year'] == 2025].shape[0]\n",
    "artifact_avail_2025 = df_relevant[(df_relevant['year'] == 2025) & (df_relevant['artifact_available'])].shape[0]\n",
    "prop_relevant_2025 = artifact_avail_2025 / total_relevant_2025\n",
    "print(f\"2025 - Proportion of relevant papers with artifact available: {prop_relevant_2025:.2%} ({artifact_avail_2025}/{total_relevant_2025})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e39d00",
   "metadata": {},
   "source": [
    "## Manual Artefact Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62cde1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artefact_manual\n",
      "True     139\n",
      "False     24\n",
      "DEAD      10\n",
      "Name: count, dtype: int64\n",
      "10 instances of dead links in the 173 relevant papers\n"
     ]
    }
   ],
   "source": [
    "print(df_relevant[\"artefact_manual\"].value_counts())\n",
    "print(\"10 instances of dead links in the 173 relevant papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518a064",
   "metadata": {},
   "source": [
    "# RQ5 - How sustainable is LLM-based SE research?\n",
    "\n",
    "DF Columns to use:\n",
    "- 'cost' (short-text list)\n",
    "- 'cost_free_text' (free text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb184c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "647f0002",
   "metadata": {},
   "source": [
    "# (IGNORE - OLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112f76b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['reviewer', 'relevant', 'year', 'title', 'authors', 'url', 'abstract',\n",
       "       'artifact_available', 'artifact_reusable', 'artifact_functional', 'ai',\n",
       "       'Task being solved  (CODE GENERATION;APR;TESTING;COMMENT GENERATION/...)',\n",
       "       'AA Task Consolidated',\n",
       "       'Do the papers evaluate with approaches other than LLM? (TRUE/FALSE)',\n",
       "       'Is the budget fair (on hold)',\n",
       "       'Do they evaluate with open source/commercial/open weight models? (COMMERCIAL/OPEN SOURCE/OPEN WEIGHT)',\n",
       "       'DW Open/Closed Consolidated ',\n",
       "       'How many models overall, benchmarks and approach? (integer)',\n",
       "       'DW Num. Models Conslidated', 'Name of models',\n",
       "       'DW Scale of models (LARGE >50B/MEDIUM>1B/SMALL<1B)',\n",
       "       'Size of models from the paper (free text from the paper)',\n",
       "       'DW Model Sizes Reported (none, partial, full, N/A for commercial)',\n",
       "       'Do they report on the model versions? (TRUE/FALSE)',\n",
       "       'Configuration of models (TRUE/FALSE, or parameters)',\n",
       "       'AA Configuration consolidation',\n",
       "       'Type of dataset (code, text, logs, documentation, images)',\n",
       "       'Programming language (if coding dataset)',\n",
       "       'Programming Language Consolidated',\n",
       "       'How many evaluation datasets? (integer)',\n",
       "       'Names of evaluation datasets (free text from paper Name1;Name2)',\n",
       "       'Size of evaluation dataset (LARGE (Millions) /MEDIUM(hundered thousand)/SMALL( thousands))',\n",
       "       'Sizes of evaluation dataset from the paper (free text from the paper)',\n",
       "       'Training dataset same as testing (TRUE/FALSE/NA)',\n",
       "       'Do they report on the data version? (TRUE/FALSE)',\n",
       "       'What do authors report in terms of COST (running time, training time, $$, tokens, GPU usage, energy, CO2, running environment)',\n",
       "       'MH Cost Consolidated', 'Cost (free text from the paper)',\n",
       "       'Artefact available online (TRUE/FALSE)',\n",
       "       'MK Artefact available consolidated', 'Permissive licence (TRUE/FALSE)',\n",
       "       'MK Does the paper consider evaluation contamination in threats to validity (TRUE/FALSE)',\n",
       "       'Strategy for dealing with contamination? (FREE text)', 'Notes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete = pd.read_excel('results/final/complete.xlsx', sheet_name='AI_ICSE2025_papers')\n",
    "\n",
    "df_relevant = df_complete[df_complete['relevant'] == True]\n",
    "\n",
    "print(\"Columns\")\n",
    "df_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0b7c222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevant\n",
       "True       164\n",
       "False       50\n",
       "SPECIAL      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete['relevant'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d364548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2025.0    89\n",
       "2024.0    53\n",
       "2023.0    22\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of relevant papers per year\n",
    "df_relevant['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cca35fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vulnerability detection' 'test generation' 'test repair'\n",
      " 'code refinement' 'code generation' 'comment repair' 'program repair'\n",
      " 'SO post editing' 'code reasoning; code translation' 'code reasoning'\n",
      " 'code translation' 'bug detection' 'security patch detection'\n",
      " 'model completion' 'commit message generation'\n",
      " 'traceability link recovery' 'log parsing' 'AI generated code detection'\n",
      " 'code generation; code summarization' 'program analysis'\n",
      " 'regression testing' 'code search' 'fuzzing'\n",
      " 'inconsistency prediction in decentralised apps' 'formal verification'\n",
      " 'bug report comprehension' 'UI design repair' 'type detection'\n",
      " 'smart contract auditing' 'configuration validation'\n",
      " 'detection of code design issues' 'code understanding; code generation'\n",
      " 'code completion' 'clone detection; vulnerability detection'\n",
      " 'code adaptation' 'fault localisation; bug detection'\n",
      " 'code summarization' 'code optimisation' 'security injection'\n",
      " 'machine-generated code detection' 'root cause analysis'\n",
      " 'code summarisation' 'log parsing '\n",
      " 'code comprehension; clone detection, bug detection; type detection'\n",
      " 'API misuse detection; code generation'\n",
      " 'binary software composition analysis' 'code idioms detection'\n",
      " 'privacy inconsistencies detection' 'figurative language detection'\n",
      " 'emotion-cause extraction' 'program comprehension'\n",
      " 'exception handling recommender' 'code comprehension; code generation'\n",
      " 'code synthesis; code translation; code summarisation'\n",
      " 'static analysis; clone detection; vulnerability detection'\n",
      " 'comment generation' 'bug reproduction' 'fault localisation'\n",
      " 'code review' 'log understanding' 'CI/CD workflow generation'\n",
      " 'log generation' 'log comprehension' 'model extraction'\n",
      " 'requirements analysis'\n",
      " 'program repair; code summarization; code completion'\n",
      " 'bug detection; clone detection; type detection; code retrieval; code search; question answering; code translation; program repair; code completion; mutant generation; assert generation; code summarisation; code generation'\n",
      " 'SO posts summarisation' 'test generation, program repair'\n",
      " 'code generation; code transalation; type detection'\n",
      " 'test generation; program repair' 'code completion; bug detection']\n"
     ]
    }
   ],
   "source": [
    "print(df_relevant[\"AA Task Consolidated\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ca4153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/jg8766954y92j4x7kpzdhg680000gp/T/ipykernel_38870/1597075678.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant['AA Task List'] = df_relevant['AA Task Consolidated'].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA Task Consolidated</th>\n",
       "      <th>AA Task List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vulnerability detection</td>\n",
       "      <td>[vulnerability detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test generation</td>\n",
       "      <td>[test generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test repair</td>\n",
       "      <td>[test repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code refinement</td>\n",
       "      <td>[code refinement]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test generation</td>\n",
       "      <td>[test generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test generation</td>\n",
       "      <td>[test generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test generation</td>\n",
       "      <td>[test generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>comment repair</td>\n",
       "      <td>[comment repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SO post editing</td>\n",
       "      <td>[SO post editing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>code reasoning; code translation</td>\n",
       "      <td>[code reasoning, code translation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>code reasoning</td>\n",
       "      <td>[code reasoning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>code translation</td>\n",
       "      <td>[code translation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bug detection</td>\n",
       "      <td>[bug detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>security patch detection</td>\n",
       "      <td>[security patch detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>model completion</td>\n",
       "      <td>[model completion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>commit message generation</td>\n",
       "      <td>[commit message generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>vulnerability detection</td>\n",
       "      <td>[vulnerability detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>traceability link recovery</td>\n",
       "      <td>[traceability link recovery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>log parsing</td>\n",
       "      <td>[log parsing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AI generated code detection</td>\n",
       "      <td>[AI generated code detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>code generation; code summarization</td>\n",
       "      <td>[code generation, code summarization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>commit message generation</td>\n",
       "      <td>[commit message generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>program analysis</td>\n",
       "      <td>[program analysis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>regression testing</td>\n",
       "      <td>[regression testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>code search</td>\n",
       "      <td>[code search]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>vulnerability detection</td>\n",
       "      <td>[vulnerability detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>vulnerability detection</td>\n",
       "      <td>[vulnerability detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>test generation</td>\n",
       "      <td>[test generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>fuzzing</td>\n",
       "      <td>[fuzzing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>inconsistency prediction in decentralised apps</td>\n",
       "      <td>[inconsistency prediction in decentralised apps]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>test generation</td>\n",
       "      <td>[test generation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>formal verification</td>\n",
       "      <td>[formal verification]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>program repair</td>\n",
       "      <td>[program repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bug report comprehension</td>\n",
       "      <td>[bug report comprehension]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>UI design repair</td>\n",
       "      <td>[UI design repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>type detection</td>\n",
       "      <td>[type detection]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>code generation</td>\n",
       "      <td>[code generation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AA Task Consolidated  \\\n",
       "0                          vulnerability detection   \n",
       "1                                  test generation   \n",
       "2                                      test repair   \n",
       "4                                  code refinement   \n",
       "6                                  test generation   \n",
       "7                                  code generation   \n",
       "9                                  test generation   \n",
       "10                                 code generation   \n",
       "11                                 test generation   \n",
       "13                                 code generation   \n",
       "15                                  comment repair   \n",
       "16                                  program repair   \n",
       "17                                 SO post editing   \n",
       "18                code reasoning; code translation   \n",
       "19                                  code reasoning   \n",
       "20                                  program repair   \n",
       "21                                code translation   \n",
       "23                                 code generation   \n",
       "26                                   bug detection   \n",
       "27                        security patch detection   \n",
       "28                                model completion   \n",
       "29                       commit message generation   \n",
       "30                                 code generation   \n",
       "34                                  program repair   \n",
       "35                         vulnerability detection   \n",
       "39                      traceability link recovery   \n",
       "40                                  program repair   \n",
       "42                                     log parsing   \n",
       "44                     AI generated code detection   \n",
       "46             code generation; code summarization   \n",
       "47                       commit message generation   \n",
       "48                                 code generation   \n",
       "49                                 code generation   \n",
       "50                                program analysis   \n",
       "53                              regression testing   \n",
       "54                                     code search   \n",
       "55                         vulnerability detection   \n",
       "56                         vulnerability detection   \n",
       "57                                 test generation   \n",
       "58                                  program repair   \n",
       "59                                         fuzzing   \n",
       "60  inconsistency prediction in decentralised apps   \n",
       "61                                 test generation   \n",
       "63                                  program repair   \n",
       "64                             formal verification   \n",
       "65                                  program repair   \n",
       "66                        bug report comprehension   \n",
       "68                                UI design repair   \n",
       "69                                  type detection   \n",
       "72                                 code generation   \n",
       "\n",
       "                                        AA Task List  \n",
       "0                          [vulnerability detection]  \n",
       "1                                  [test generation]  \n",
       "2                                      [test repair]  \n",
       "4                                  [code refinement]  \n",
       "6                                  [test generation]  \n",
       "7                                  [code generation]  \n",
       "9                                  [test generation]  \n",
       "10                                 [code generation]  \n",
       "11                                 [test generation]  \n",
       "13                                 [code generation]  \n",
       "15                                  [comment repair]  \n",
       "16                                  [program repair]  \n",
       "17                                 [SO post editing]  \n",
       "18                [code reasoning, code translation]  \n",
       "19                                  [code reasoning]  \n",
       "20                                  [program repair]  \n",
       "21                                [code translation]  \n",
       "23                                 [code generation]  \n",
       "26                                   [bug detection]  \n",
       "27                        [security patch detection]  \n",
       "28                                [model completion]  \n",
       "29                       [commit message generation]  \n",
       "30                                 [code generation]  \n",
       "34                                  [program repair]  \n",
       "35                         [vulnerability detection]  \n",
       "39                      [traceability link recovery]  \n",
       "40                                  [program repair]  \n",
       "42                                     [log parsing]  \n",
       "44                     [AI generated code detection]  \n",
       "46             [code generation, code summarization]  \n",
       "47                       [commit message generation]  \n",
       "48                                 [code generation]  \n",
       "49                                 [code generation]  \n",
       "50                                [program analysis]  \n",
       "53                              [regression testing]  \n",
       "54                                     [code search]  \n",
       "55                         [vulnerability detection]  \n",
       "56                         [vulnerability detection]  \n",
       "57                                 [test generation]  \n",
       "58                                  [program repair]  \n",
       "59                                         [fuzzing]  \n",
       "60  [inconsistency prediction in decentralised apps]  \n",
       "61                                 [test generation]  \n",
       "63                                  [program repair]  \n",
       "64                             [formal verification]  \n",
       "65                                  [program repair]  \n",
       "66                        [bug report comprehension]  \n",
       "68                                [UI design repair]  \n",
       "69                                  [type detection]  \n",
       "72                                 [code generation]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the 'AA Task Consolidated' column into lists\n",
    "df_relevant['AA Task List'] = df_relevant['AA Task Consolidated'].apply(\n",
    "    lambda x: [task.strip() for task in str(x).split(';')] if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "df_relevant[['AA Task Consolidated', 'AA Task List']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b504644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tasks: 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Paper_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>code generation</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test generation</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>program repair</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vulnerability detection</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bug detection</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fuzzing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>log parsing</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>type detection</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>code completion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>code translation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>code search</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clone detection</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>code summarisation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bug reproduction</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>code summarization</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>code comprehension</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>formal verification</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CI/CD workflow generation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fault localisation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test repair</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>program analysis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>traceability link recovery</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>commit message generation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>code refinement</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>code reasoning</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>regression testing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>program comprehension</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>exception handling recommender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>code synthesis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>static analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>comment generation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>code review</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>log understanding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>log generation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>figurative language detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>log comprehension</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>model extraction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>requirements analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>code retrieval</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>question answering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mutant generation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>assert generation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SO posts summarisation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>test generation, program repair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>emotion-cause extraction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>binary software composition analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>privacy inconsistencies detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>code idioms detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>AI generated code detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>inconsistency prediction in decentralised apps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>bug report comprehension</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>UI design repair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>smart contract auditing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>configuration validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>detection of code design issues</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>code understanding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>model completion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>security patch detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>code adaptation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>code optimisation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>security injection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>machine-generated code detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>root cause analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SO post editing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>comment repair</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>clone detection, bug detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>API misuse detection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>code transalation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Task  Paper_Count\n",
       "0                                  code generation           25\n",
       "1                                  test generation           24\n",
       "2                                   program repair           22\n",
       "3                          vulnerability detection           13\n",
       "4                                    bug detection            8\n",
       "5                                          fuzzing            5\n",
       "6                                      log parsing            5\n",
       "7                                   type detection            5\n",
       "8                                  code completion            5\n",
       "9                                 code translation            5\n",
       "10                                     code search            3\n",
       "11                                 clone detection            3\n",
       "12                              code summarisation            3\n",
       "13                                bug reproduction            3\n",
       "14                              code summarization            3\n",
       "15                              code comprehension            2\n",
       "16                             formal verification            2\n",
       "17                       CI/CD workflow generation            2\n",
       "18                              fault localisation            2\n",
       "19                                     test repair            2\n",
       "20                                program analysis            2\n",
       "21                      traceability link recovery            2\n",
       "22                       commit message generation            2\n",
       "23                                 code refinement            2\n",
       "24                                  code reasoning            2\n",
       "25                              regression testing            1\n",
       "26                           program comprehension            1\n",
       "27                  exception handling recommender            1\n",
       "28                                  code synthesis            1\n",
       "29                                 static analysis            1\n",
       "30                              comment generation            1\n",
       "31                                     code review            1\n",
       "32                               log understanding            1\n",
       "33                                  log generation            1\n",
       "34                   figurative language detection            1\n",
       "35                               log comprehension            1\n",
       "36                                model extraction            1\n",
       "37                           requirements analysis            1\n",
       "38                                  code retrieval            1\n",
       "39                              question answering            1\n",
       "40                               mutant generation            1\n",
       "41                               assert generation            1\n",
       "42                          SO posts summarisation            1\n",
       "43                 test generation, program repair            1\n",
       "44                        emotion-cause extraction            1\n",
       "45            binary software composition analysis            1\n",
       "46               privacy inconsistencies detection            1\n",
       "47                           code idioms detection            1\n",
       "48                     AI generated code detection            1\n",
       "49  inconsistency prediction in decentralised apps            1\n",
       "50                        bug report comprehension            1\n",
       "51                                UI design repair            1\n",
       "52                         smart contract auditing            1\n",
       "53                        configuration validation            1\n",
       "54                 detection of code design issues            1\n",
       "55                              code understanding            1\n",
       "56                                model completion            1\n",
       "57                        security patch detection            1\n",
       "58                                 code adaptation            1\n",
       "59                               code optimisation            1\n",
       "60                              security injection            1\n",
       "61                machine-generated code detection            1\n",
       "62                             root cause analysis            1\n",
       "63                                 SO post editing            1\n",
       "64                                  comment repair            1\n",
       "65                  clone detection, bug detection            1\n",
       "66                            API misuse detection            1\n",
       "67                               code transalation            1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_tasks = []\n",
    "for task_list in df_relevant['AA Task List']:\n",
    "    all_tasks.extend(task_list)\n",
    "\n",
    "task_counts = Counter(all_tasks)\n",
    "\n",
    "task_frequency_df = pd.DataFrame(task_counts.items(), columns=['Task', 'Paper_Count'])\n",
    "task_frequency_df = task_frequency_df.sort_values('Paper_Count', ascending=False, ignore_index=True)\n",
    "\n",
    "print(f\"Total unique tasks: {len(task_frequency_df)}\")\n",
    "task_frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3809884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of number of tasks per paper:\n",
      "num_tasks\n",
      "1     149\n",
      "2       9\n",
      "3       5\n",
      "13      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Papers covering multiple tasks: 15\n",
      "Percentage covering multiple tasks: 9.1%\n",
      "                                                 title  \\\n",
      "205  An Empirical Comparison of Pre-Trained Models ...   \n",
      "\n",
      "                                          AA Task List  \n",
      "205  [bug detection, clone detection, type detectio...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/jg8766954y92j4x7kpzdhg680000gp/T/ipykernel_38870/2640534977.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant['num_tasks'] = df_relevant['AA Task List'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "# Looking at how many papers cover multiple tasks\n",
    "df_relevant['num_tasks'] = df_relevant['AA Task List'].apply(len)\n",
    "\n",
    "print(\"Distribution of number of tasks per paper:\")\n",
    "print(df_relevant['num_tasks'].value_counts().sort_index())\n",
    "print(f\"\\nPapers covering multiple tasks: {(df_relevant['num_tasks'] > 1).sum()}\")\n",
    "print(f\"Percentage covering multiple tasks: {(df_relevant['num_tasks'] > 1).mean()*100:.1f}%\")\n",
    "\n",
    "print(df_relevant[df_relevant['num_tasks'] > 5][['title', 'AA Task List']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192a93c",
   "metadata": {},
   "source": [
    "# Artifact Badges vs Our Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d2f4d",
   "metadata": {},
   "source": [
    "## Badges from ACM Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e048e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_available\n",
      "False    132\n",
      "True      32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "artifact_reusable\n",
      "False    143\n",
      "True      21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "artifact_functional\n",
      "False    150\n",
      "True      14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Overall\n",
    "print(df_relevant['artifact_available'].value_counts())\n",
    "print()\n",
    "print(df_relevant['artifact_reusable'].value_counts())\n",
    "print()\n",
    "print(df_relevant['artifact_functional'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c8ec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Available (ACM Badges)\n",
      "2023\n",
      "artifact_available\n",
      "False    17\n",
      "True      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2024\n",
      "artifact_available\n",
      "False    45\n",
      "True      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2025\n",
      "artifact_available\n",
      "False    70\n",
      "True     19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Artifact Reusable (ACM Badges)\n",
      "2023\n",
      "artifact_reusable\n",
      "False    20\n",
      "True      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2024\n",
      "artifact_reusable\n",
      "False    45\n",
      "True      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2025\n",
      "artifact_reusable\n",
      "False    78\n",
      "True     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Artifact Functional (ACM Badges)\n",
      "2023\n",
      "artifact_functional\n",
      "False    21\n",
      "True      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2024\n",
      "artifact_functional\n",
      "False    53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2025\n",
      "artifact_functional\n",
      "False    76\n",
      "True     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Per year\n",
    "print(\"Artifact Available (ACM Badges)\")\n",
    "print(\"2023\")\n",
    "print(df_relevant[df_relevant['year'] == 2023]['artifact_available'].value_counts())\n",
    "print(\"\\n2024\")\n",
    "print(df_relevant[df_relevant['year'] == 2024]['artifact_available'].value_counts())\n",
    "print(\"\\n2025\")\n",
    "print(df_relevant[df_relevant['year'] == 2025]['artifact_available'].value_counts())\n",
    "\n",
    "\n",
    "print(\"\\n\\nArtifact Reusable (ACM Badges)\")\n",
    "print(\"2023\")\n",
    "print(df_relevant[df_relevant['year'] == 2023]['artifact_reusable'].value_counts())\n",
    "print(\"\\n2024\")\n",
    "print(df_relevant[df_relevant['year'] == 2024]['artifact_reusable'].value_counts())\n",
    "print(\"\\n2025\")\n",
    "print(df_relevant[df_relevant['year'] == 2025]['artifact_reusable'].value_counts())\n",
    "\n",
    "\n",
    "print(\"\\n\\nArtifact Functional (ACM Badges)\")\n",
    "print(\"2023\")\n",
    "print(df_relevant[df_relevant['year'] == 2023]['artifact_functional'].value_counts())\n",
    "print(\"\\n2024\")\n",
    "print(df_relevant[df_relevant['year'] == 2024]['artifact_functional'].value_counts())\n",
    "print(\"\\n2025\")\n",
    "print(df_relevant[df_relevant['year'] == 2025]['artifact_functional'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1cd70",
   "metadata": {},
   "source": [
    "## Artifact Availability from Manual Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0e8eaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MK Artefact available consolidated\n",
      "True     129\n",
      "False     24\n",
      "DEAD      11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Overall\n",
    "print(df_relevant['MK Artefact available consolidated'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167137b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 Artifacts (Manual Checking)\n",
      "MK Artefact available consolidated\n",
      "True     15\n",
      "False     4\n",
      "DEAD      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2024 Artifacts (Manual Checking)\n",
      "MK Artefact available consolidated\n",
      "True     40\n",
      "False     9\n",
      "DEAD      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "2025 Artifacts (Manual Checking)\n",
      "MK Artefact available consolidated\n",
      "True     74\n",
      "False    11\n",
      "DEAD      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Per year\n",
    "print(\"2023 Artifacts (Manual Checking)\")\n",
    "print(df_relevant[df_relevant['year'] == 2023]['MK Artefact available consolidated'].value_counts())\n",
    "print(\"\\n2024 Artifacts (Manual Checking)\")\n",
    "print(df_relevant[df_relevant['year'] == 2024]['MK Artefact available consolidated'].value_counts())\n",
    "print(\"\\n2025 Artifacts (Manual Checking)\")\n",
    "print(df_relevant[df_relevant['year'] == 2025]['MK Artefact available consolidated'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8966d95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
