{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c2ad56",
   "metadata": {},
   "source": [
    "# Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models: A Reflection - Analysis Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685ec4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_relevant = pd.read_excel(\n",
    "    'results/final/final_results.xlsx', sheet_name='relevant_papers')\n",
    "df_all_papers = pd.read_csv('results/ICSE_all_papers.csv')\n",
    "\n",
    "relevant_papers = df_relevant['title'].tolist()\n",
    "df_non_relevant = df_all_papers[~df_all_papers['title'].isin(\n",
    "    relevant_papers)].copy()\n",
    "df_non_relevant['relevant'] = False\n",
    "common_columns = ['reviewer', 'relevant', 'year', 'title', 'authors', 'url',\n",
    "                  'abstract', 'artifact_available', 'artifact_reusable', 'artifact_functional', 'ai']\n",
    "df_non_relevant = df_non_relevant[common_columns]\n",
    "extra_columns = ['task', 'non_llm_approaches', 'models_open_closed', 'num_models', 'model_families', 'model_scale', 'model_size_free_text', 'model_sizes_reported',\n",
    "                 'model_config', 'dataset_type', 'programming_language', 'cost', 'cost_free_text', 'artefact_manual', 'contamination', 'contamination_free_text']\n",
    "for col in extra_columns:\n",
    "    df_non_relevant[col] = None\n",
    "df_combined = pd.concat([df_relevant, df_non_relevant], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fe84e",
   "metadata": {},
   "source": [
    "# Number of Papers at Each Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff256aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Papers: 692\n",
      "Number of Papers matching AI Keywords: 304/692 (43.93%)\n",
      "Number of Relevant Papers: 177/692 (25.58%)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Papers:\", df_combined.shape[0])\n",
    "\n",
    "print(\n",
    "    f\"Number of Papers matching AI Keywords: {df_combined['ai'].sum()}/{df_combined.shape[0]} ({(df_combined['ai'].sum()/df_combined.shape[0])*100:.2f}%)\")\n",
    "\n",
    "print(\n",
    "    f\"Number of Relevant Papers: {df_combined['relevant'].sum()}/{df_combined.shape[0]} ({(df_combined['relevant'].sum()/df_combined.shape[0])*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d1e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers Per Year:\n",
      "year\n",
      "2023    210\n",
      "2024    236\n",
      "2025    246\n",
      "Name: title, dtype: int64\n",
      "\n",
      "AI Keyword Papers Per Year:\n",
      "year\n",
      "2023     59\n",
      "2024     99\n",
      "2025    146\n",
      "Name: title, dtype: int64\n",
      "\n",
      "Relevant Papers Per Year:\n",
      "year\n",
      "2023    32\n",
      "2024    55\n",
      "2025    90\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Per Year\n",
    "print(\"Papers Per Year:\")\n",
    "print(df_combined.groupby('year')['title'].nunique())\n",
    "\n",
    "print(\"\\nAI Keyword Papers Per Year:\")\n",
    "print(df_combined[df_combined['ai'] == True].groupby(\n",
    "    'year')['title'].nunique())\n",
    "\n",
    "print(\"\\nRelevant Papers Per Year:\")\n",
    "print(df_combined[df_combined['relevant'] ==\n",
    "      True].groupby('year')['title'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f4bc3",
   "metadata": {},
   "source": [
    "# RQ1 - Which LLMs are used in SE research and how are they benchmarked?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56742b4",
   "metadata": {},
   "source": [
    "## Open vs. Closed (Commercial) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19d31b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models_open_closed\n",
       "open      71\n",
       "both      65\n",
       "closed    41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relevant['models_open_closed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf18354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open models in 136 out of 177 papers (76.8%)\n",
      "Closed models in 106 out of 177 papers (59.9%)\n"
     ]
    }
   ],
   "source": [
    "total = df_relevant.shape[0]\n",
    "number_open = df_relevant[~(\n",
    "    df_relevant['models_open_closed'] == 'closed')].shape[0]\n",
    "number_closed = df_relevant[~(\n",
    "    df_relevant['models_open_closed'] == 'open')].shape[0]\n",
    "\n",
    "print(\n",
    "    f\"Open models in {number_open} out of {total} papers ({(number_open/total)*100:.1f}%)\")\n",
    "print(\n",
    "    f\"Closed models in {number_closed} out of {total} papers ({(number_closed/total)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23da2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 Papers:\n",
      "Only open models in 22 out of 32 papers (68.8%)\n",
      "Only closed models in 4 out of 32 papers (12.5%)\n",
      "Open models in 28 out of 32 papers (87.5%)\n",
      "Closed models in 10 out of 32 papers (31.2%)\n",
      "Both model types in 6 out of 32 papers (18.8%)\n",
      "\n",
      "2024 Papers:\n",
      "Only open models in 25 out of 55 papers (45.5%)\n",
      "Only closed models in 13 out of 55 papers (23.6%)\n",
      "Open models in 42 out of 55 papers (76.4%)\n",
      "Closed models in 30 out of 55 papers (54.5%)\n",
      "Both model types in 17 out of 55 papers (30.9%)\n",
      "\n",
      "2025 Papers:\n",
      "Only open models in 24 out of 90 papers (26.7%)\n",
      "Only closed models in 24 out of 90 papers (26.7%)\n",
      "Open models in 66 out of 90 papers (73.3%)\n",
      "Closed models in 66 out of 90 papers (73.3%)\n",
      "Both model types in 42 out of 90 papers (46.7%)\n"
     ]
    }
   ],
   "source": [
    "def open_vs_closed_per_year(year):\n",
    "    total_year = df_relevant[df_relevant[\"year\"] == year].shape[0]\n",
    "    number_open_year = df_relevant[(df_relevant[\"year\"] == year) & ~(\n",
    "        df_relevant['models_open_closed'] == 'closed')].shape[0]\n",
    "    number_open_only_year = df_relevant[(df_relevant[\"year\"] == year) & (\n",
    "        df_relevant['models_open_closed'] == 'open')].shape[0]\n",
    "    number_closed_year = df_relevant[(df_relevant[\"year\"] == year) & ~(\n",
    "        df_relevant['models_open_closed'] == 'open')].shape[0]\n",
    "    number_closed_only_year = df_relevant[(df_relevant[\"year\"] == year) & (\n",
    "        df_relevant['models_open_closed'] == 'closed')].shape[0]\n",
    "    number_both_year = df_relevant[(df_relevant[\"year\"] == year) & (\n",
    "        df_relevant['models_open_closed'] == 'both')].shape[0]\n",
    "\n",
    "    print(f\"{year} Papers:\")\n",
    "    print(\n",
    "        f\"Only open models in {number_open_only_year} out of {total_year} papers ({(number_open_only_year/total_year)*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Only closed models in {number_closed_only_year} out of {total_year} papers ({(number_closed_only_year/total_year)*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Open models in {number_open_year} out of {total_year} papers ({(number_open_year/total_year)*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Closed models in {number_closed_year} out of {total_year} papers ({(number_closed_year/total_year)*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Both model types in {number_both_year} out of {total_year} papers ({(number_both_year/total_year)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "open_vs_closed_per_year(2023)\n",
    "print()\n",
    "open_vs_closed_per_year(2024)\n",
    "print()\n",
    "open_vs_closed_per_year(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180e73a",
   "metadata": {},
   "source": [
    "## Model Families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5aeb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall - Number of Papers per Model Family:\n",
      "model_families_list\n",
      "GPT-4                           47\n",
      "GPT-3.5                         44\n",
      "CodeBERT                        34\n",
      "CodeLlama                       26\n",
      "CodeT5                          22\n",
      "CodeGen                         19\n",
      "StarCoder                       18\n",
      "GraphCodeBERT                   18\n",
      "Llama                           17\n",
      "RoBERTa                         15\n",
      "ChatGPT                         14\n",
      "BERT                            13\n",
      "DeepSeekCoder                   12\n",
      "UniXcoder                       11\n",
      "Codex                           10\n",
      "InCoder                          9\n",
      "T5                               8\n",
      "Claude                           7\n",
      "Gemini                           7\n",
      "ChatGLM                          6\n",
      "DeepSeek                         6\n",
      "CodeQwen                         6\n",
      "GPT-3                            6\n",
      "UnixCoder                        6\n",
      "PLBART                           6\n",
      "CodeGPT                          5\n",
      "CodeParrot                       4\n",
      "Copilot                          4\n",
      "WizardCoder                      4\n",
      "GPT-2                            4\n",
      "PolyCoder                        4\n",
      "Mistral                          3\n",
      "Gemma                            3\n",
      "text-davinci                     3\n",
      "Pythia                           3\n",
      "Vicuna                           3\n",
      "DistilBERT                       3\n",
      "LineVul                          3\n",
      "CodeT5+                          3\n",
      "text-embedding                   3\n",
      "TransCoder                       2\n",
      "Codestral                        2\n",
      "Qwen                             2\n",
      "GPT3.5                           2\n",
      "CodeGemma                        2\n",
      "Incoder                          2\n",
      "CodeGeeX                         2\n",
      "VulBERTa                         2\n",
      "CuBERT                           2\n",
      "UniLog                           2\n",
      "BART                             2\n",
      "GPT-J                            2\n",
      "GPT-Neo                          2\n",
      "GPT-NEO                          2\n",
      "GPT-C                            2\n",
      "SynCoBERT                        2\n",
      "CoTexT                           2\n",
      "Phi                              2\n",
      "TFix                             2\n",
      "ALBERT                           2\n",
      "seBERT                           2\n",
      "Code-davinci                     2\n",
      "OpenDevin                        2\n",
      "SantaCoder                       2\n",
      "Longformer                       1\n",
      "CoditT5                          1\n",
      "Unixcoder                        1\n",
      "CodeBert                         1\n",
      "GPT4                             1\n",
      "SVulD                            1\n",
      "Poro                             1\n",
      "ChatDev                          1\n",
      "Self-collaboration               1\n",
      "MetaGPT                          1\n",
      "AutoGPT                          1\n",
      "Multi-Turn Program Synthesis     1\n",
      "AgentCoder                       1\n",
      "DetectGPT                        1\n",
      "GPT-2 Output Detector            1\n",
      "GPTZero                          1\n",
      "GPTSniffer                       1\n",
      "Starcoder                        1\n",
      "LLM-Parser                       1\n",
      "LILAC                            1\n",
      "Repilot                          1\n",
      "RAP-Gen                          1\n",
      "ChatRepair                       1\n",
      "FitRepair                        1\n",
      "AlphaRe-pair                     1\n",
      "Mixtral                          1\n",
      "VGX                              1\n",
      "ReVeal                           1\n",
      "Devign                           1\n",
      "VULGEN                           1\n",
      "COME                             1\n",
      "CCT5                             1\n",
      "NNGen                            1\n",
      "ALL-MINILM-L6-V210               1\n",
      "UniTrans                         1\n",
      "Shipwright                       1\n",
      "MagiCoder                        1\n",
      "Magicoder                        1\n",
      "Parfum                           1\n",
      "TOGA                             1\n",
      "AthenTest                        1\n",
      "SEQ Graph& HYBRID                1\n",
      "AppMap Naive                     1\n",
      "OpenCodeInterpreter              1\n",
      "AutoCodeRover                    1\n",
      "CodeShell                        1\n",
      "LLama                            1\n",
      "CoCoSoDa                         1\n",
      "CodeRetriever                    1\n",
      "HedgeCode                        1\n",
      "SYNCOBERT                        1\n",
      "Vercel                           1\n",
      "GPT-4, CodeBERT                  1\n",
      "Moatless Tools                   1\n",
      "Agentless                        1\n",
      "FuzzGPT                          1\n",
      "TitanFuzz                        1\n",
      "Aider                            1\n",
      "SWE-Agent                        1\n",
      "DeBERTa                          1\n",
      "OPT                              1\n",
      "GPT3-5                           1\n",
      "Tulu                             1\n",
      "Guanaco                          1\n",
      "PaLM                             1\n",
      "StarChat                         1\n",
      "CAT-LM                           1\n",
      "Exlong                           1\n",
      "GLTR                             1\n",
      "ContraBERT                       1\n",
      "ChatUniTest                      1\n",
      "TestGen-LLM                      1\n",
      "RustAssistant                    1\n",
      "Sonnet                           1\n",
      "Stable-Code                      1\n",
      "BigBird                          1\n",
      "Sapling                          1\n",
      "KeyBERT                          1\n",
      "DISCO                            1\n",
      "PDBERT                           1\n",
      "GPTBigCode                       1\n",
      "Sentence-BERT                    1\n",
      "Airboros                         1\n",
      "CodeBERTa                        1\n",
      "Flan                             1\n",
      "code-davinci                     1\n",
      "UnifiedQA                        1\n",
      "VRepair                          1\n",
      "CodeReviewer                     1\n",
      "GrammarT5                        1\n",
      "Transformer                      1\n",
      "LSTM                             1\n",
      "GIN                              1\n",
      "TypeFix                          1\n",
      "PyTER                            1\n",
      "CoCoNuT                          1\n",
      "AlphaRepair                      1\n",
      "LANCE                            1\n",
      "XLNet                            1\n",
      "RepresentThemAll                 1\n",
      "Curie                            1\n",
      "Davinci                          1\n",
      "ELECTRA                          1\n",
      "MiniLM                           1\n",
      "DOBF                             1\n",
      "VulRepair                        1\n",
      "VulMaster                        1\n",
      "PanguCoder                       1\n",
      "flan-alpaca                      1\n",
      "SPT-Code                         1\n",
      "ProphetNet-Code                  1\n",
      "T5-learning                      1\n",
      "JavaBERT                         1\n",
      "DeepDebug                        1\n",
      "C-BERT                           1\n",
      "CugLM                            1\n",
      "TreeBERT                         1\n",
      "PLBart                           1\n",
      "ATLAS                            1\n",
      "CoCoNut                          1\n",
      "Hoppity                          1\n",
      "Sequencer                        1\n",
      "CEDAR                            1\n",
      "Transformers                     1\n",
      "GPT-NeoX                         1\n",
      "FAIR                             1\n",
      "OSCAR                            1\n",
      "Transcoder*                      1\n",
      "IRGen                            1\n",
      "Deep-SE                          1\n",
      "GPT2SP                           1\n",
      "sentenceBERT                     1\n",
      "SDA-Trans                        1\n",
      "StableCode                       1\n",
      "CodeGen-NL                       1\n",
      "CodeGen-Mono                     1\n",
      "CodeGen-Multi                    1\n",
      "CodeGen2                         1\n",
      "PyCodeGPT                        1\n",
      "GPT-Code-Clippy                  1\n",
      "BERTOverflow                     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_relevant['model_families_list'] = df_relevant['model_families'].apply(\n",
    "    lambda x: [model_family.strip()\n",
    "               for model_family in str(x).split(';')] if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "print(\"Overall - Number of Papers per Model Family:\")\n",
    "print(df_relevant['model_families_list'].explode().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade8be06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Number of Papers per Model Family:\n",
      "model_families_list\n",
      "CodeBERT            11\n",
      "RoBERTa              8\n",
      "BERT                 7\n",
      "CodeT5               7\n",
      "Codex                5\n",
      "T5                   5\n",
      "GraphCodeBERT        4\n",
      "DistilBERT           3\n",
      "PLBART               2\n",
      "GPT-J                2\n",
      "CodeGen              2\n",
      "BART                 2\n",
      "InCoder              2\n",
      "GPT-Neo              2\n",
      "XLNet                1\n",
      "MiniLM               1\n",
      "ELECTRA              1\n",
      "ALBERT               1\n",
      "RepresentThemAll     1\n",
      "seBERT               1\n",
      "Code-davinci         1\n",
      "Curie                1\n",
      "Davinci              1\n",
      "T5-learning          1\n",
      "CodeGPT              1\n",
      "JavaBERT             1\n",
      "DOBF                 1\n",
      "CuBERT               1\n",
      "ProphetNet-Code      1\n",
      "SPT-Code             1\n",
      "CoTexT               1\n",
      "C-BERT               1\n",
      "GPT-C                1\n",
      "CugLM                1\n",
      "TreeBERT             1\n",
      "GPT-2                1\n",
      "SynCoBERT            1\n",
      "DeepDebug            1\n",
      "UniXcoder            1\n",
      "GPT-NeoX             1\n",
      "PLBart               1\n",
      "GPT-3                1\n",
      "CodeParrot           1\n",
      "Copilot              1\n",
      "ATLAS                1\n",
      "CoCoNut              1\n",
      "Hoppity              1\n",
      "Sequencer            1\n",
      "TFix                 1\n",
      "CEDAR                1\n",
      "Transformers         1\n",
      "TransCoder           1\n",
      "Transcoder*          1\n",
      "SDA-Trans            1\n",
      "BERTOverflow         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def model_families_per_year(year):\n",
    "    df_year = df_relevant[df_relevant['year'] == year]\n",
    "    print(f\"{year} - Number of Papers per Model Family:\")\n",
    "    print(df_year['model_families_list'].explode().value_counts())\n",
    "\n",
    "\n",
    "model_families_per_year(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7394dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 - Number of Papers per Model Family:\n",
      "model_families_list\n",
      "CodeBERT           11\n",
      "GPT-3.5             9\n",
      "GPT-4               8\n",
      "CodeT5              8\n",
      "ChatGPT             8\n",
      "CodeGen             8\n",
      "GraphCodeBERT       7\n",
      "UniXcoder           5\n",
      "BERT                5\n",
      "Codex               4\n",
      "RoBERTa             4\n",
      "InCoder             4\n",
      "StarCoder           4\n",
      "Llama               3\n",
      "ChatGLM             3\n",
      "UnixCoder           3\n",
      "PLBART              3\n",
      "T5                  3\n",
      "GPT-3               3\n",
      "GPT-2               3\n",
      "text-davinci        3\n",
      "PolyCoder           3\n",
      "CodeGeeX            2\n",
      "CodeParrot          2\n",
      "UniLog              2\n",
      "GPT-NEO             2\n",
      "Copilot             2\n",
      "Vicuna              2\n",
      "Pythia              2\n",
      "CodeGPT             2\n",
      "Airboros            1\n",
      "code-davinci        1\n",
      "SantaCoder          1\n",
      "WizardCoder         1\n",
      "Sentence-BERT       1\n",
      "GPTBigCode          1\n",
      "seBERT              1\n",
      "VulBERTa            1\n",
      "PDBERT              1\n",
      "ALBERT              1\n",
      "KeyBERT             1\n",
      "LSTM                1\n",
      "TFix                1\n",
      "DISCO               1\n",
      "text-embedding      1\n",
      "Flan                1\n",
      "CodeBERTa           1\n",
      "SynCoBERT           1\n",
      "CodeLlama           1\n",
      "Transformer         1\n",
      "GIN                 1\n",
      "flan-alpaca         1\n",
      "UnifiedQA           1\n",
      "GrammarT5           1\n",
      "GPT-C               1\n",
      "VRepair             1\n",
      "CodeReviewer        1\n",
      "VulMaster           1\n",
      "VulRepair           1\n",
      "PanguCoder          1\n",
      "TypeFix             1\n",
      "CoTexT              1\n",
      "CodeT5+             1\n",
      "AlphaRepair         1\n",
      "PyTER               1\n",
      "CoCoNuT             1\n",
      "LANCE               1\n",
      "IRGen               1\n",
      "Deep-SE             1\n",
      "FAIR                1\n",
      "OSCAR               1\n",
      "sentenceBERT        1\n",
      "GPT2SP              1\n",
      "CodeGen-Mono        1\n",
      "CodeGen-NL          1\n",
      "CodeGen-Multi       1\n",
      "CodeGen2            1\n",
      "PyCodeGPT           1\n",
      "GPT-Code-Clippy     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model_families_per_year(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af84a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 - Number of Papers per Model Family:\n",
      "model_families_list\n",
      "GPT-4                           39\n",
      "GPT-3.5                         35\n",
      "CodeLlama                       25\n",
      "Llama                           14\n",
      "StarCoder                       14\n",
      "CodeBERT                        12\n",
      "DeepSeekCoder                   12\n",
      "CodeGen                          9\n",
      "Claude                           7\n",
      "Gemini                           7\n",
      "CodeT5                           7\n",
      "GraphCodeBERT                    7\n",
      "ChatGPT                          6\n",
      "CodeQwen                         6\n",
      "DeepSeek                         6\n",
      "UniXcoder                        5\n",
      "UnixCoder                        3\n",
      "LineVul                          3\n",
      "WizardCoder                      3\n",
      "ChatGLM                          3\n",
      "Mistral                          3\n",
      "Gemma                            3\n",
      "RoBERTa                          3\n",
      "InCoder                          3\n",
      "Codestral                        2\n",
      "Qwen                             2\n",
      "CodeT5+                          2\n",
      "CodeGemma                        2\n",
      "GPT3.5                           2\n",
      "OpenDevin                        2\n",
      "CodeGPT                          2\n",
      "Incoder                          2\n",
      "text-embedding                   2\n",
      "Phi                              2\n",
      "GPT-3                            2\n",
      "AthenTest                        1\n",
      "ChatDev                          1\n",
      "SVulD                            1\n",
      "Code-davinci                     1\n",
      "Multi-Turn Program Synthesis     1\n",
      "GPT4                             1\n",
      "AgentCoder                       1\n",
      "Self-collaboration               1\n",
      "Copilot                          1\n",
      "AutoGPT                          1\n",
      "MetaGPT                          1\n",
      "Magicoder                        1\n",
      "CoditT5                          1\n",
      "Unixcoder                        1\n",
      "Longformer                       1\n",
      "Shipwright                       1\n",
      "MagiCoder                        1\n",
      "TransCoder                       1\n",
      "Parfum                           1\n",
      "UniTrans                         1\n",
      "SantaCoder                       1\n",
      "ALL-MINILM-L6-V210               1\n",
      "CodeBert                         1\n",
      "TOGA                             1\n",
      "Poro                             1\n",
      "BERT                             1\n",
      "SEQ Graph& HYBRID                1\n",
      "Devign                           1\n",
      "VULGEN                           1\n",
      "COME                             1\n",
      "CCT5                             1\n",
      "NNGen                            1\n",
      "ReVeal                           1\n",
      "Mixtral                          1\n",
      "VGX                              1\n",
      "LILAC                            1\n",
      "LLM-Parser                       1\n",
      "Starcoder                        1\n",
      "GPTSniffer                       1\n",
      "FitRepair                        1\n",
      "ChatRepair                       1\n",
      "RAP-Gen                          1\n",
      "AlphaRe-pair                     1\n",
      "GLTR                             1\n",
      "Sapling                          1\n",
      "OpenCodeInterpreter              1\n",
      "Stable-Code                      1\n",
      "BigBird                          1\n",
      "ContraBERT                       1\n",
      "CuBERT                           1\n",
      "VulBERTa                         1\n",
      "ChatUniTest                      1\n",
      "TestGen-LLM                      1\n",
      "RustAssistant                    1\n",
      "Sonnet                           1\n",
      "GPTZero                          1\n",
      "GPT-2 Output Detector            1\n",
      "DetectGPT                        1\n",
      "Repilot                          1\n",
      "Aider                            1\n",
      "AppMap Naive                     1\n",
      "AutoCodeRover                    1\n",
      "SWE-Agent                        1\n",
      "Vercel                           1\n",
      "Agentless                        1\n",
      "TitanFuzz                        1\n",
      "Moatless Tools                   1\n",
      "HedgeCode                        1\n",
      "GPT-4, CodeBERT                  1\n",
      "Codex                            1\n",
      "SYNCOBERT                        1\n",
      "CoCoSoDa                         1\n",
      "CodeRetriever                    1\n",
      "LLama                            1\n",
      "FuzzGPT                          1\n",
      "CodeShell                        1\n",
      "PLBART                           1\n",
      "Pythia                           1\n",
      "OPT                              1\n",
      "Exlong                           1\n",
      "DeBERTa                          1\n",
      "CodeParrot                       1\n",
      "CAT-LM                           1\n",
      "PolyCoder                        1\n",
      "StarChat                         1\n",
      "PaLM                             1\n",
      "Vicuna                           1\n",
      "Guanaco                          1\n",
      "Tulu                             1\n",
      "GPT3-5                           1\n",
      "StableCode                       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model_families_per_year(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb637d",
   "metadata": {},
   "source": [
    "## Targeted Programming Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b053fa88",
   "metadata": {},
   "source": [
    "### Which Programming Languages are Evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "befe399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall - Number of Papers per Programming Language:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "programming_languages_list\n",
       "Java           67\n",
       "Python         56\n",
       "C              30\n",
       "C++            23\n",
       "JavaScript     13\n",
       "PHP            10\n",
       "Go              9\n",
       "NM              8\n",
       "Rust            7\n",
       "Ruby            7\n",
       "C#              5\n",
       "Kotlin          3\n",
       "SQL             3\n",
       "R               2\n",
       "TypeScript      2\n",
       "Haskell         2\n",
       "Objective-C     2\n",
       "Scala           2\n",
       "Swift           2\n",
       "Prolog          1\n",
       "Erlang          1\n",
       "Solidity        1\n",
       "Bash            1\n",
       "CSharp          1\n",
       "Perl            1\n",
       "SCRATCH         1\n",
       "HTML            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relevant[\"programming_languages_list\"] = df_relevant['programming_language'].apply(\n",
    "    lambda x: [lang.strip() for lang in str(\n",
    "        x).split(';')] if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "print(\"Overall - Number of Papers per Programming Language:\")\n",
    "df_relevant[\"programming_languages_list\"].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b152bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Number of Papers per Programming Language:\n",
      "programming_languages_list\n",
      "Java          14\n",
      "Python         9\n",
      "C              7\n",
      "JavaScript     4\n",
      "PHP            4\n",
      "C++            2\n",
      "NM             2\n",
      "Ruby           2\n",
      "Go             2\n",
      "SCRATCH        1\n",
      "C#             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def programming_languages_per_year(year):\n",
    "    df_year = df_relevant[df_relevant['year'] == year]\n",
    "    print(f\"{year} - Number of Papers per Programming Language:\")\n",
    "    print(df_year['programming_languages_list'].explode().value_counts())\n",
    "\n",
    "\n",
    "programming_languages_per_year(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "445eec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 - Number of Papers per Programming Language:\n",
      "programming_languages_list\n",
      "Java           22\n",
      "Python         18\n",
      "C              11\n",
      "C++             9\n",
      "Go              4\n",
      "Ruby            3\n",
      "JavaScript      3\n",
      "PHP             3\n",
      "Rust            3\n",
      "C#              3\n",
      "Kotlin          3\n",
      "Scala           2\n",
      "SQL             2\n",
      "NM              1\n",
      "CSharp          1\n",
      "Solidity        1\n",
      "Bash            1\n",
      "Swift           1\n",
      "Objective-C     1\n",
      "Perl            1\n",
      "R               1\n",
      "TypeScript      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "programming_languages_per_year(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c8f8151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 - Number of Papers per Programming Language:\n",
      "programming_languages_list\n",
      "Java           31\n",
      "Python         29\n",
      "C              12\n",
      "C++            12\n",
      "JavaScript      6\n",
      "NM              5\n",
      "Rust            4\n",
      "Go              3\n",
      "PHP             3\n",
      "Ruby            2\n",
      "Haskell         2\n",
      "C#              1\n",
      "TypeScript      1\n",
      "R               1\n",
      "Objective-C     1\n",
      "Swift           1\n",
      "Erlang          1\n",
      "Prolog          1\n",
      "SQL             1\n",
      "HTML            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "programming_languages_per_year(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28521274",
   "metadata": {},
   "source": [
    "### Number of Programming Languages Evaluated per Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcd7cabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall - Distribution of Number of Programming Languages per Paper:\n",
      "programming_languages_list\n",
      "1     81\n",
      "0     48\n",
      "2     24\n",
      "3     10\n",
      "6      4\n",
      "4      3\n",
      "10     2\n",
      "5      2\n",
      "16     1\n",
      "7      1\n",
      "13     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Papers covering multiple programming languages: 48\n",
      "Percentage covering multiple programming languages: 27.1%\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall - Distribution of Number of Programming Languages per Paper:\")\n",
    "print(df_relevant[\"programming_languages_list\"].apply(len).value_counts())\n",
    "print(\n",
    "    f\"\\nPapers covering multiple programming languages: {(df_relevant['programming_languages_list'].apply(len) > 1).sum()}\")\n",
    "print(\n",
    "    f\"Percentage covering multiple programming languages: {(df_relevant['programming_languages_list'].apply(len) > 1).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ace3627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Distribution of Number of Programming Languages per Paper:\n",
      "programming_languages_list\n",
      "1    13\n",
      "0     9\n",
      "2     5\n",
      "4     1\n",
      "6     1\n",
      "7     1\n",
      "5     1\n",
      "3     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Papers covering multiple programming languages: 10\n",
      "Percentage covering multiple programming languages: 31.2%\n"
     ]
    }
   ],
   "source": [
    "def programming_language_distribution_and_multi_language_stats(year):\n",
    "    year_df = df_relevant[df_relevant['year'] == year]\n",
    "    print(f\"{year} - Distribution of Number of Programming Languages per Paper:\")\n",
    "    print(year_df[\"programming_languages_list\"].apply(len).value_counts())\n",
    "    print(\n",
    "        f\"\\nPapers covering multiple programming languages: {(year_df['programming_languages_list'].apply(len) > 1).sum()}\")\n",
    "    print(\n",
    "        f\"Percentage covering multiple programming languages: {(year_df['programming_languages_list'].apply(len) > 1).mean()*100:.1f}%\")\n",
    "\n",
    "\n",
    "programming_language_distribution_and_multi_language_stats(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f7b0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024 - Distribution of Number of Programming Languages per Paper:\n",
      "programming_languages_list\n",
      "1     22\n",
      "0     15\n",
      "2     10\n",
      "3      3\n",
      "5      1\n",
      "6      1\n",
      "4      1\n",
      "16     1\n",
      "13     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Papers covering multiple programming languages: 18\n",
      "Percentage covering multiple programming languages: 32.7%\n"
     ]
    }
   ],
   "source": [
    "programming_language_distribution_and_multi_language_stats(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08a91060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 - Distribution of Number of Programming Languages per Paper:\n",
      "programming_languages_list\n",
      "1     46\n",
      "0     24\n",
      "2      9\n",
      "3      6\n",
      "6      2\n",
      "10     2\n",
      "4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Papers covering multiple programming languages: 20\n",
      "Percentage covering multiple programming languages: 22.2%\n"
     ]
    }
   ],
   "source": [
    "programming_language_distribution_and_multi_language_stats(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a2df8",
   "metadata": {},
   "source": [
    "# RQ2 - How well do authors tackle the problem of data leakage/contamination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2910977a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall - Contamination reported in 58 out of 177 papers (32.8%)\n"
     ]
    }
   ],
   "source": [
    "contamination_reported = df_relevant['contamination'].sum()\n",
    "\n",
    "print(\n",
    "    f\"Overall - Contamination reported in {contamination_reported} out of {df_relevant.shape[0]} papers ({(contamination_reported/df_relevant.shape[0])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adc08c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Contamination reported in 6 out of 32 papers (18.8%)\n",
      "2024 - Contamination reported in 14 out of 55 papers (25.5%)\n",
      "2025 - Contamination reported in 38 out of 90 papers (42.2%)\n"
     ]
    }
   ],
   "source": [
    "def contamination_reported_per_year(year):\n",
    "    year_df = df_relevant[df_relevant['year'] == year]\n",
    "    contamination_reported_year = year_df['contamination'].sum()\n",
    "    print(\n",
    "        f\"{year} - Contamination reported in {contamination_reported_year} out of {year_df.shape[0]} papers ({(contamination_reported_year/year_df.shape[0])*100:.1f}%)\")\n",
    "\n",
    "\n",
    "contamination_reported_per_year(2023)\n",
    "contamination_reported_per_year(2024)\n",
    "contamination_reported_per_year(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c44a07e",
   "metadata": {},
   "source": [
    "# RQ3 - How replicable are LLM-based studies?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9643c0df",
   "metadata": {},
   "source": [
    "## Model Configuration Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06e1f22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall - Number of Papers Reporting on Inference (Generation) Configuration/Parameters:\n",
      "89 out of 177 papers (50.3%)\n"
     ]
    }
   ],
   "source": [
    "df_relevant[\"model_config_list\"] = df_relevant['model_config'].apply(\n",
    "    lambda x: [config.strip() for config in str(\n",
    "        x).split(';')] if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "print(\"Overall - Number of Papers Reporting on Inference (Generation) Configuration/Parameters:\")\n",
    "num_reporting_inference_config = df_relevant[df_relevant['model_config_list'].apply(\n",
    "    lambda x: 'inference' in [cfg.lower() for cfg in x])].shape[0]\n",
    "print(\n",
    "    f\"{num_reporting_inference_config} out of {df_relevant.shape[0]} papers ({(num_reporting_inference_config/df_relevant.shape[0])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10003378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Number of Papers Reporting on Inference (Generation) Configuration/Parameters: 10 out of 32 papers (31.2%)\n",
      "2024 - Number of Papers Reporting on Inference (Generation) Configuration/Parameters: 27 out of 55 papers (49.1%)\n",
      "2025 - Number of Papers Reporting on Inference (Generation) Configuration/Parameters: 52 out of 90 papers (57.8%)\n"
     ]
    }
   ],
   "source": [
    "num_reporting_inference_config_2023 = df_relevant[df_relevant['model_config_list'].apply(\n",
    "    lambda x: 'inference' in [cfg.lower() for cfg in x]) & (df_relevant['year'] == 2023)].shape[0]\n",
    "print(\n",
    "    f\"2023 - Number of Papers Reporting on Inference (Generation) Configuration/Parameters: {num_reporting_inference_config_2023} out of {df_relevant[df_relevant['year'] == 2023].shape[0]} papers ({(num_reporting_inference_config_2023/df_relevant[df_relevant['year'] == 2023].shape[0])*100:.1f}%)\")\n",
    "\n",
    "num_reporting_inference_config_2024 = df_relevant[df_relevant['model_config_list'].apply(\n",
    "    lambda x: 'inference' in [cfg.lower() for cfg in x]) & (df_relevant['year'] == 2024)].shape[0]\n",
    "print(\n",
    "    f\"2024 - Number of Papers Reporting on Inference (Generation) Configuration/Parameters: {num_reporting_inference_config_2024} out of {df_relevant[df_relevant['year'] == 2024].shape[0]} papers ({(num_reporting_inference_config_2024/df_relevant[df_relevant['year'] == 2024].shape[0])*100:.1f}%)\")\n",
    "\n",
    "num_reporting_inference_config_2025 = df_relevant[df_relevant['model_config_list'].apply(\n",
    "    lambda x: 'inference' in [cfg.lower() for cfg in x]) & (df_relevant['year'] == 2025)].shape[0]\n",
    "print(\n",
    "    f\"2025 - Number of Papers Reporting on Inference (Generation) Configuration/Parameters: {num_reporting_inference_config_2025} out of {df_relevant[df_relevant['year'] == 2025].shape[0]} papers ({(num_reporting_inference_config_2025/df_relevant[df_relevant['year'] == 2025].shape[0])*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6532ca",
   "metadata": {},
   "source": [
    "## Artefact Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011bcc7",
   "metadata": {},
   "source": [
    "### Artifact Badges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c8bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Papers with Artifact Available Badge: 33 out of 177 papers (18.6%)\n",
      "Non-Relevant Papers with Artifact Available Badge: 213 out of 515 papers (41.4%)\n",
      "\n",
      "Relevant Papers with Artifact Reusable Badge: 21 out of 177 papers (11.9%)\n",
      "Non-Relevant Papers with Artifact Reusable Badge: 150 out of 515 papers (29.1%)\n",
      "\n",
      "Relevant Papers with Artifact Functional Badge: 13 out of 177 papers (7.3%)\n",
      "Non-Relevant Papers with Artifact Functional Badge: 70 out of 515 papers (13.6%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_artifact_badge_relevant_vs_non_relevant(col, name):\n",
    "    relevant_with_badge = df_relevant[df_relevant[col] == True].shape[0]\n",
    "    non_relevant_with_badge = df_non_relevant[df_non_relevant[col]\n",
    "                                              == True].shape[0]\n",
    "    print(\n",
    "        f\"Relevant Papers with {name}: {relevant_with_badge} out of {df_relevant.shape[0]} papers ({(relevant_with_badge/df_relevant.shape[0])*100:.1f}%)\")\n",
    "    print(\n",
    "        f\"Non-Relevant Papers with {name}: {non_relevant_with_badge} out of {df_non_relevant.shape[0]} papers ({(non_relevant_with_badge/df_non_relevant.shape[0])*100:.1f}%)\")\n",
    "\n",
    "\n",
    "badge_columns = [\n",
    "    ('artifact_available', 'Artifact Available Badge'),\n",
    "    ('artifact_reusable', 'Artifact Reusable Badge'),\n",
    "    ('artifact_functional', 'Artifact Functional Badge')\n",
    "]\n",
    "\n",
    "for col, name in badge_columns:\n",
    "    compare_artifact_badge_relevant_vs_non_relevant(col, name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c165955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 - Artifact Available Badge for 6 out of 32 Relevant Papers (18.8%)\n",
      "2023 - Artifact Reusable Badge for 3 out of 32 Relevant Papers (9.4%)\n",
      "2023 - Artifact Functional Badge for 1 out of 32 Relevant Papers (3.1%)\n",
      "\n",
      "2024 - Artifact Available Badge for 9 out of 55 Relevant Papers (16.4%)\n",
      "2024 - Artifact Reusable Badge for 8 out of 55 Relevant Papers (14.5%)\n",
      "2024 - Artifact Functional Badge for 0 out of 55 Relevant Papers (0.0%)\n",
      "\n",
      "2025 - Artifact Available Badge for 18 out of 90 Relevant Papers (20.0%)\n",
      "2025 - Artifact Reusable Badge for 10 out of 90 Relevant Papers (11.1%)\n",
      "2025 - Artifact Functional Badge for 12 out of 90 Relevant Papers (13.3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def artifact_badges_per_year(year, col, name):\n",
    "    year_df = df_relevant[df_relevant['year'] == year]\n",
    "    artifact_year = year_df[col].sum()\n",
    "    print(\n",
    "        f\"{year} - {name} for {artifact_year} out of {year_df.shape[0]} Relevant Papers ({(artifact_year/year_df.shape[0])*100:.1f}%)\")\n",
    "\n",
    "\n",
    "years = [2023, 2024, 2025]\n",
    "\n",
    "badge_columns = [\n",
    "    ('artifact_available', 'Artifact Available Badge'),\n",
    "    ('artifact_reusable', 'Artifact Reusable Badge'),\n",
    "    ('artifact_functional', 'Artifact Functional Badge')\n",
    "]\n",
    "\n",
    "for year in years:\n",
    "    for col, name in badge_columns:\n",
    "        artifact_badges_per_year(year, col, name)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e352c5b",
   "metadata": {},
   "source": [
    "### Manual Artefact Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70c734c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall - Number of Papers with Artefacts (Manual Check): 144 out of 177 (81.4%)\n",
      "Overall - Number of Papers with no Artefact (Manual Check): 24 out of 177 (13.6%)\n",
      "Overall - Number of Papers with Dead Links (Manual Check): 9 out of 177 (5.1%)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"\\nOverall - Number of Papers with Artefacts (Manual Check): {df_relevant[df_relevant['artefact_manual'] == True].shape[0]} out of {df_relevant.shape[0]} ({(df_relevant[df_relevant['artefact_manual'] == True].shape[0] / df_relevant.shape[0]) * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"Overall - Number of Papers with no Artefact (Manual Check): {df_relevant[df_relevant['artefact_manual'] == False].shape[0]} out of {df_relevant.shape[0]} ({(df_relevant[df_relevant['artefact_manual'] == False].shape[0] / df_relevant.shape[0]) * 100:.1f}%)\")\n",
    "print(\n",
    "    f\"Overall - Number of Papers with Dead Links (Manual Check): {df_relevant[df_relevant['artefact_manual'] == 'DEAD'].shape[0]} out of {df_relevant.shape[0]} ({(df_relevant[df_relevant['artefact_manual'] == 'DEAD'].shape[0] / df_relevant.shape[0]) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3b3a3d",
   "metadata": {},
   "source": [
    "### Number of Papers with Artifact Badges that have Dead Links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28dcc2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers with Artifact Available Badges but DEAD links: 2\n",
      "Number of papers with Artifact Reusable Badges but DEAD links: 1\n",
      "Number of papers with Artifact Functional Badges but DEAD links: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of papers with Artifact Available Badges but DEAD links:\", df_relevant[(\n",
    "    df_relevant['artefact_manual'] == 'DEAD') & (df_relevant['artifact_available'])].shape[0])\n",
    "print(\"Number of papers with Artifact Reusable Badges but DEAD links:\", df_relevant[(\n",
    "    df_relevant['artefact_manual'] == 'DEAD') & (df_relevant['artifact_reusable'])].shape[0])\n",
    "print(\"Number of papers with Artifact Functional Badges but DEAD links:\", df_relevant[(\n",
    "    df_relevant['artefact_manual'] == 'DEAD') & (df_relevant['artifact_functional'])].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132cf7b0",
   "metadata": {},
   "source": [
    "# RQ4 - What are the costs of LLM-based SE research?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10156e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of Different Costs Reported Across All Papers:\n",
      "cost_list\n",
      "gpu            78\n",
      "time           68\n",
      "-              48\n",
      "money          18\n",
      "content        13\n",
      "hw             10\n",
      "memory          6\n",
      "invocations     3\n",
      "tpu             2\n",
      "tokens          1\n",
      "operations      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Frequency of Different Costs Reported Across All Papers:\")\n",
    "import regex as re\n",
    "df_relevant['cost_list'] = df_relevant['cost'].apply(\n",
    "    lambda x: [task.strip() for task in re.split(';|,', str(x))] if pd.notna(x) else []\n",
    ")\n",
    "\n",
    "print(df_relevant['cost_list'].explode().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9832f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Papers Reporting both Time and Hardware: 36\n"
     ]
    }
   ],
   "source": [
    "both = 0\n",
    "for i,row in df_relevant.iterrows():\n",
    "    c = row[\"cost\"]\n",
    "    if \"time\" in c:\n",
    "        if any(x in c for x in [\"gpu\",\"hw\",\"tpu\",\"hardware\"]):\n",
    "            both += 1\n",
    "both\n",
    "\n",
    "print(\"Number of Papers Reporting both Time and Hardware:\", both)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
