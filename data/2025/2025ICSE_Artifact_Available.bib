@inproceedings{10.1109/ICSE55347.2025.00187,
author = {Kong, Ziqiao and Li, Shaohua and Huang, Heqing and Su, Zhendong},
title = {Sand: Decoupling Sanitization from Fuzzing for Low Overhead},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00187},
doi = {10.1109/ICSE55347.2025.00187},
abstract = {Sanitizers provide robust test oracles for various vulnerabilities. Fuzzing on sanitizer-enabled programs has been the best practice to find software bugs. Since sanitizers require heavy program instrumentation to insert run-time checks, sanitizer-enabled programs have much higher overhead compared to normally built programs.In this paper, we present Sand, a new fuzzing framework that decouples sanitization from the fuzzing loop. Sand performs fuzzing on a normally built program and only invokes the sanitizer-enabled program when input is shown to be interesting. Since most of the generated inputs are not interesting, i.e., not bug-triggering, Sand allows most of the fuzzing time to be spent on the normally built program. We further introduce execution pattern to practically and effectively identify interesting inputs.We implement Sand on top of AFL++ and evaluate it on 20 real-world programs. Our extensive evaluation highlights its effectiveness: in 24 hours, compared to all the baseline fuzzers, Sand significantly discovers more bugs while not missing any.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {255–267},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00185,
author = {Sens, Yorick and Knopp, Henriette and Peldszus, Sven and Berger, Thorsten},
title = {A Large-Scale Study of Model Integration in ML-Enabled Software Systems},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00185},
doi = {10.1109/ICSE55347.2025.00185},
abstract = {The rise of machine learning (ML) and its integration into software systems has drastically changed development practices. While software engineering traditionally focused on manually created code artifacts with dedicated processes and architectures, ML-enabled systems require additional data-science methods and tools to create ML artifacts—especially ML models and training data. However, integrating models into systems, and managing the many different artifacts involved, is far from trivial. ML-enabled systems can easily have multiple ML models that interact with each other and with traditional code in intricate ways. Unfortunately, while challenges and practices of building ML-enabled systems have been studied, little is known about the characteristics of real-world ML-enabled systems beyond isolated examples. Improving engineering processes and architectures for ML-enabled systems requires improving the empirical understanding of these systems.We present a large-scale study of 2,928 open-source ML-enabled software systems. We classified and analyzed them to determine system characteristics, model and code reuse practices, and architectural aspects of integrating ML models. Our findings show that these systems still mainly consist of traditional source code, and that ML model reuse through code duplication or pre-trained models is common. We also identified different ML integration patterns and related implementation practices. We hope that our results help improve practices for integrating ML models, bringing data science and software engineering closer together.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1165–1177},
numpages = {13},
keywords = {machine learning, AI engineering, SE4AI},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00183,
author = {Kokkonis, Dimitri and Marcozzi, Micha\"{e}l and Decoux, Emilien and Zacchiroli, Stefano},
title = {Rosa: Finding Backdoors with Fuzzing},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00183},
doi = {10.1109/ICSE55347.2025.00183},
abstract = {A code-level backdoor is a hidden access, programmed and concealed within the code of a program. For instance, hard-coded credentials planted in the code of a file server application would enable maliciously logging into all deployed instances of this application. Confirmed software supply-chain attacks have led to the injection of backdoors into popular open-source projects, and backdoors have been discovered in various router firmware. Manual code auditing for backdoors is challenging and existing semi-automated approaches can handle only a limited scope of programs and backdoors, while requiring manual reverse-engineering of the audited (binary) program. Graybox fuzzing (automated semi-randomized testing) has grown in popularity due to its success in discovering vulnerabilities and hence stands as a strong candidate for improved backdoor detection. However, current fuzzing knowledge does not offer any means to detect the triggering of a backdoor at runtime.In this work we introduce Rosa, a novel approach (and tool) which combines a state-of-the-art fuzzer (AFL++) with a new metamorphic test oracle, capable of detecting runtime backdoor triggers. To facilitate the evaluation of Rosa, we have created Rosarum, the first openly available benchmark for assessing the detection of various backdoors in diverse programs. Experimental evaluation shows that Rosa has a level of robustness, speed and automation similar to classical fuzzing. It finds all 17 authentic or synthetic backdooors from Rosarum in 1h30 on average. Compared to existing detection tools, it can handle a diversity of backdoors and programs and it does not rely on manual reverse-engineering of the fuzzed binary code.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2816–2828},
numpages = {13},
keywords = {fuzzing, dynamic analysis, metamorphic testing, backdoors, vulnerability detection},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00170,
author = {Shamim, Shazibul Islam and Hu, Hanyang and Rahman, Akond},
title = {On Prescription or Off Prescription? An Empirical Study of Community-Prescribed Security Configurations for Kubernetes},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00170},
doi = {10.1109/ICSE55347.2025.00170},
abstract = {Despite being beneficial for rapid delivery of software, Kubernetes deployments can be susceptible to security attacks, which can cause serious consequences. A systematic characterization of how community-prescribed security configurations, i.e., security configurations that are recommended by security experts, can aid practitioners to secure their Kubernetes deployments. To that end, we conduct an empirical study with 53 security configurations recommended by the Center for Internet Security (CIS), 20 survey respondents, and 544 configuration files obtained from the open source software (OSS) and proprietary domains.From our empirical study, we observe: (i) practitioners can be unaware of prescribed security configurations as 5% ~40% of the survey respondents are unfamiliar with 16 prescribed configurations; and (ii) for Company-A and OSS respectively, 18.0% and 17.9% of the configuration files include at least one violation of prescribed configurations. From our evaluation with 5 static application security testing (SAST) tools we find (i) only Kubescape to support all of the prescribed security configuration categories; (ii) the highest observed precision to be 0.41 and 0.43 respectively, for the Company-A and OSS datasets; and (iii) the highest observed recall to be respectively, 0.53 and 0.65 for the Company-A and OSS datasets. Our findings show a disconnect between what CIS experts recommend for Kubernetes-related configurations and what happens in practice. We conclude the paper by providing recommendations for practitioners and researchers. Dataset used for the paper is publicly available online.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2432–2444},
numpages = {13},
keywords = {configuration, container orchestration, devops, devsecops, empirical study, kubernetes, security, static analysis},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00159,
author = {She, Yining and Biswas, Sumon and K\"{a}stner, Christian and Kang, Eunsuk},
title = {FairSense: Long-Term Fairness Analysis of ML-Enabled Systems},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00159},
doi = {10.1109/ICSE55347.2025.00159},
abstract = {Algorithmic fairness of machine learning (ML) models has raised significant concern in the recent years. Many testing, verification, and bias mitigation techniques have been proposed to identify and reduce fairness issues in ML models. The existing methods are model-centric and designed to detect fairness issues under static settings. However, many ML-enabled systems operate in a dynamic environment where the predictive decisions made by the system impact the environment, which in turn affects future decision-making. Such a self-reinforcing feedback loop can cause fairness violations in the long term, even if the immediate outcomes are fair. In this paper, we propose a simulation-based framework called FairSense to detect and analyze long-term unfairness in ML-enabled systems. Given a fairness requirement, FairSense performs Monte-Carlo simulation to enumerate evolution traces for each system configuration. Then, FairSense performs sensitivity analysis on the space of possible configurations to understand the impact of design options and environmental factors on the long-term fairness of the system. We demonstrate FairSense's potential utility through three real-world case studies: Loan lending, opioids risk scoring, and predictive policing.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {782–794},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00147,
author = {Wu, Mengying and Hong, Geng and Mai, Wuyuao and Wu, Xinyi and Zhang, Lei and Pu, Yingyuan and Chai, Huajun and Ying, Lingyun and Duan, Haixin and Yang, Min},
title = {Exposing the Hidden Layer: Software Repositories in the Service of SEO Manipulation},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00147},
doi = {10.1109/ICSE55347.2025.00147},
abstract = {Distinct from traditional malicious packages, this paper uncovers a novel attack vector named "blackhat Search Engine Optimization through REPositories (RepSEO)". In this approach, attackers carefully craft packages to manipulate search engine results, exploiting the credibility of software repositories to promote illicit websites.Our research presents a systematic analysis of the underground ecosystem of RepSEO, identifying key players such as account providers, advertisers, and publishers. We developed an effective detection tool, applied to a ten-year large-scale dataset of npm, Docker Hub, and NuGet software repositories. This investigation led to the startling discovery of 3,801,682 abusive packages, highlighting the widespread nature of this attack. Our study also delves into the supply chain tactics of these attacks, revealing strategies like the use of self-hosted email services for account registration, redirection methods to obscure landing pages, and rapid deployment techniques by aggressive attackers. Additionally, we explore the profit motives behind these attacks, identifying two primary types of advertisers: survey-based advertisers and malware distribution advertisers. We reported npm, NuGet, and Docker Hub about the RepSEO packages and the related supply chain vulnerabilities of Google, and received their acknowledgments. Software repositories have started removing the abusive packages as of this paper's submission. We also open-source our code and data to facilitate future research.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2100–2112},
numpages = {13},
keywords = {software repository, blackhat SEO, supply chain vulnerability},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00136,
author = {Benedetti, Giacomo and Solarin, Oreofe and Miller, Courtney and Tystahl, Greg and Enck, William and K\"{a}stner, Christian and Kapravelos, Alexandros and Merlo, Alessio and Verderame, Luca},
title = {An Empirical Study on Reproducible Packaging in Open-Source Ecosystems},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00136},
doi = {10.1109/ICSE55347.2025.00136},
abstract = {The integrity of software builds is fundamental to the security of the software supply chain. While Thompson first raised the potential for attacks on build infrastructure in 1984, limited attention has been given to build integrity in the past 40 years, enabling recent attacks on SolarWinds, event-stream, and xz. The best-known defense against build system attacks is creating reproducible builds; however, achieving them can be complex for both technical and social reasons and thus is often viewed as impractical to obtain. In this paper, we analyze reproducibility of builds in a novel context: reusable components distributed as packages in six popular software ecosystems (npm, Maven, PyPI, Go, RubyGems, and Cargo). Our quantitative study on a representative sample of 4000 packages in each ecosystem raises concerns: Rates of reproducible builds vary widely between ecosystems, with some ecosystems having all packages reproducible whereas others have reproducibility issues in nearly every package. However, upon deeper investigation, we identified that with relatively straightforward infrastructure configuration and patching of build tools, we can achieve very high rates of reproducible builds in all studied ecosystems. We conclude that if the ecosystems adopt our suggestions, the build process of published packages can be independently confirmed for nearly all packages without individual developer actions, and doing so will prevent significant future software supply chain attacks.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1052–1063},
numpages = {12},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00124,
author = {Gomes, L\'{u}\i{}s F. and Hellendoorn, Vincent J. and Aldrich, Jonathan and Abreu, Rui},
title = {An Exploratory Study of ML Sketches and Visual Code Assistants},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00124},
doi = {10.1109/ICSE55347.2025.00124},
abstract = {This paper explores the integration of Visual Code Assistants in Integrated Development Environments (IDEs). In Software Engineering, whiteboard sketching is often the initial step before coding, serving as a crucial collaboration tool for developers. Previous studies have investigated patterns in SE sketches and how they are used in practice, yet methods for directly using these sketches for code generation remain limited. The emergence of visually-equipped large language models presents an opportunity to bridge this gap, which is the focus of our research. In this paper, we built a first prototype of a Visual Code Assistant to get user feedback regarding in-IDE sketch-to-code tools. We conduct an experiment with 19 data scientists, most of whom regularly sketch as part of their job. We investigate developers' mental models by analyzing patterns commonly observed in their sketches when developing an ML workflow. Analysis indicates that diagrams were the preferred organizational component (52.6%), often accompanied by lists (42.1%) and numbered points (36.8%). Our tool converts their sketches into a Python notebook by querying an LLM. We use an LLM-as-judge setup to score the quality of the generated code, finding that even brief sketching can effectively generate useful code outlines. We also find a positive correlation between sketch time and the quality of the generated code. We conclude the study by conducting extensive interviews to assess the tool's usefulness, explore potential use cases, and understand developers' needs. As noted by participants, promising applications for these assistants include education, prototyping, and collaborative settings. Our findings signal promise for the next generation of Code Assistants to integrate visual information, both to improve code generation and to better leverage developers' existing sketching practices.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1653–1664},
numpages = {12},
keywords = {AI4SE, code generation, visual programming, sketching, machine learning, tool development, human-AI interaction},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00036,
author = {Thomas, Deepak-George and Biagiola, Matteo and Humbatova, Nargiz and Wardat, Mohammad and Jahangirova, Gunel and Rajan, Hridesh and Tonella, Paolo},
title = {μPRL: A Mutation Testing Pipeline for Deep Reinforcement Learning Based on Real Faults},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00036},
doi = {10.1109/ICSE55347.2025.00036},
abstract = {Reinforcement Learning (RL) is increasingly adopted to train agents that can deal with complex sequential tasks, such as driving an autonomous vehicle or controlling a humanoid robot. Correspondingly, novel approaches are needed to ensure that RL agents have been tested adequately before going to production. Among them, mutation testing is quite promising, especially under the assumption that the injected faults (mutations) mimic the real ones.In this paper, we first describe a taxonomy of real RL faults obtained by repository mining. Then, we present the mutation operators derived from such real faults and implemented in the tool μPRL. Finally, we discuss the experimental results, showing that μPRL is effective at discriminating strong from weak test generators, hence providing useful feedback to developers about the adequacy of the generated test scenarios.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2238–2250},
numpages = {13},
keywords = {reinforcement learning, mutation testing, real faults},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00020,
author = {Zhang, Wen and Xiao, Botang and Kong, Qingchen and Guan, Le and Wang, Wenwen},
title = {BSan: A Powerful Identifier-Based Hardware-Independent Memory Error Detector for COTS Binaries},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00020},
doi = {10.1109/ICSE55347.2025.00020},
abstract = {This paper presents BSan, a practical software-only memory error detector for binary code. Different from state-of-the-art binary-level detectors, which rely on either the shadow-memory-based approach or the hardware-specific feature and thus suffer from several fundamental limitations, BSan adopts an identifier-based approach, enabling it to detect deep memory errors missed by existing detectors. Also, BSan does not depend on any specific hardware features. To reduce the high performance overhead caused by identifier propagation, BSan creates a novel hybrid approach, static analysis+dynamic instrumentation, to improve the performance without inheriting the poor reliability of static binary rewriting, distinguishing it from existing detectors that simply refer to static binary rewriting for better performance. The comprehensive evaluation demonstrates that BSan can detect more memory errors than state-of-the-art binary-level detectors. Meanwhile, the performance and memory overheads of BSan are comparable to those of existing detectors.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {3085–3096},
numpages = {12},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00227,
author = {Li, Haofeng and Shi, Chenghang and Lu, Jie and Li, Lian and Zhao, Zixuan},
title = {Module-Aware Context Sensitive Pointer Analysis},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00227},
doi = {10.1109/ICSE55347.2025.00227},
abstract = {The Java Platform Module System (JPMS) has found widespread applications since introduced in Java 9. However, existing pointer analyses fail to leverage the semantics of JPMS. This paper presents a novel module-aware approach to improving the performance of pointer analysis. We model the semantics of keywords provides and uses in JPMS to recover missing points-to relations. We design a module-aware context-sensitive analysis, which can propagate and apply critical contexts (by exploiting modularity) to balance precision and efficiency better. We have implemented our module-aware pointer analysis named MPA in Tai-e and conducted extensive experiments to compare it with standard object-sensitivity. The evaluation results demonstrate that MPA finds more reachable methods and enhances existing context-sensitive approaches, striking a good balance between efficiency and precision. MPA can increase the number of reachable methods up to 90.9\texttimes{} (lombok) under the same analysis. Performance-wise, MPA is nearly as fast as context-insensitivity for most benchmarks, while its precision is superior to that of 1-object-sensitivity on average.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1819–1831},
numpages = {13},
keywords = {pointer analysis, context sensitivity, JPMS},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00222,
author = {Hundal, Rajdeep Singh and Xiao, Yan and Cao, Xiaochun and Dong, Jin Song and Rigger, Manuel},
title = {On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00222},
doi = {10.1109/ICSE55347.2025.00222},
abstract = {Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. Furthermore, the performance among the high-performing PPO implementations was found to differ significantly in nine games. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used. In addition, we recommend for (1) replicability studies for studies mistakenly assuming implementation inter-changeability, (2) DRL researchers and practitioners to adopt the differential testing methodology proposed in this paper to combat implementation inconsistencies, and (3) the use of large environment suites.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2225–2237},
numpages = {13},
keywords = {reinforcement learning, differential testing},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00158,
author = {Fratantonio, Yanick and Invernizzi, Luca and Farah, Loua and Thomas, Kurt and Zhang, Marina and Albertini, Ange and Galilee, Francois and Metitieri, Giancarlo and Cretin, Julien and Petit-Bianco, Alex and Tao, David and Bursztein, Elie},
title = {Magika: AI-Powered Content-Type Detection},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00158},
doi = {10.1109/ICSE55347.2025.00158},
abstract = {The task of content-type detection—which entails identifying the data encoded in an arbitrary byte sequence—is critical for operating systems, development, reverse engineering environments, and a variety of security applications. In this paper, we introduce Magika, a novel AI-powered content-type detection tool. Under the hood, Magika employs a deep learning model that can execute on a single CPU with just 1MB of memory to store the model's weights. We show that Magika achieves an average F1 score of 99% across over a hundred content types and a test set of more than 1M files, outperforming all existing content-type detection tools today. To foster adoption and improvements, we open source Magika under an Apache 2 license on GitHub and we make our model and training pipeline publicly available. Our tool has already seen adoption by Gmail and Google Drive for attachment scanning, by VirusTotal to aid with malware analysis, and by prominent open-source projects such as Apache Tika. While this paper focuses on the initial version, Magika continues to evolve with support for over 200 content types now available. The latest developments can be found at https://github.com/google/magika.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2638–2649},
numpages = {12},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00127,
author = {Wu, Xiafa and Demsky, Brian},
title = {GenC2Rust: Towards Generating Generic Rust Code from C},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00127},
doi = {10.1109/ICSE55347.2025.00127},
abstract = {Rust provides an exciting combination of strong safety guarantees and high performance. Many new systems are being implemented in Rust. Nevertheless, there is a large body of existing C code that could greatly benefit from Rust's safety guarantees. Unfortunately, the manual effort required to rewrite C code into Rust is often prohibitively expensive.Researchers have explored tools to assist developers in translating legacy C code into Rust code. However, the mismatch between C abstractions and idiomatic Rust abstractions makes it challenging to automatically utilize Rust's language features, resulting in non-idiomatic Rust code that requires extensive manual effort to further refactor. For example, existing tools often fail to map polymorphic uses of void pointers in C to Rust's generic pointers. In this paper, we present a translation tool, GenC2Rust, that translates non-generic C code into generic Rust code. GenC2Rust statically analyzes the use of void pointers in the C program to compute the typing constraints and then retypes the parametric polymorphic void pointers into generic pointers. We conducted an evaluation of GenC2Rust across 42 C programs that vary in size and span multiple domains to demonstrate its scalability as well as correctness. We discovered GenC2Rust has translated 4,572 void pointers to use generics. We also discuss the limiting factors encountered in the translation process.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {90–102},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00118,
author = {Roque, Enrique Barba and Cruz, Luis and Durieux, Thomas},
title = {Unveiling the Energy Vampires: A Methodology for Debugging Software Energy Consumption},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00118},
doi = {10.1109/ICSE55347.2025.00118},
abstract = {Energy consumption in software systems is becoming increasingly important, especially in large-scale deployments. However, debugging energy-related issues remains challenging due to the lack of specialized tools. This paper presents an energy debugging methodology for identifying and isolating energy consumption hotspots in software systems. We demonstrate the methodology's effectiveness through a case study of Redis, a popular in-memory database. Our analysis reveals significant energy consumption differences between Alpine and Ubuntu distributions, with Alpine consuming up to 20.2% more power in certain operations. We trace this difference to the implementation of the memcpy function in different C standard libraries (musl vs. glibc). By isolating and benchmarking memcpy, we confirm it as the primary cause of the energy discrepancy. Our findings highlight the importance of considering energy efficiency in software dependencies and demonstrate the capability to assist developers in identifying and addressing energy-related issues. This work contributes to the growing field of sustainable software engineering by providing a systematic approach to energy debugging and using it to unveil unexpected energy behaviors in Alpine.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2406–2418},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00059,
author = {Erhabor, Daniel and Udayashankar, Sreeharsha and Nagappan, Meiyappan and Al-Kiswany, Samer},
title = {Measuring the Runtime Performance of C++ Code Written by Humans Using GitHub Copilot},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00059},
doi = {10.1109/ICSE55347.2025.00059},
abstract = {GitHub Copilot is an artificially intelligent programming assistant used by many developers. While a few studies have evaluated the security risks of using Copilot, there has not been any study to show if it aids developers in producing code with better runtime performance. We evaluate the runtime performance of C++ code produced when developers use GitHub Copilot versus when they do not. To this end, we conducted a user study with 32 participants where each participant solved two C++ programming problems, one with Copilot and the other without it and measured the runtime performance of the participants' solutions on our test data. Our results suggest that using Copilot may produce C++ code with (statistically significant) slower runtime performance.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2062–2074},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00033,
author = {Sanchez-Stern, Alex and Varghese, Abhishek and Kaufman, Zhanna and Zhang, Dylan and Ringer, Talia and Brun, Yuriy},
title = {QEDCartographer: Automating Formal Verification Using Reward-Free Reinforcement Learning},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00033},
doi = {10.1109/ICSE55347.2025.00033},
abstract = {Formal verification is a promising method for producing reliable software, but the difficulty of manually writing verification proofs severely limits its utility in practice. Recent methods have automated some proof synthesis by guiding a search through the proof space using a theorem prover. Unfortunately, the theorem prover provides only the crudest estimate of progress, resulting in effectively undirected search. To address this problem, we create QEDCartographer, an automated proof-synthesis tool that combines supervised and reinforcement learning to more effectively explore the proof space. QEDCartographer incorporates the proofs' branching structure, enabling reward-free search and overcoming the sparse reward problem inherent to formal verification. We evaluate QEDCartographer using the CoqGym benchmark of 68.5K theorems from 124 open-source Coq projects. QEDCartographer fully automatically proves 21.4% of the test-set theorems. Previous search-based proof-synthesis tools Tok, Tac, ASTactic, Passport, and Proverbot9001, which rely only on supervised learning, prove 9.6%, 9.8%, 10.9%, 12.5%, and 19.8%, respectively. Diva, which combines 62 tools, proves 19.2%. Comparing to the most effective prior tool, Proverbot9001, QEDCartographer produces 26% shorter proofs 27% faster, on average over the theorems both tools prove. Together, QEDCartographer and non-learning-based CoqHammer prove 31.8% of the theorems, while CoqHammer alone proves 26.6%. Our work demonstrates that reinforcement learning is a fruitful research direction for improving proof-synthesis tools' search mechanisms.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {307–320},
numpages = {14},
keywords = {formal verification, proof assistants, proof synthesis, reinforcement learning},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00032,
author = {Deljouyi, Amirhossein and Koohestani, Roham and Izadi, Maliheh and Zaidman, Andy},
title = {Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00032},
doi = {10.1109/ICSE55347.2025.00032},
abstract = {Automated unit test generators, particularly search-based software testing tools like EvoSuite, are capable of generating tests with high coverage. Although these generators alleviate the burden of writing unit tests, they often pose challenges for software engineers in terms of understanding the generated tests. To address this, we introduce UTGen, which combines search-based software testing and large language models to enhance the understandability of automatically generated test cases. We achieve this enhancement through contextualizing test data, improving identifier naming, and adding descriptive comments. Through a controlled experiment with 32 participants from both academia and industry, we investigate how the understandability of unit tests affects a software engineer's ability to perform bug-fixing tasks. We selected bug-fixing to simulate a real-world scenario that emphasizes the importance of understandable test cases. We observe that participants working on assignments with UTGen test cases fix up to 33% more bugs and use up to 20% less time when compared to baseline test cases. From the post-test questionnaire, we gathered that participants found that enhanced test names, test data, and variable names improved their bug-fixing process.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1449–1461},
numpages = {13},
keywords = {automated test generation, large language models, unit testing, readability, understandability},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00239,
author = {Sherman, Gabriel and Nagy, Stefan},
title = {No Harness, No Problem: Oracle-Guided Harnessing for Auto-Generating C API Fuzzing Harnesses},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00239},
doi = {10.1109/ICSE55347.2025.00239},
abstract = {Library APIs are used by virtually every modern application and system, making them among today's most security-critical software. In recent years, library bug-finding efforts have overwhelmingly adopted the powerful testing strategy of coverage-guided fuzzing. At its core, API fuzzing operates on harnesses: wrapper programs that initialize an API before feeding random inputs to its functions. Successful fuzzing demands correct and thorough harnesses, making manual harnessing challenging without sufficient domain expertise. To overcome this, recent strategies propose "learning" libraries' intended usage to automatically generate their fuzzing harnesses. Yet, despite their high code coverage, resulting harnesses frequently miss key API semantics—bringing with them invalid, unrealistic, or otherwise-impossible data and call sequences—derailing fuzzing with false-positive crashes. Thus, without a precise, semantically-correct harnessing, many critical APIs will remain beyond fuzzing's reach—leaving their hidden vulnerabilities ripe for attackers.This paper introduces Oracle-guided Harnessing: a technique for fully-automatic, semantics-aware API fuzzing harness synthesis. At a high level, Oracle-guided Harnessing mimics the trial-and-error process of manual harness creation—yet automates it via fuzzing. Specifically, we leverage information from API headers to mutationally stitch-together candidate harnesses; and evaluate their validity via a set of Correctness Oracles: compilation, execution, and changes in coverage. By keeping—and further mutating—only correct candidates, our approach produces a diverse set of semantically-correct harnesses for complex, real-world libraries in as little as one hour.We integrate Oracle-guided Harnessing as a prototype, OGHarn; and evaluate it alongside today's leading fully-automatic harnessing approach, Hopper, and a plethora of developer-written harnesses from OSS-Fuzz. Across 20 real-world APIs, OGHarn outperforms developer-written harnesses by a median 14% code coverage, while uncovering 31 and 30 more vulnerabilities than both Hopper and developer-written harnesses, respectively—with zero false-positive crashes. Of the 41 new vulnerabilities found by OGHarn, all 41 are confirmed by developers—40 of which are since fixed—with many found in APIs that, until now, lacked harnesses whatsoever.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {165–177},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00193,
author = {Ren, Mengxia and Xiang, Anhao and Yue, Chuan},
title = {Analyzing the Feasibility of Adopting Google's Nonce-Based CSP Solutions on Websites},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00193},
doi = {10.1109/ICSE55347.2025.00193},
abstract = {Content Security Policy (CSP) is a leading security mechanism for mitigating content injection attacks such as Cross-Site Scripting (XSS). Nevertheless, despite efforts from academia and industry, CSP policies (in short, CSPs) are not widely deployed on websites, and deployed CSPs often have security issues or errors. Such low and insecure CSP deployment problems are mainly due to the complexity of the CSP mechanism. Google recently proposed four nonce-based CSP solutions which are simpler and more secure compared to traditional whitelisting-based CSP solutions. Google successfully deployed their nonce-based CSP solutions on over 160 services, covering 62% of all outgoing Google traffic. These nonce-based CSP solutions use simple CSPs but provide fine-grained control of web resources; therefore, if widely adopted on many other websites, they can be very helpful on addressing the low and insecure CSP deployment problems. In this paper, we evaluate the feasibility of adopting Google's nonce-based CSP solutions on the Tranco top 10K websites. We construct a crawling tool to automatically visit websites, simulate user interactions, and insert four CSPs to collect the CSP violations triggered under them. We investigate the adoptability of the nonce-based CSP solutions, adoption issues, and the stability of adopting them on websites by analyzing the CSP violations triggered under the inserted CSPs. We found that most websites can adopt the nonce-based CSP solutions on all their webpages visited in our study. For websites that cannot, usually the adoption is hard on around 40% of their webpages. Overall, our results are very encouraging and can be helpful in promoting the proper deployment of CSPs on many websites.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2829–2840},
numpages = {12},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00161,
author = {Thompson, Kyle and Saavedra, Nuno and Carrott, Pedro and Fisher, Kevin and Sanchez-Stern, Alex and Brun, Yuriy and Ferreira, Jo\~{a}o F. and Lerner, Sorin and First, Emily},
title = {Rango: Adaptive Retrieval-Augmented Proving for Automated Software Verification},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00161},
doi = {10.1109/ICSE55347.2025.00161},
abstract = {Formal verification using proof assistants, such as Coq, enables the creation of high-quality software. However, the verification process requires significant expertise and manual effort to write proofs. Recent work has explored automating proof synthesis using machine learning and large language models (LLMs). This work has shown that identifying relevant premises, such as lemmas and definitions, can aid synthesis. We present Rango, a fully automated proof synthesis tool for Coq that automatically identifies relevant premises and also similar proofs from the current project and uses them during synthesis. Rango uses retrieval augmentation at every step of the proof to automatically determine which proofs and premises to include in the context of its fine-tuned LLM. In this way, Rango adapts to the project and to the evolving state of the proof. We create a new dataset, CoqStoq, of 2,226 open-source Coq projects and 196,929 theorems from GitHub, which includes both training data and a curated evaluation benchmark of well-maintained projects. On this benchmark, Rango synthesizes proofs for 32.0% of the theorems, which is 29% more theorems than the prior state-of-the-art tool Tactician. Our evaluation also shows that Rango adding relevant proofs to its context leads to a 47% increase in the number of theorems proven.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {347–359},
numpages = {13},
keywords = {formal verification, theorem proving, large language models, retrieval augmentation, software reliability},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00157,
author = {Bouzenia, Islem and Devanbu, Premkumar and Pradel, Michael},
title = {RepairAgent: An Autonomous, LLM-Based Agent for Program Repair},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00157},
doi = {10.1109/ICSE55347.2025.00157},
abstract = {Automated program repair has emerged as a powerful technique to mitigate the impact of software bugs on system reliability and user experience. This paper introduces RepairAgent, the first work to address the program repair challenge through an autonomous agent based on a large language model (LLM). Unlike existing deep learning-based approaches, which prompt a model with a fixed prompt or in a fixed feedback loop, our work treats the LLM as an agent capable of autonomously planning and executing actions to fix bugs by invoking suitable tools. RepairAgent freely interleaves gathering information about the bug, gathering repair ingredients, and validating fixes, while deciding which tools to invoke based on the gathered information and feedback from previous fix attempts. Key contributions that enable RepairAgent include a set of tools that are useful for program repair, a dynamically updated prompt format that allows the LLM to interact with these tools, and a finite state machine that guides the agent in invoking the tools. Our evaluation on the popular Defects4J dataset demonstrates RepairAgent's effectiveness in autonomously repairing 164 bugs, including 39 bugs not fixed by prior techniques. Interacting with the LLM imposes an average cost of 270k tokens per bug, which, under the current pricing of OpenAI's GPT-3.5 model, translates to 14 cents per bug. To the best of our knowledge, this work is the first to present an autonomous, LLM-based agent for program repair, paving the way for future agent-based techniques in software engineering.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2188–2200},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00143,
author = {Baatartogtokh, Yesugen and Cook, Kaitlyn and Grubb, Alicia M.},
title = {Exploring the Robustness of the Effect of EVO on Intention Valuation through Replication},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00143},
doi = {10.1109/ICSE55347.2025.00143},
abstract = {The development of high-quality software depends on precise and comprehensive requirements that meet the objectives of stakeholders. Goal modeling techniques have been developed to fill this gap by capturing and analyzing stakeholders' needs and allowing them to make trade-off decisions; yet, goal modeling analysis is often difficult for stakeholders to interpret. Recent work found that when subjects are given minimal training on goal modeling and access to a color visualization, called EVO, they are able to use EVO to make goal modeling decisions faster without compromising quality. In this paper, we evaluate the robustness of the empirical evidence for EVO and question the underlying color choices made by the initial designers of EVO. We conduct a pseudo-exact replication (n = 60) of the original EVO study, varying the experimental site and the study population. Even in our heterogeneous sample with less a priori familiarity with requirements and goal modeling, we find that individuals using EVO answered the goal-modeling questions significantly faster than those using the control, expanding the external validity of the original results. However, we find some evidence that the chosen color scheme is not intuitive and make recommendations for the goal modeling community.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {808–820},
numpages = {13},
keywords = {requirements, goal modeling, replication},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00040,
author = {Spiess, Claudio and Gros, David and Pai, Kunal Suresh and Pradel, Michael and Rabin, Md Rafiqul Islam and Alipour, Amin and Jha, Susmit and Devanbu, Prem and Ahmed, Toufique},
title = {Calibration and Correctness of Language Models for Code},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00040},
doi = {10.1109/ICSE55347.2025.00040},
abstract = {Machine learning models are widely used, but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated.A well-calibrated confidence measure can serve as a basis for rational, graduated decision-making on how much review and care is needed when using generated code. Calibration has so far been studied in mostly non-generative (e.g., classification) settings, especially in software engineering. However, generated code can quite often be wrong: Given generated code, developers must decide whether to use directly, use after varying intensity of careful review, or discard model-generated code. Thus, calibration is vital in generative settings.We make several contributions. We develop a framework for evaluating the calibration of code-generating models. We consider several tasks, correctness criteria, datasets, and approaches, and find that, by and large, generative code models we test are not well-calibrated out of the box. We then show how calibration can be improved using standard methods, such as Platt scaling. Since Platt scaling relies on the prior availability of correctness data, we evaluate the applicability and generalizability of Platt scaling in software engineering, discuss settings where it has good potential for practical use, and settings where it does not. Our contributions will lead to better-calibrated decision-making in the current use of code generated by language models, and offers a framework for future research to further improve calibration methods for generative models in software engineering.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {540–552},
numpages = {13},
keywords = {LLM, calibration, confidence measure},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00037,
author = {Limpanukorn, Ben and Wang, Jiyuan and Kang, Hong Jin and Zhou, Zitong and Kim, Miryung},
title = {Fuzzing MLIR Compilers with Custom Mutation Synthesis},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00037},
doi = {10.1109/ICSE55347.2025.00037},
abstract = {Compiler technologies in deep learning and domain-specific hardware acceleration are increasingly adopting extensible compiler frameworks such as Multi-Level Intermediate Representation (MLIR) to facilitate more efficient development. With MLIR, compiler developers can easily define their own custom IRs in the form of MLIR dialects. However, the diversity and rapid evolution of such custom IRs make it impractical to manually write a custom test generator for each dialect.To address this problem, we design a new test generator called SynthFuzz that combines grammar-based fuzzing with custom mutation synthesis. The key essence of SynthFuzz is two fold: (1) It automatically infers parameterized context-dependent custom mutations from existing test cases. (2) It then concretizes the mutation's content depending on the target context and reduces the chance of inserting invalid edits by performing k-ancestor and prefix/postfix matching. It obviates the need to manually define custom mutation operators for each dialect.We compare SynthFuzz to three baselines: Grammarinator—a grammar-based fuzzer without custom mutations, MLIRSmith—a custom test generator for MLIR core dialects, and NeuRI—a custom test generator for ML models with parameterization of tensor shapes. We conduct this comprehensive comparison on four different MLIR projects. Each project defines a new set of MLIR dialects where manually writing a custom test generator would take weeks of effort. Our evaluation shows that SynthFuzz on average improves MLIR dialect pair coverage by 1.75X, which increases branch coverage by 1.22X. Further, we show that our context dependent custom mutation increases the proportion of valid tests by up to 1.11X, indicating that SynthFuzz correctly concretizes its parameterized mutations with respect to the target context. Parameterization of the mutations reduces the fraction of tests violating the base MLIR constraints by 0.57X, increasing the time spent fuzzing dialect-specific code.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {217–229},
numpages = {13},
keywords = {grammar-based fuzzing, program synthesis, program transformation, MLIR, compiler testing, code patterns},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00017,
author = {Lian, Xinyu and Chen, Yinfang and Cheng, Runxiang and Huang, Jie and Thakkar, Parth and Zhang, Minjia and Xu, Tianyin},
title = {Large Language Models as Configuration Validators},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00017},
doi = {10.1109/ICSE55347.2025.00017},
abstract = {Misconfigurations are major causes of software failures. Existing practices rely on developer-written rules or test cases to validate configuration values, which are expensive. Machine learning (ML) for configuration validation is considered a promising direction, but has been facing challenges such as the need of large-scale field data and system-specific models. Recent advances in Large Language Models (LLMs) show promise in addressing some of the long-lasting limitations of ML-based configuration validation. We present the first analysis on the feasibility and effectiveness of using LLMs for configuration validation. We empirically evaluate LLMs as configuration validators by developing a generic LLM-based configuration validation framework, named Ciri. Ciri employs effective prompt engineering with few-shot learning based on both valid configuration and misconfiguration data. Ciri checks outputs from LLMs when producing results, addressing hallucination and nondeterminism of LLMs. We evaluate Ciri's validation effectiveness on eight popular LLMs using configuration data of ten widely deployed open-source systems. Our analysis (1) confirms the potential of using LLMs for configuration validation, (2) explores design space of LLM-based validators like Ciri, and (3) reveals open challenges such as ineffectiveness in detecting certain types of misconfigurations and biases towards popular configuration parameters.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1704–1716},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00208,
author = {Chen, Menglong and Tan, Tian and Pan, Minxue and Li, Yue},
title = {PacDroid: A Pointer-Analysis-Centric Framework for Security Vulnerabilities in Android Apps},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00208},
doi = {10.1109/ICSE55347.2025.00208},
abstract = {General frameworks such as FlowDroid, IccTA, P/Taint, Amandroid, and DroidSafe have significantly advanced the development of static analysis tools for Android security by providing fundamental facilities for them. However, while these frameworks have been instrumental in fostering progress, they often operate with inherent inefficiencies, such as redundant computations, reliance on separate tools, and unnecessary complexity, which are rarely scrutinized by the analysis tools that depend on them. This paper introduces PacDroid, a new static analysis framework for detecting security vulnerabilities in Android apps. PacDroid employs a simple yet effective pointer-analysis-centric approach that naturally manages alias information, interprocedural value propagation, and all Android features it supports (including ICC, lifecycles, and miscs), in a unified manner. Our extensive evaluation reveals that PacDroid not only outperforms state-of-the-art frameworks in achieving a superior trade-off between soundness and precision (F-measure) but also surpasses them in both analysis speed and robustness; moreover, PacDroid successfully identifies 77 real security vulnerability flows across 23 real-world Android apps that were missed by all other frameworks. With its ease of extension and provision of essential facilities, PacDroid is expected to serve as a foundational framework for various future analysis applications for Android.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2803–2815},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00186,
author = {Fuch\ss{}, Dominik and Hey, Tobias and Keim, Jan and Liu, Haoyu and Ewald, Niklas and Thirolf, Tobias and Koziolek, Anne},
title = {LiSSA: Toward Generic Traceability Link Recovery through Retrieval-Augmented Generation},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00186},
doi = {10.1109/ICSE55347.2025.00186},
abstract = {There are a multitude of software artifacts which need to be handled during the development and maintenance of a software system. These artifacts interrelate in multiple, complex ways. Therefore, many software engineering tasks are enabled — and even empowered — by a clear understanding of artifact interrelationships and also by the continued advancement of techniques for automated artifact linking.However, current approaches in automatic Traceability Link Recovery (TLR) target mostly the links between specific sets of artifacts, such as those between requirements and code. Fortunately, recent advancements in Large Language Models (LLMs) can enable TLR approaches to achieve broad applicability. Still, it is a nontrivial problem how to provide the LLMs with the specific information needed to perform TLR.In this paper, we present LiSSA, a framework that harnesses LLM performance and enhances them through Retrieval-Augmented Generation (RAG). We empirically evaluate LiSSA on three different TLR tasks, requirements to code, documentation to code, and architecture documentation to architecture models, and we compare our approach to state-of-the-art approaches.Our results show that the RAG-based approach can significantly outperform the state-of-the-art on the code-related tasks. However, further research is required to improve the performance of RAG-based approaches to be applicable in practice.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1396–1408},
numpages = {13},
keywords = {traceability link recovery, large language models, retrieval-augmented generation},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00184,
author = {Hermann, Kevin and Peldszus, Sven and Stegh\"{o}fer, Jan-Philipp and Berger, Thorsten},
title = {An Exploratory Study on the Engineering of Security Features},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00184},
doi = {10.1109/ICSE55347.2025.00184},
abstract = {Software security is of utmost importance for most software systems. Developers must systematically select, plan, design, implement, and especially, maintain and evolve security features—functionalities to mitigate attacks or protect personal data such as cryptography or access control—to ensure the security of their software. Although security features are usually available in libraries, integrating security features requires writing and maintaining additional security-critical code. While there have been studies on the use of such libraries, surprisingly little is known about how developers engineer security features, how they select what security features to implement and which ones may require custom implementation, and the implications for maintenance. As a result, we currently rely on assumptions that are largely based on common sense or individual examples. However, to provide them with effective solutions, researchers need hard empirical data to understand what practitioners need and how they view security—data that we currently lack. To fill this gap, we contribute an exploratory study with 26 knowledgeable industrial participants. We study how security features of software systems are selected and engineered in practice, what their code-level characteristics are, and what challenges practitioners face. Based on the empirical data gathered, we provide insights into engineering practices and validate four common assumptions.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2470–2482},
numpages = {13},
keywords = {security feature, software security, secure software development, security by design, developer study},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00042,
author = {Hasanov, Sanan and Nagy, Stefan and Gazzillo, Paul},
title = {A Little Goes a Long Way: Tuning Configuration Selection for Continuous Kernel Fuzzing},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00042},
doi = {10.1109/ICSE55347.2025.00042},
abstract = {The Linux kernel is actively-developed and widely-used. It supports billions of devices of all classes, from high-performance computing to the Internet-of-Things, in part because of its sophisticated configuration system, which automatically tailors the source code according to thousands of user-provided configuration options. Fuzzing has been highly successful at finding kernel bugs, being among the top bug reporters. Since the kernel receives 100s of patches per day, fuzzers run continuously, stopping regularly to rebuild the kernel with the latest changes before restarting fuzzing. But kernel fuzzers currently use predefined configuration settings that, as we show, exclude the majority of new patches from the kernel binary, nullifying the benefits of continuous fuzzing. Unfortunately, state-of-the-art configuration testing techniques are generally ill-suited to the needs of continuous fuzzing, excluding necessary options or requiring too many configuration files to be tractable. We distill down the needs of continuous testing into six properties with the most impact, systematically analyze the space of configuration selection strategies, and provide actionable recommendations. Through our analysis, we discover that continuous fuzzers can improve configuration variety without sacrificing performance. We empirically evaluate our discovery by modifying the configuration selection strategy for syzkaller, the most popular Linux kernel fuzzer, which subsequently found more than twice as many new bugs (35 vs. 13) than with the original configuration file and 12x more (24 vs. 2) when considering only unique bugs—with one security vulnerability being assigned a CVE.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {795–807},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00232,
author = {Huang, Ruanqianqian (Lisa) and Ravi, Savitha and He, Michael and Tian, Boyu and Lerner, Sorin and Coblenz, Michael},
title = {How Scientists Use Jupyter Notebooks: Goals, Quality Attributes, and Opportunities},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00232},
doi = {10.1109/ICSE55347.2025.00232},
abstract = {Computational notebooks are intended to prioritize the needs of scientists, but little is known about how scientists interact with notebooks, what requirements drive scientists' software development processes, or what tactics scientists use to meet their requirements. We conducted an observational study of 20 scientists using Jupyter notebooks for their day-to-day tasks, finding that scientists prioritize different quality attributes depending on their goals. A qualitative analysis of their usage shows (1) a collection of goals scientists pursue with Jupyter notebooks, (2) a set of quality attributes that scientists value when they write software, and (3) tactics that scientists leverage to promote quality. In addition, we identify ways scientists incorporated AI tools into their notebook work. From our observations, we derive design recommendations for improving computational notebooks and future programming systems for scientists. Key opportunities pertain to helping scientists create and manage state, dependencies, and abstractions in their software, enabling more effective reuse of clearly-defined components.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1243–1255},
numpages = {13},
keywords = {scientific computing, computational notebooks, end-user software engineering},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00231,
author = {Verbeek, Freek and Shokri, Ali and Engel, Daniel and Ravindran, Binoy},
title = {Formally Verified Binary-Level Pointer Analysis},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00231},
doi = {10.1109/ICSE55347.2025.00231},
abstract = {Binary-level pointer analysis can be of use in symbolic execution, testing, verification, and decompilation of software binaries. In various such contexts, it is crucial that the result is trustworthy, i.e., it can be formally established that the pointer designations are overapproximative. This paper presents an approach to formally proven correct binary-level pointer analysis. A salient property of our approach is that it first generically considers what proof obligations a generic abstract domain for pointer analysis must satisfy. This allows easy instantiation of different domains, varying in precision, while preserving the correctness of the analysis. In the tradeoff between scalability and precision, such customization allows "meaningful" precision (sufficiently precise to ensure basic sanity properties, such as that relevant parts of the stack frame are not overwritten during function execution) while also allowing coarse analysis when pointer computations have become too obfuscated during compilation for sound and accurate bounds analysis. We experiment with three different abstract domains with high, medium, and low precision. Evaluation shows that our approach is able to derive designations for memory writes soundly in COTS binaries, in a context-sensitive interprocedural fashion.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {42–53},
numpages = {12},
keywords = {binary analysis, pointer analysis, formal methods},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00224,
author = {Jahan, Sigma and Shah, Mehil B and Mahbub, Parvez and Rahman, Mohammad Masudur},
title = {Improved Detection and Diagnosis of Faults in Deep Neural Networks Using Hierarchical and Explainable Classification},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00224},
doi = {10.1109/ICSE55347.2025.00224},
abstract = {Deep Neural Networks (DNN) have found numerous applications in various domains, including fraud detection, medical diagnosis, facial recognition, and autonomous driving. However, DNN-based systems often suffer from reliability issues due to their inherent complexity and the stochastic nature of their underlying models. Unfortunately, existing techniques to detect faults in DNN programs are either limited by the types of faults (e.g., hyperparameter or layer) they support or the kind of information (e.g., dynamic or static) they use. As a result, they might fall short of comprehensively detecting and diagnosing the faults. In this paper, we present DEFault (Detect and Explain Fault) – a novel technique to detect and diagnose faults in DNN programs. It first captures dynamic (i.e., runtime) features during model training and leverages a hierarchical classification approach to detect all major fault categories from the literature. Then, it captures static features (e.g., layer types) from DNN programs and leverages explainable AI methods (e.g., SHAP) to narrow down the root cause of the fault. We train and evaluate DEFault on a large, diverse dataset of ≈ 14.5K DNN programs and further validate our technique using a benchmark dataset of 52 real-life faulty DNN programs. Our approach achieves ≈ 94% recall in detecting real-world faulty DNN programs and ≈ 63% recall in diagnosing the root causes of the faults, demonstrating 3.92%–11.54% higher performance than that of state-of-the-art techniques. Thus, DEFault has the potential to significantly improve the reliability of DNN programs by effectively detecting and diagnosing the faults.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2944–2956},
numpages = {13},
keywords = {deep neural networks, dynamic analysis, model fault, static analysis, training fault},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00203,
author = {Yadavally, Aashish and Rong, Xiaokai and Nguyen, Phat and Nguyen, Tien N.},
title = {Large Language Models for Safe Minimization},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00203},
doi = {10.1109/ICSE55347.2025.00203},
abstract = {Several tasks in program analysis, verification, and testing are modeled as constraint solving problems, utilizing SMT solvers as the reasoning engine. In this work, we aim to investigate the reasoning capabilities of large language models (LLMs) toward reducing the size of an infeasible string constraint system by exploiting inter-constraint interactions such that the remaining ones are still unsatisfiable. We term this safe minimization.Motivated by preliminary observations of hallucination and error propagation in LLMs, we design SafeMin, a framework leveraging an LLM and SMT solver in tandem to ensure a safe and correct minimization. We test the applicability of our approach on string benchmarks from LeetCode in the computation of minimal unsatisfiable subsets (MUSes). We observed that SafeMin helps safely minimize 94.3% of these constraints, with an average minimization ratio of 98% relative to the MUSes. In addition, we assess SAFEMIN's capabilities in partially enumerating non-unique MUSes, which is baked into our approach via a "sample-and-enumerate" decoding strategy. Overall, we captured 42.1% more non-unique MUSes than without such LLM-based macro-reasoning. Finally, we demonstrate SafeMin's usefulness in detecting infeasible paths in programs.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1114–1126},
numpages = {13},
keywords = {large language models, constraint solving, safe minimization, inter-constraint reasoning},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00201,
author = {Ma, Youpeng and Chen, Tao and Li, Ke},
title = {Faster Configuration Performance Bug Testing with Neural Dual-Level Prioritization},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00201},
doi = {10.1109/ICSE55347.2025.00201},
abstract = {As software systems become more complex and configurable, more performance problems tend to arise from the configuration designs. This has caused some configuration options to unexpectedly degrade performance which deviates from their original expectations designed by the developers. Such discrepancies, namely configuration performance bugs (CPBugs), are devastating and can be deeply hidden in the source code. Yet, efficiently testing CPBugs is difficult, not only due to the test oracle is hard to set, but also because the configuration measurement is expensive and there are simply too many possible configurations to test. As such, existing testing tools suffer from lengthy runtime or have been ineffective in detecting CPBugs when the budget is limited, compounded by inaccurate test oracle.In this paper, we seek to achieve significantly faster CP-Bug testing by neurally prioritizing the testing at both the configuration option and value range levels with automated oracle estimation. Our proposed tool, dubbed NDP, is a general framework that works with different heuristic generators. The idea is to leverage two neural language models: one to estimate the CPBug types that serve as the oracle while, more vitally, the other to infer the probabilities of an option being CPBug-related, based on which the options and the value ranges to be searched can be prioritized. Experiments on several widely-used systems of different versions reveal that NDP can, in general, better predict CPBug type in 87% cases and find more CPBugs with up to 88.88\texttimes{} testing efficiency speedup over the state-of-the-art tools.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {988–1000},
numpages = {13},
keywords = {performance bug testing, software debugging, testing prioritization, configuration testing, SBSE},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00188,
author = {Choi, Youngjae and Woo, Seunghoon},
title = {Tiver: Identifying Adaptive Versions of C/C++ Third-Party Open-Source Components Using a Code Clustering Technique},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00188},
doi = {10.1109/ICSE55347.2025.00188},
abstract = {Reusing open-source software (OSS) provides significant benefits but also poses risks from propagated vulnerabilities. While tracking OSS component versions helps mitigate threats, existing approaches typically map a single version to the reused codebase. This coarse-grained approach overlooks the coexistence of multiple versions, leading to ineffective OSS management. Moreover, identifying component versions is further complicated by noise codes, such as shared algorithmic code across different OSS, and duplicate components caused by redundant OSS reuse.In this paper, we introduce the concept of the adaptive version, a one-stop solution to represent the version diversity of reused OSS. To identify adaptive versions, we present Tiver, which employs two key techniques: (1) fine-grained function-level versioning and (2) OSS code clustering to identify duplicate components and remove noise. This enables precise identification of OSS reuse locations and adaptive versions, effectively mitigating risks associated with OSS reuse. Evaluation of 2,025 popular C/C++ software revealed that 67% of OSS components contained multiple versions, averaging over three versions per component. Nonetheless, Tiver effectively identified adaptive versions with 88.46% precision and 91.63% recall in duplicate component distinction, and 86% precision and 86.84% recall in eliminating noise, while existing approaches barely achieved 42% recall in distinguishing duplicates and did not address noise. Further experiments showed that Tiver could enhance vulnerability management and be applied to Software Bills of Materials (SBOM) to improve supply chain security.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2458–2469},
numpages = {12},
keywords = {open-source software, third-party library management, version identification, supply chain security},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00125,
author = {Miao, Miao and Mordahl, Austin and Soles, Dakota and Beideck, Alice and Wei, Shiyi},
title = {An Extensive Empirical Study of Nondeterministic Behavior in Static Analysis Tools},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00125},
doi = {10.1109/ICSE55347.2025.00125},
abstract = {Recent research has studied the importance and identified causes of nondeterminism in software. Static analysis tools exhibit many risk factors for nondeterministic behavior, but no work has analyzed the occurrence of such behavior in these tools. To bridge this gap, we perform an extensive empirical study aiming to understand past and ongoing nondeterminism in 12 popular, open-source static analysis tools that target 5 types of projects. We first conduct a qualitative study to understand the extent to which nondeterministic behavior has been found and addressed within the tools under study, and find results in 7 tool repositories. After classifying the issues and commits by root cause, we find that the majority of nondeterminisms are caused by concurrency issues, incorrect analysis logic, or assumed orderings of unordered data structures, which have shared patterns. We also perform a quantitative analysis, where we use two strategies and diverse input programs and configurations to detect yet-unknown nondeterministic behaviors. We discover such behavior in 8 out of the 12 tools, including 3 which had no results from the qualitative analysis. We find that nondeterminism often appears in multiple configurations on a variety of input programs. We communicated all identified nondeterminism to the developers, and received confirmation of five tools. Finally, we detail a case study of fixing FlowDroid's nondeterministic behavior.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1064–1076},
numpages = {13},
keywords = {nondeterminism, staic analysis, software testing},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00113,
author = {Luo, Chuan and Lyu, Shuangyu and Wu, Wei and Zhang, Hongyu and Chu, Dianhui and Hu, Chunming},
title = {Towards High-Strength Combinatorial Interaction Testing for Highly Configurable Software Systems},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00113},
doi = {10.1109/ICSE55347.2025.00113},
abstract = {Highly configurable software systems are crucial in practice to satisfy the rising demand for software customization, and combinatorial interaction testing (CIT) is an important methodology for testing such systems. Constrained covering array generation (CCAG), as the core problem in CIT, is to construct a t-wise covering array (CA) of minimum size, where t represents the testing strength. Extensive studies have demonstrated that high-strength CIT (e.g., 4-wise and 5-wise CIT) has stronger fault detection capability than low-strength CIT (i.e., 2-wise and 3-wise CIT), and there exist certain critical faults that can be disclosed through high-strength CIT. Although existing CCAG algorithm has exhibited effectiveness in solving the low-strength CCAG problem, they suffer the severe high-strength challenge when solving 4-wise and 5-wise CCAG, which urgently calls for effective solutions to solving 4-wise and 5-wise CCAG problems. To alleviate the high-strength challenge, we propose a novel and effective local search algorithm dubbed HSCA. Particularly, HSCA incorporates three new and powerful techniques, i.e., multi-round CA generation mechanism, dynamic priority assigning technique, and variable grouping strategy, to improve its performance. Extensive experiments on 35 real-world and synthetic instances demonstrate that HSCA can generate significantly smaller 4-wise and 5-wise CAs than existing state-of-the-art CCAG algorithms. More encouragingly, among all 35 instances, HSCA successfully builds 4-wise and 5-wise CAs for 35 and 29 instances, respectively, including 11 and 15 instances where existing CCAG algorithms fail. Our results indicate that HSCA can effectively mitigate the high-strength challenge.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1579–1591},
numpages = {13},
keywords = {combinatorial interaction testing, local search},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00094,
author = {Ye, Yulong and Chen, Tao and Li, Miqing},
title = {Distilled Lifelong Self-Adaptation for Configurable Systems},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00094},
doi = {10.1109/ICSE55347.2025.00094},
abstract = {Modern configurable systems provide tremendous opportunities for engineering future intelligent software systems. A key difficulty thereof is how to effectively self-adapt the configuration of a running system such that its performance (e.g., runtime and throughput) can be optimized under time-varying workloads. This unfortunately remains unaddressed in existing approaches as they either overlook the available past knowledge or rely on static exploitation of past knowledge without reasoning the usefulness of information when planning for self-adaptation. In this paper, we tackle this challenging problem by proposing DLiSA, a framework that self-adapts configurable systems. DLiSA comes with two properties: firstly, it supports lifelong planning, and thereby the planning process runs continuously throughout the lifetime of the system, allowing dynamic exploitation of the accumulated knowledge for rapid adaptation. Secondly, the planning for a newly emerged workload is boosted via distilled knowledge seeding, in which the knowledge is dynamically purified such that only useful past configurations are seeded when necessary, mitigating misleading information.Extensive experiments suggest that the proposed DLiSA significantly outperforms state-of-the-art approaches, demonstrating a performance improvement of up to 229% and a resource acceleration of up to 2.22\texttimes{} on generating promising adaptation configurations. All data and sources can be found at our repository: https://github.com/ideas-labo/dlisa.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1333–1345},
numpages = {13},
keywords = {self-adaptive systems, search-based software engineering, dynamic optimization, configuration tuning},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00092,
author = {Richter, Cedric and Chalupa, Marek and Jakobs, Marie-Christine and Wehrheim, Heike},
title = {Cooperative Software Verification via Dynamic Program Splitting},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00092},
doi = {10.1109/ICSE55347.2025.00092},
abstract = {Cooperative software verification divides the task of software verification among several verification tools in order to increase efficiency and effectiveness. The basic approach is to let verifiers work on different parts of a program and at the end join verification results. While this idea is intuitively appealing, cooperative verification is usually hindered by the fact that program decomposition (1) is often static, disregarding strengths and weaknesses of employed verifiers, and (2) often represents the decomposed program parts in a specific proprietary format, thereby making the use of off-the-shelf verifiers in cooperative verification difficult.In this paper, we propose a novel cooperative verification scheme that we call dynamic program splitting (DPS). Splitting decomposes programs into (smaller) programs, and thus directly enables the use of off-the-shelf tools. In DPS, splitting is dynamically applied on demand: Verification starts by giving a verification task (a program plus a correctness specification) to a verifier V1. Whenever V1 finds the current task to be hard to verify, it splits the task (i.e., the program) and restarts verification on subtasks. DPS continues until (1) a violation is found, (2) all subtasks are completed or (3) some user-defined stopping criterion is met. In the latter case, the remaining uncompleted subtasks are merged into a single one and are given to a next verifier V2, repeating the same procedure on the still unverified program parts. This way, the decomposition is steered by what is hard to verify for particular verifiers, leveraging their complementary strengths. We have implemented dynamic program splitting and evaluated it on benchmarks of the annual software verification competition SV-COMP. The evaluation shows that cooperative verification with DPS is able to solve verification tasks that none of the constituent verifiers can solve, without any significant overhead.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2087–2099},
numpages = {13},
keywords = {software verification, cooperation, program splitting, off-the-shelf tools},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00230,
author = {Panichella, Annibale},
title = {Metamorphic-Based Many-Objective Distillation of LLMs for Code-Related Tasks},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00230},
doi = {10.1109/ICSE55347.2025.00230},
abstract = {Knowledge distillation compresses large language models (LLMs) into more compact and efficient versions that achieve similar accuracy on code-related tasks. However, as we demonstrate in this study, compressed models are four times less robust than the original LLMs when evaluated with metamorphic code. They exhibit a 440% higher probability of misclassifying code clones due to minor changes in the code fragment under analysis, such as replacing parameter names with synonyms. To address this issue, we propose Morph, a novel method that combines metamorphic testing with many-objective optimization for a robust distillation of LLMs for code. Morph efficiently explores the models' configuration space and generates Pareto-optimal models that effectively balance accuracy, efficiency, and robustness to metamorphic code. Metamorphic testing measures robustness as the number of code fragments for which a model incorrectly makes different predictions between the original and their equivalent metamorphic variants (prediction flips). We evaluate Morph on two tasks—code clone and vulnerability detection—targeting CodeBERT and GraphCodeBERT for distillation. Our comparison includes Morph, the state-of-the-art distillation method Avatar, and the fine-tuned non-distilled LLMs. Compared to Avatar, Morph produces compressed models that are (i) 47% more robust, (ii) 25% more efficient (fewer floating-point operations), while maintaining (iii) equal or higher accuracy (up to +6%), and (iv) similar model size.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1001–1013},
numpages = {13},
keywords = {knowledge distillation, large language models, metamorphic testing, many-objective optimization, green-AI, sustainability, search-based software engineering, AI for SE},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00225,
author = {Wu, Ziji and Huang, Yu and Huang, Peishan and Wen, Shanghua and Li, Minglong and Wang, Ji},
title = {EffBT: An Efficient Behavior Tree Reactive Synthesis and Execution Framework},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00225},
doi = {10.1109/ICSE55347.2025.00225},
abstract = {Behavior Trees (BTs), originated from the control of Non-Player-Characters (NPCs), have been widely embraced in robotics and software engineering communities due to their modularity, reactivity, and other beneficial characteristics. It is highly desirable to synthesize BTs automatically. The consequent challenges are to ensure the generated BTs semantically correct, well-structured, and efficiently executable. To address these challenges, in this paper, we present a novel reactive synthesis method for BTs, namely EffBT, to generate correct and efficient controllers from formal specifications in GR(1) automatically. The idea is to construct BTs soundly from the intermediate strategies derived during the algorithm of GR(1) realizability check. Additionally, we introduce pruning strategies and use of Parallel nodes to improve BT execution, while none of the priors explored before. We prove the soundness of the EffBT method, and the experimental results demonstrate its effectiveness in various scenarios and datasets.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {54–65},
numpages = {12},
keywords = {behavior trees, reactive synthesis, GR(1), efficient execution},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00215,
author = {Souza, Beatriz and Pradel, Michael},
title = {Treefix: Enabling Execution with a Tree of Prefixes},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00215},
doi = {10.1109/ICSE55347.2025.00215},
abstract = {The ability to execute code is a prerequisite for various dynamic program analyses. Learning-guided execution has been proposed as an approach to enable the execution of arbitrary code snippets by letting a neural model predict likely values for any missing variables. Although state-of-the-art learning-guided execution approaches, such as LExecutor, can enable the execution of a relative high amount of code, they are limited to predicting a restricted set of possible values and do not use any feedback from previous executions to execute even more code. This paper presents Treefix, a novel learning-guided execution approach that leverages LLMs to iteratively create code prefixes that enable the execution of a given code snippet. The approach addresses the problem in a multi-step fashion, where each step uses feedback about the code snippet and its execution to instruct an LLM to improve a previously generated prefix. This process iteratively creates a tree of prefixes, a subset of which is returned to the user as prefixes that maximize the number of executed lines in the code snippet. In our experiments with two datasets of Python code snippets, Treefix achieves 25% and 7% more coverage relative to the current state of the art in learning-guided execution, covering a total of 84% and 82% of all lines in the code snippets.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2676–2688},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00212,
author = {Liang, Hongyuan and Huang, Yue and Chen, Tao},
title = {The Same Only Different: On Information Modality for Configuration Performance Analysis},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00212},
doi = {10.1109/ICSE55347.2025.00212},
abstract = {Configuration in software systems helps to ensure efficient operation and meet diverse user needs. Yet, some, if not all, configuration options have profound implications for the system's performance. Configuration performance analysis, wherein the key is to understand (or infer) the configuration options' relations and their impacts on performance, is crucial. Two major modalities exist that serve as the source information in the analysis: either the manual or source code. However, it remains unclear what roles they play in configuration performance analysis. Much work that relies on manuals claims their benefits of information richness and naturalness; while work that trusts the source code more prefers the structural information provided therein and criticizes the timeliness of manuals.To fill such a gap, in this paper, we conduct an extensive empirical study over 10 systems, covering 1,694 options, 106,798 words in the manual, and 22,859,552 lines-of-code for investigating the usefulness of manual and code in two important tasks of configuration performance analysis, namely performance-sensitive options identification and the associated dependencies extraction. We reveal several new findings and insights, such as it is beneficial to fuse the manual and code modalities for both tasks; the current automated tools that rely on a single modality are far from being practically useful and generally remain incomparable to human analysis. All those pave the way for further advancing configuration performance analysis.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2522–2534},
numpages = {13},
keywords = {software configuration, performance analysis, manual, source code analysis, configuration dependency},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00209,
author = {Zhou, Shide and Li, Tianlin and Wang, Kailong and Huang, Yihao and Shi, Ling and Liu, Yang and Wang, Haoyu},
title = {Understanding the Effectiveness of Coverage Criteria for Large Language Models: A Special Angle from Jailbreak Attacks},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00209},
doi = {10.1109/ICSE55347.2025.00209},
abstract = {Large language models (LLMs) have revolutionized artificial intelligence, but their increasing deployment across critical domains has raised concerns about their abnormal behaviors when faced with malicious attacks. Such vulnerability alerts the widespread inadequacy of pre-release testing. In this paper, we conduct a comprehensive empirical study to evaluate the effectiveness of traditional coverage criteria in identifying such inadequacies, exemplified by the significant security concern of jailbreak attacks. Our study begins with a clustering analysis of the hidden states of LLMs, revealing that the embedded characteristics effectively distinguish between different query types. We then systematically evaluate the performance of these criteria across three key dimensions: criterion level, layer level, and token level.Our research uncovers significant differences in neuron coverage when LLMs process normal versus jailbreak queries, aligning with our clustering experiments. Leveraging these findings, we propose three practical applications of coverage criteria in the context of LLM security testing. Specifically, we develop a real-time jailbreak detection mechanism that achieves high accuracy (93.61% on average) in classifying queries as normal or jailbreak. Furthermore, we explore the use of coverage levels to prioritize test cases, improving testing efficiency by focusing on high-risk interactions and removing redundant tests. Lastly, we introduce a coverage-guided approach for generating jailbreak attack examples, enabling systematic refinement of prompts to uncover vulnerabilities. This study improves our understanding of LLM security testing, enhances their safety, and provides a foundation for developing more robust AI applications.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {730–742},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00206,
author = {Baresi, Luciano and Hu, Davide Yi Xian and Stocco, Andrea and Tonella, Paolo},
title = {Efficient Domain Augmentation for Autonomous Driving Testing Using Diffusion Models},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00206},
doi = {10.1109/ICSE55347.2025.00206},
abstract = {Simulation-based testing is widely used to assess the reliability of Autonomous Driving Systems (ADS), but its effectiveness is limited by the operational design domain (ODD) conditions available in such simulators. To address this limitation, in this work, we explore the integration of generative artificial intelligence techniques with physics-based simulators to enhance ADS system-level testing. Our study evaluates the effectiveness and computational overhead of three generative strategies based on diffusion models, namely instruction-editing, inpainting, and inpainting with refinement. Specifically, we assess these techniques' capabilities to produce augmented simulator-generated images of driving scenarios representing new ODDs. We employ a novel automated detector for invalid inputs based on semantic segmentation to ensure semantic preservation and realism of the neural generated images. We then performed system-level testing to evaluate the ability of the ADS to generalize to newly synthesized ODDs. Our findings show that diffusion models help to increase the coverage of ODD for system-level ADS testing. Our automated semantic validator achieved a percentage of false positives as low as 3%, retaining the correctness and quality of the images generated for testing. Our approach successfully identified new ADS system failures before real-world testing.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {398–410},
numpages = {13},
keywords = {autonomous driving systems, deep learning testing, diffusion models, generative AI},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00182,
author = {Gropengie\ss{}er, Uwe and Dietz, Elias and Brandherm, Florian and Doula, Achref and Abboud, Osama and Xiao, Xun and M\"{u}hlh\"{a}user, Max},
title = {MARQ: Engineering Mission-Critical AI-Based Software with Automated Result Quality Adaptation},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00182},
doi = {10.1109/ICSE55347.2025.00182},
abstract = {AI-based mission-critical software exposes a blessing and a curse: its inherent statistical nature allows for flexibility in result quality, yet the mission-critical importance demands adherence to stringent constraints such as execution deadlines. This creates a space for trade-offs between the Quality of Result (QoR)—a metric that quantifies the quality of a computational outcome—and other application attributes like execution time and energy, particularly in real-time scenarios. Fluctuating resource constraints, such as data transfer to a remote server over unstable network connections, are prevalent in mobile and edge computing environments—encompassing use cases like Vehicle-to-Everything, drone swarms, or social-VR scenarios. We introduce a novel approach that enables software engineers to easily specify alternative AI service chains—sequences of AI services encapsulated in microservices aiming to achieve a predefined goal—with varying QoR and resource requirements. Our methodology facilitates dynamic optimization at runtime, which is automatically driven by the MARQ framework. Our evaluations show that MARQ can be used effectively for the dynamic selection of AI service chains in real-time while maintaining the required application constraints of mission-critical AI software. Notably, our approach achieves a 100\texttimes{} acceleration in service chain selection and an average 10% improvement in QoR compared to existing methods.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1934–1946},
numpages = {13},
keywords = {mission-critical AI, quality of result, edge computing, approximate computing, software engineering},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00176,
author = {Zhang, Jiyang and Liu, Yu and Nie, Pengyu and Li, Junyi Jessy and Gligoric, Milos},
title = {exLong: Generating Exceptional Behavior Tests with Large Language Models},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00176},
doi = {10.1109/ICSE55347.2025.00176},
abstract = {Many popular programming languages, including C#, Java, and Python, support exceptions. Exceptions are thrown during program execution if an unwanted event happens, e.g., a method is invoked with an illegal argument value. Software developers write exceptional behavior tests (EBTs) to check that their code detects unwanted events and throws appropriate exceptions. Prior research studies have shown the importance of EBTs, but those studies also highlighted that developers put most of their efforts on "happy paths", e.g., paths without unwanted events. To help developers fill the gap, we present the first framework, dubbed exLong, that automatically generates EBTs. exLong is a large language model instruction fine-tuned from CodeLlama and embeds reasoning about traces that lead to throw statements, conditional expressions that guard throw statements, and non-exceptional behavior tests that execute similar traces. We compare exLong with the state-of-the-art models for test generation (CAT-LM) and one of the strongest foundation models (GPT-4o), as well as with analysis-based tools for test generation (Randoop and EvoSuite). Our results show that exLong outperforms existing models and tools. Furthermore, we contributed several pull requests to open-source projects and 23 EBTs generated by exLong were already accepted.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1462–1474},
numpages = {13},
keywords = {test generation, large language models, program analysis, exceptional behavior tests},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00174,
author = {Le, Van-Hoang and Xiao, Yi and Zhang, Hongyu},
title = {Unleashing the True Potential of Semantic-Based Log Parsing with Pre-Trained Language Models},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00174},
doi = {10.1109/ICSE55347.2025.00174},
abstract = {Software-intensive systems often produce console logs for troubleshooting purposes. Log parsing, which aims at parsing a log message into a specific log template, typically serves as the first step toward automated log analytics. To better comprehend the semantic information of log messages, many semantic-based log parsers have been proposed. These log parsers fine-tune a small pre-trained language model (PLM) such as RoBERTa on a few labelled log samples. With the increasing popularity of large language models (LLMs), some recent studies also propose to leverage LLMs such as ChatGPT through in-context learning for automated log parsing and obtain better results than previous semantic-based log parsers with small PLMs. In this paper, we show that semantic-based log parsers with small PLMs can actually achieve better or comparable performance to state-of-the-art LLM-based log parsing models while being more efficient and cost-effective. We propose Unleash, a novel semantic-based log parsing approach, which incorporates three enhancement methods to boost the performance of PLMs for log parsing, including (1) an entropy-based ranking method to select the most informative log samples; (2) a contrastive learning method to enhance the fine-tuning process; and (3) an inference optimization method to improve the log parsing performance. We evaluate Unleash on a set of large-scale, public log datasets and the experimental results show that Unleash is effective and efficient compared to state-of-the-art log parsers.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {975–987},
numpages = {13},
keywords = {log parsing, log analytics, pre-trained LMs},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00163,
author = {Woodlief, Trey and Hildebrandt, Carl and Elbaum, Sebastian},
title = {A Differential Testing Framework to Identify Critical AV Failures Leveraging Arbitrary Inputs},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00163},
doi = {10.1109/ICSE55347.2025.00163},
abstract = {The proliferation of autonomous vehicles (AVs) has made their failures increasingly evident. Testing efforts aimed at identifying the inputs leading to those failures are challenged by the input's long-tail distribution, whose area under the curve is dominated by rare scenarios. We hypothesize that leveraging emerging open-access datasets can accelerate the exploration of long-tail inputs. Having access to diverse inputs, however, is not sufficient to expose failures; an effective test also requires an oracle to distinguish between correct and incorrect behaviors. Current datasets lack such oracles and developing them is notoriously difficult. In response, we propose DiffTest4AV, a differential testing framework designed to address the unique challenges of testing AV systems: 1) for any given input, many outputs may be considered acceptable, 2) the long tail contains an insurmountable number of inputs to explore, and 3) the AV's continuous execution loop requires failures to persist in order to affect the system. DiffTest4AV integrates statistical analysis to identify meaningful behavioral variations, judges their importance in terms of the severity of these differences, and incorporates sequential analysis to detect persistent errors indicative of potential system-level failures. Our study on 5 versions of the commercially-available, road-deployed comma.ai OpenPilot system, using 3 available image datasets, demonstrates the capabilities of the framework to detect high-severity, high-confidence, long-running test failures.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {360–372},
numpages = {13},
keywords = {differential testing, autonomous system validation, autonomous vehicles},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00153,
author = {Li, Jiageng and Dong, Zhen and Wang, Chong and You, Haozhen and Zhang, Cen and Liu, Yang and Peng, Xin},
title = {LLM Based Input Space Partitioning Testing for Library APIs},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00153},
doi = {10.1109/ICSE55347.2025.00153},
abstract = {Automated library APIs testing is difficult as it requires exploring a vast space of parameter inputs that may involve objects with complex data types. Existing search based approaches, with limited knowledge of relations between object states and program branches, often suffer from the low efficiency issue, i.e., tending to generate invalid inputs. Symbolic execution based approaches can effectively identify such relations, but fail to scale to large programs.In this work, we present an LLM-based input space partitioning testing approach, LISP, for library APIs. The approach leverages LLMs to understand the code of a library API under test and perform input space partitioning based on its understanding and rich common knowledge. Specifically, we provide the signature and code of the API under test to LLMs, with the expectation of obtaining a text description of each input space partition of the API under test. Then, we generate inputs through employing the generated text description to sample inputs from each partition, ultimately resulting in test suites that systematically explore the program behavior of the API.We evaluate LISP on more than 2,205 library API methods taken from 10 popular open-source Java libraries (e.g., apache/commons-lang with 2.6k stars, guava with 48.8k stars on GitHub). Our experiment results show that LISP is effective in library API testing. It significantly outperforms state-of-the-art tool EvoSuite in terms of edge coverage. On average, LISP achieves 67.82% branch coverage, surpassing EvoSuite by 1.21 times. In total, LISP triggers 404 exceptions or errors in the experiments, and discovers 13 previously unknown vulnerabilities during evaluation, which have been assigned CVE IDs.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1436–1448},
numpages = {13},
keywords = {input space partitioning testing, large language models, symbolic execution, API testing},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00128,
author = {Gill, Waris and Anwar, Ali and Gulzar, Muhammad Ali},
title = {TraceFL: Interpretability-Driven Debugging in Federated Learning via Neuron Provenance},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00128},
doi = {10.1109/ICSE55347.2025.00128},
abstract = {In Federated Learning, clients train models on local data and send updates to a central server, which aggregates them into a global model using a fusion algorithm. This collaborative yet privacy-preserving training comes at a cost. FL developers face significant challenges in attributing global model predictions to specific clients. Localizing responsible clients is a crucial step towards (a) excluding clients primarily responsible for incorrect predictions and (b) encouraging clients who contributed high-quality models to continue participating in the future. Existing ML debugging approaches are inherently inapplicable as they are designed for single-model, centralized training.We introduce TraceFL, a fine-grained neuron provenance capturing mechanism that identifies clients responsible for a global model's prediction by tracking the flow of information from individual clients to the global model. Since inference on different inputs activates a different set of neurons of the global model, TraceFL dynamically quantifies the significance of the global model's neurons in a given prediction, identifying the most crucial neurons in the global model. It then maps them to the corresponding neurons in every participating client to determine each client's contribution, ultimately localizing the responsible client. We evaluate TraceFL on six datasets, including two real-world medical imaging datasets and four neural networks, including advanced models such as GPT. TraceFL achieves 99% accuracy in localizing the responsible client in FL tasks spanning both image and text classification tasks. At a time when state-of-the-art ML debugging approaches are mostly domain-specific (e.g., image classification only), TraceFL is the first technique to enable highly accurate automated reasoning across a wide range of FL applications.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2264–2276},
numpages = {13},
keywords = {interpretability, explainability, debugging, machine learning, federated learning, transformer},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00117,
author = {Zhang, Mengxiao and Xu, Zhenyang and Tian, Yongqiang and Cheng, Xinru and Sun, Chengnian},
title = {Toward a Better Understanding of Probabilistic Delta Debugging},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00117},
doi = {10.1109/ICSE55347.2025.00117},
abstract = {Given a list L of elements and a property ψ that L exhibits, ddmin is a classic test input minimization algorithm that aims to automatically remove ψ-irrelevant elements from L. This algorithm has been widely adopted in domains such as test input minimization and software debloating. Recently, ProbDD, a variant of ddmin, has been proposed and achieved state-of-the-art performance. By employing Bayesian optimization, ProbDD estimates the probability of each element in L being relevant to ψ, and statistically decides which and how many elements should be deleted together each time. However, the theoretical probabilistic model of ProbDD is rather intricate, and the underlying details for the superior performance of ProbDD have not been adequately explored.In this paper, we conduct the first in-depth theoretical analysis of ProbDD, clarifying the trends in probability and subset size changes and simplifying the probability model. We complement this analysis with empirical experiments, including success rate analysis, ablation studies, and examinations of trade-offs and limitations, to further comprehend and demystify this state-of-the-art algorithm. Our success rate analysis reveals how ProbDD effectively addresses bottlenecks that slow down ddmin by skipping inefficient queries that attempt to delete complements of subsets and previously tried subsets. The ablation study illustrates that randomness in ProbDD has no significant impact on efficiency. These findings provide valuable insights for future research and applications of test input minimization algorithms.Based on the findings above, we propose CDD, a simplified version of ProbDD, reducing the complexity in both theory and implementation. CDD assists in ① validating the correctness of our key findings, e.g., that probabilities in ProbDD essentially serve as monotonically increasing counters for each element, and ② identifying the main factors that truly contribute to ProbDD's superior performance. Our comprehensive evaluations across 76 benchmarks in test input minimization and software debloating demonstrate that CDD can achieve the same performance as ProbDD, despite being much simplified.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2024–2035},
numpages = {12},
keywords = {program reduction, delta debugging, software debloating, test input minimization},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00114,
author = {Cheng, Mingfei and Xie, Xiaofei and Zhou, Yuan and Wang, Junjie and Meng, Guozhu and Yang, Kairui},
title = {Decictor: Towards Evaluating the Robustness of Decision-Making in Autonomous Driving Systems},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00114},
doi = {10.1109/ICSE55347.2025.00114},
abstract = {Autonomous Driving System (ADS) testing is crucial in ADS development, with the current primary focus being on safety. However, the evaluation of non-safety-critical performance, particularly the ADS's ability to make optimal decisions and produce optimal paths for autonomous vehicles (AVs), is also vital to ensure the intelligence and reduce risks of AVs. Currently, there is little work dedicated to assessing the robustness of ADSs' path-planning decisions (PPDs), i.e., whether an ADS can maintain the optimal PPD after an insignificant change in the environment. The key challenges include the lack of clear oracles for assessing PPD optimality and the difficulty in searching for scenarios that lead to non-optimal PPDs. To fill this gap, in this paper, we focus on evaluating the robustness of ADSs' PPDs and propose the first method, Decictor, for generating non-optimal decision scenarios (NoDSs), where the ADS does not plan optimal paths for AVs. Decictor comprises three main components: Non-invasive Mutation, Consistency Check, and Feedback. To overcome the oracle challenge, Non-invasive Mutation is devised to implement conservative modifications, ensuring the preservation of the original optimal path in the mutated scenarios. Subsequently, the Consistency Check is applied to determine the presence of non-optimal PPDs by comparing the driving paths in the original and mutated scenarios. To deal with the challenge of large environment space, we design Feedback metrics that integrate spatial and temporal dimensions of the AV's movement. These metrics are crucial for effectively steering the generation of NoDSs. Therefore, Decictor can generate NoDSs by generating new scenarios and then identifying NoDSs in the new scenarios. We evaluate Decictor on Baidu Apollo, an open-source and production-grade ADS. The experimental results validate the effectiveness of Decictor in detecting non-optimal PPDs of ADSs. It generates 63.9 NoDSs in total, while the best-performing baseline only detects 35.4 NoDSs.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {424–436},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00098,
author = {Hossain, Soneya Binta and Dwyer, Matthew B.},
title = {TOGLL: Correct and Strong Test Oracle Generation with LLMs},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00098},
doi = {10.1109/ICSE55347.2025.00098},
abstract = {Test oracles play a crucial role in software testing, enabling effective bug detection. Despite initial promise, neural methods for automated test oracle generation often result in a large number of false positives and weaker test oracles. While LLMs have shown impressive effectiveness in various software engineering tasks, including code generation, test case creation, and bug fixing, there remains a notable absence of large-scale studies exploring their effectiveness in test oracle generation. The question of whether LLMs can address the challenges in effective oracle generation is both compelling and requires thorough investigation.In this research, we present the first comprehensive study to investigate the capabilities of LLMs in generating correct, diverse, and strong test oracles capable of effectively identifying a large number of unique bugs. To this end, we fine-tuned seven code LLMs using six distinct prompts on a large dataset consisting of 110 Java projects. Utilizing the most effective fine-tuned LLM and prompt pair, we introduce TOGLL, a novel LLM-based method for test oracle generation. To investigate the generalizability of TOGLL, we conduct studies on 25 unseen large-scale Java projects. Besides assessing the correctness, we also assess the diversity and strength of the generated oracles. We compare the results against EvoSuite and the state-of-the-art neural method, TOGA. Our findings reveal that TOGLL can produce 3.8 times more correct assertion oracles and 4.9 times more exception oracles than TOGA. Regarding bug detection effectiveness, TOGLL can detect 1,023 unique mutants that EvoSuite cannot, which is ten times more than what TOGA can detect. Additionally, TOGLL significantly outperforms TOGA in detecting real bugs from the Defects4J dataset.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1475–1487},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00088,
author = {Chen, Boqi and L\'{o}pez, Jos\'{e} Antonio Hern\'{a}ndez and Mussbacher, Gunter and Varr\'{o}, D\'{a}niel},
title = {The Power of Types: Exploring the Impact of Type Checking on Neural Bug Detection in Dynamically Typed Languages},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00088},
doi = {10.1109/ICSE55347.2025.00088},
abstract = {[Motivation] Automated bug detection in dynamically typed languages such as Python is essential for maintaining code quality. The lack of mandatory type annotations in such languages can lead to errors that are challenging to identify early with traditional static analysis tools. Recent progress in deep neural networks has led to increased use of neural bug detectors. In statically typed languages, a type checker is integrated into the compiler and thus taken into consideration when the neural bug detector is designed for these languages.[Problem] However, prior studies overlook this aspect during the training and testing of neural bug detectors for dynamically typed languages. When an optional type checker is used, assessing existing neural bug detectors on bugs easily detectable by type checkers may impact their performance estimation. Moreover, including these bugs in the training set of neural bug detectors can shift their detection focus toward the wrong type of bugs.[Contribution] We explore the impact of type checking on various neural bug detectors for variable misuse bugs, a common type targeted by neural bug detectors. Existing synthetic and real-world datasets are type-checked to evaluate the prevalence of type-related bugs. Then, we investigate how type-related bugs influence the training and testing of the neural bug detectors.[Findings] Our findings indicate that existing bug detection datasets contain a significant proportion of type-related bugs. Building on this insight, we discover integrating the neural bug detector with a type checker can be beneficial, especially when the code is annotated with types. Further investigation reveals neural bug detectors perform better on type-related bugs than other bugs. Moreover, removing type-related bugs from the training data helps improve neural bug detectors' ability to identify bugs beyond the scope of type checkers.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {489–501},
numpages = {13},
keywords = {type checking, neural bug detection, dynamically typed languages},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00078,
author = {Qin, Qiaolin and Li, Heng and Merlo, Ettore and Lamothe, Maxime},
title = {Automated, Unsupervised, and Auto-Parameterized Inference of Data Patterns and Anomaly Detection},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00078},
doi = {10.1109/ICSE55347.2025.00078},
abstract = {With the advent of data-centric and machine learning (ML) systems, data quality is playing an increasingly critical role for ensuring the overall quality of software systems. Data preparation, an essential step towards high data quality, is known to be a highly effort-intensive process. Although prior studies have dealt with one of the most impacting issues, data pattern violations, these studies usually require data-specific configurations (i.e., parameterized) or use carefully curated data as learning examples (i.e., supervised), relying on domain knowledge and deep understanding of the data, or demanding significant manual effort. In this paper, we introduce RIOLU: Regex Inferencer autO-parameterized Learning with Uncleaned data. RIOLU is fully automated, automatically parameterized, and does not need labeled samples. RIOLU can generate precise patterns from datasets in various domains, with a high F1 score of 97.2%, exceeding the state-of-the-art baseline. In addition, according to our experiment on five datasets with anomalies, RIOLU can automatically estimate a data column's error rate, draw normal patterns, and predict anomalies from unlabeled data with higher performance (up to 800.4% improvement in terms of F1) than the state-of-the-art baseline, even outperforming ChatGPT in terms of both accuracy (12.3% higher F1) and efficiency (10% less inference time). A variant of RIOLU, with user guidance, can further boost its precision, with up to 37.4% improvement in terms of F1. Our evaluation in an industrial setting further demonstrates the practical benefits of RIOLU.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2419–2431},
numpages = {13},
keywords = {pattern anomaly detection, pattern-based data profiling, unsupervised learning, supervised learning},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00074,
author = {Zhang, Shiyu and Song, Haoyang and Wang, Qixin and Shen, Henghua and Pei, Yu},
title = {A Test Oracle for Reinforcement Learning Software Based on Lyapunov Stability Control Theory},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00074},
doi = {10.1109/ICSE55347.2025.00074},
abstract = {Reinforcement Learning (RL) has gained significant attention in recent years. As RL software becomes more complex and infiltrates critical application domains, ensuring its quality and correctness becomes increasingly important. An indispensable aspect of software quality/correctness insurance is testing. However, testing RL software faces unique challenges compared to testing traditional software, due to the difficulty on defining the outputs' correctness. This leads to the RL test oracle problem. Current approaches to testing RL software often rely on human oracles, i.e. convening human experts to judge the correctness of RL software outputs. This heavily depends on the availability and quality (including the experiences, subjective states, etc.) of the human experts, and cannot be fully automated. In this paper, we propose a novel approach to design test oracles for RL software by leveraging the Lyapunov stability control theory. By incorporating Lyapunov stability concepts to guide RL training, we hypothesize that a correctly implemented RL software shall output an agent that respects Lyapunov stability control theories. Based on this heuristics, we propose a Lyapunov stability control theory based oracle, LPEA(ϑ, θ), for testing RL software. We conduct extensive experiments over representative RL algorithms and RL software bugs to evaluate our proposed oracle. The results show that our proposed oracle can outperform the human oracle in most metrics. Particularly, LPEA(ϑ = 100%, θ = 75%) outperforms the human oracle by 53.6%, 50%, 18.4%, 34.8%, 18.4%, 127.8%, 60.5%, 38.9%, and 31.7% respectively on accuracy, precision, recall, F1 score, true positive rate, true negative rate, false positive rate, false negative rate, and ROC curve's AUC; and LPEA(ϑ = 100%, θ = 50%) outperforms the human oracle by 48.2%, 47.4%, 10.5%, 29.1%, 10.5%, 127.8%, 60.5%, 22.2%, and 26.0% respectively on these metrics.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {502–513},
numpages = {12},
keywords = {reinforcement learning, test oracle},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00016,
author = {Kim, Brian Hyeongseok and Wang, Jingbo and Wang, Chao},
title = {FairQuant: Certifying and Quantifying Fairness of Deep Neural Networks},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00016},
doi = {10.1109/ICSE55347.2025.00016},
abstract = {We propose a method for formally certifying and quantifying individual fairness of deep neural networks (DNN). Individual fairness guarantees that any two individuals who are identical except for a legally protected attribute (e.g., gender or race) receive the same treatment. While there are existing techniques that provide such a guarantee, they tend to suffer from lack of scalability or accuracy as the size and input dimension of the DNN increase. Our method overcomes this limitation by applying abstraction to a symbolic interval based analysis of the DNN followed by iterative refinement guided by the fairness property. Furthermore, our method lifts the symbolic interval based analysis from conventional qualitative certification to quantitative certification, by computing the percentage of individuals whose classification outputs are provably fair, instead of merely deciding if the DNN is fair. We have implemented our method and evaluated it on deep neural networks trained on four popular fairness research datasets. The experimental results show that our method is not only more accurate than state-of-the-art techniques but also several orders-of-magnitude faster.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {527–539},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00007,
author = {Pedro, Rodrigo and Coimbra, Miguel E. and Castro, Daniel and Carreira, Paulo and Santos, Nuno},
title = {Prompt-to-SQL Injections in LLM-Integrated Web Applications: Risks and Defenses},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00007},
doi = {10.1109/ICSE55347.2025.00007},
abstract = {Large Language Models (LLMs) have found widespread applications in various domains, including web applications with chatbot interfaces. Aided by an LLM-integration middleware such as LangChain, user prompts are translated into SQL queries used by the LLM to provide meaningful responses to users. However, unsanitized user prompts can lead to SQL injection attacks, potentially compromising the security of the database. In this paper, we present a comprehensive examination of prompt-to-SQL (P2SQL) injections targeting web applications based on frameworks such as LangChain and LlamaIndex. We characterize P2SQL injections, exploring their variants and impact on application security through multiple concrete examples. We evaluate seven state-of-the-art LLMs, demonstrating the risks of P2SQL attacks across language models. By employing both manual and automated methods, we discovered P2SQL vulnerabilities in five real-world applications. Our findings indicate that LLM-integrated applications are highly susceptible to P2SQL injection attacks, warranting the adoption of robust defenses. To counter these attacks, we propose four effective defense techniques that can be integrated as extensions to the LangChain framework.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1768–1780},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00241,
author = {Saha, Antu and Chaparro, Oscar},
title = {Decoding the Issue Resolution Process in Practice via Issue Report Analysis: A Case Study of Firefox},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00241},
doi = {10.1109/ICSE55347.2025.00241},
abstract = {Effectively managing and resolving software issues is critical for maintaining and evolving software systems. Development teams often rely on issue trackers and issue reports to track and manage the work needed during issue resolution, ranging from issue reproduction and analysis to solution design, implementation, verification, and deployment. Despite the issue resolution process being generally known in the software engineering community as a sequential list of activities, it is unknown how developers implement this process in practice and how they discuss it in issue reports. This paper aims to enhance our understanding of the issue resolution process implemented in practice by analyzing the issue reports of Mozilla Firefox. We qualitatively and quantitatively analyzed the discussions found in 356 Firefox issue reports, to identify the sequences of stages that developers go through to address various software problems. We analyzed the sequences to identify the overall resolution process at Firefox and derived a catalog of 47 patterns that represent instances of the process. We analyzed the process and patterns across multiple dimensions, including pattern complexity, issue report types, problem categories, and issue resolution times, resulting in various insights about Mozilla's issue resolution process. We discuss these findings and their implications for different stakeholders on how to better assess and improve the issue resolution process.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2316–2328},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00204,
author = {Shao, Yuchen and Huang, Yuheng and Shen, Jiawei and Ma, Lei and Su, Ting and Wan, Chengcheng},
title = {Are LLMs Correctly Integrated into Software Systems?},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00204},
doi = {10.1109/ICSE55347.2025.00204},
abstract = {Large language models (LLMs) provide effective solutions in various application scenarios, with the support of retrieval-augmented generation (RAG). However, developers face challenges in integrating LLM and RAG into software systems, due to lacking interface specifications, various requirements from software context, and complicated system management. In this paper, we have conducted a comprehensive study of 100 open-source applications that incorporate LLMs with RAG support, and identified 18 defect patterns. Our study reveals that 77% of these applications contain more than three types of integration defects that degrade software functionality, efficiency, and security. Guided by our study, we propose systematic guidelines for resolving these defects in software life cycle. We also construct an open-source defect library Hydrangea [1].},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1178–1190},
numpages = {13},
keywords = {LLM, defects, empirical software engineering},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00202,
author = {Kim, Sehoon and Kim, Yonghyeon and Park, Dahyeon and Jeon, Yuseok and Yi, Jooyong and Kim, Mijung},
title = {Lightweight Concolic Testing via Path-Condition Synthesis for Deep Learning Libraries},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00202},
doi = {10.1109/ICSE55347.2025.00202},
abstract = {Many techniques have been recently developed for testing deep learning (DL) libraries. Although these techniques have effectively improved API and code coverage and detected unknown bugs, they rely on blackbox fuzzing for input generation. Concolic testing (also known as dynamic symbolic execution) can be more effective in exploring diverse execution paths, but applying it to DL libraries is extremely challenging due to their inherent complexity. In this paper, we introduce the first concolic testing technique for DL libraries. Our technique offers a lightweight approach that significantly reduces the heavy overhead associated with traditional concolic testing. While symbolic execution maintains symbolic expressions for every variable with non-concrete values to build a path condition, our technique computes approximate path conditions by inferring branch conditions via inductive program synthesis. Despite potential imprecision from approximation, our method's light overhead allows for effective exploration of diverse execution paths within the complex implementations of DL libraries. We have implemented our tool, PathFinder, and evaluated it on PyTorch and TensorFlow. Our results show that PathFinder outperforms existing API-level DL library fuzzers by achieving 67% more branch coverage on average; up to 63% higher than TitanFuzz and 120% higher than FreeFuzz. PathFinder is also effective in bug detection, uncovering 61 crash bugs, 59 of which were confirmed by developers as previously unknown, with 32 already fixed.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2957–2969},
numpages = {13},
keywords = {fuzzing, concolic testing, deep learning libraries},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00194,
author = {Das, Satyaki and Fabiha, Syeda Tasnim and Shafiq, Saad and Medvidovi\'{c}, Nenad},
title = {Are We Learning the Right Features? A Framework for Evaluating DL-Based Software Vulnerability Detection Solutions},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00194},
doi = {10.1109/ICSE55347.2025.00194},
abstract = {Recent research has revealed that the reported results of an emerging body of deep learning-based techniques for detecting software vulnerabilities are not reproducible, either across different datasets or on unseen samples. This paper aims to provide the foundation for properly evaluating the research in this domain. We do so by analyzing prior work and existing vulnerability datasets for the syntactic and semantic features of code that contribute to vulnerability, as well as features that falsely correlate with vulnerability. We provide a novel, uniform representation to capture both sets of features, and use this representation to detect the presence of both vulnerability and spurious features in code. To this end, we design two types of code perturbations: feature preserving perturbations (FPP) ensure that the vulnerability feature remains in a given code sample, while feature eliminating perturbations (FEP) eliminate the feature from the code sample. These perturbations aim to measure the influence of spurious and vulnerability features on the predictions of a given vulnerability detection solution. To evaluate how the two classes of perturbations influence predictions, we conducted a large-scale empirical study on five state-of-the-art DL-based vulnerability detectors. Our study shows that, for vulnerability features, only ~2% of FPPs yield the undesirable effect of a prediction changing among the five detectors on average. However, on average, ~84% of FEPs yield the undesirable effect of retaining the vulnerability predictions. For spurious features, we observed that FPPs yielded a drop in recall up to 29% for graph-based detectors. We present the reasons underlying these results and suggest strategies for improving DNN-based vulnerability detectors. We provide our perturbation-based evaluation framework as a public resource to enable independent future evaluation of vulnerability detectors.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2893–2904},
numpages = {12},
keywords = {vulnerability detection, deep learning, software security, explainable AI},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00175,
author = {Gao, Hongyan and Yang, Yibiao and Sun, Maolin and Wu, Jiangchang and Zhou, Yuming and Xu, Baowen},
title = {ClozeMaster: Fuzzing Rust Compiler by Harnessing LLMs for Infilling Masked Real Programs},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00175},
doi = {10.1109/ICSE55347.2025.00175},
abstract = {Ensuring the reliability of the Rust compiler is of paramount importance, given increasing adoption of Rust for critical systems development, due to its emphasis on memory and thread safety. However, generating valid test programs for the Rust compiler poses significant challenges, given Rust's complex syntax and strict requirements. With the growing popularity of large language models (LLMs), much research in software testing has explored using LLMs to generate test cases. Still, directly using LLMs to generate Rust programs often results in a large number of invalid test cases. Existing studies have indicated that test cases triggering historical compiler bugs can assist in software testing. Our investigation into Rust compiler bug issues supports this observation. Inspired by existing work and our empirical research, we introduce a bracket-based masking and filling strategy called clozeMask. The clozeMask strategy involves extracting test code from historical issue reports, identifying and masking code snippets with specific structures, and using an LLM to fill in the masked portions for synthesizing new test programs. This approach harnesses the generative capabilities of LLMs while retaining the ability to trigger Rust compiler bugs. It enables comprehensive testing of the compiler's behavior, particularly exploring edge cases. We implemented our approach as a prototype ClozeMaster. ClozeMaster has identified 27 confirmed bugs for rustc and mrustc, of which 10 have been fixed by developers. Furthermore, our experimental results indicate that ClozeMaster outperforms existing fuzzers in terms of code coverage and effectiveness.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1422–1435},
numpages = {14},
keywords = {rust compiler, fuzzing, large language model, bug detection},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00172,
author = {Galland, Octavio and B\"{o}hme, Marcel},
title = {Invivo Fuzzing by Amplifying Actual Executions},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00172},
doi = {10.1109/ICSE55347.2025.00172},
abstract = {A major bottleneck that remains when fuzzing software libraries is the need for fuzz drivers, i.e., the glue code between the fuzzer and the library. Despite years of fuzzing, critical security flaws are still found, e.g., by manual auditing, because the fuzz drivers do not cover the complex interactions between the library and the host programs using it.In this work we propose an alternative approach to library fuzzing, which leverages a valid execution context that is set up by a given program using the library (the host), and amplify its execution. More specifically, we execute the host until a designated function from a list of target functions has been reached, and then perform coverage-guided function-level fuzzing on it. Once the fuzzing quota is exhausted, we move on to fuzzing the next target from the list. In this way we not only reduce the amount of manual work needed by a developer to incorporate fuzzing into their workflow, but we also allow the fuzzer to explore parts of the library as they are used in real-world programs that may otherwise not have been tested due to the simplicity of most fuzz drivers.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1566–1578},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00167,
author = {McCormack, Ian and Sunshine, Joshua and Aldrich, Jonathan},
title = {A Study of Undefined Behavior across Foreign Function Boundaries in Rust Libraries},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00167},
doi = {10.1109/ICSE55347.2025.00167},
abstract = {Developers rely on the static safety guarantees of the Rust programming language to write secure and performant applications. However, Rust is frequently used to interoperate with other languages which allow design patterns that conflict with Rust's evolving aliasing models. Miri is currently the only dynamic analysis tool that can validate applications against these models, but it does not support finding bugs in foreign functions, indicating that there may be a critical correctness gap across the Rust ecosystem. We conducted a large-scale evaluation of Rust libraries that call foreign functions to determine whether Miri's dynamic analyses remain useful in this context. We used Miri and an LLVM interpreter to jointly execute applications that call foreign functions, where we found 46 instances of undefined or undesired behavior in 37 libraries. Three bugs were found in libraries that had more than 10,000 daily downloads on average during our observation period, and one was found in a library maintained by the Rust Project. Many of these bugs were violations of Rust's aliasing models, but the latest Tree Borrows model was significantly more permissive than the earlier Stacked Borrows model. The Rust community must invest in new, production-ready tooling for multi-language applications to ensure that developers can detect these errors.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2075–2086},
numpages = {12},
keywords = {rust, interoperation, undefined behavior, aliasing, bugs, foreign functions},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00160,
author = {Zhang, Changjian and Kapoor, Parv and Dardik, Ian and Cui, Leyi and Meira-G\'{o}es, R\^{o}mulo and Garlan, David and Kang, Eunsuk},
title = {Constrained LTL Specification Learning from Examples},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00160},
doi = {10.1109/ICSE55347.2025.00160},
abstract = {Temporal logic specifications play an important role in a wide range of software analysis tasks, such as model checking, automated synthesis, program comprehension, and runtime monitoring. Given a set of positive and negative examples, specified as traces, LTL learning is the problem of synthesizing a specification, in linear temporal logic (LTL), that evaluates to true over the positive traces and false over the negative ones. In this paper, we propose a new type of LTL learning problem called constrained LTL learning, where the user, in addition to positive and negative examples, is given an option to specify one or more constraints over the properties of the LTL formula to be learned. We demonstrate that the ability to specify these additional constraints significantly increases the range of applications for LTL learning, and also allows efficient generation of LTL formulas that satisfy certain desirable properties (such as minimality). We propose an approach for solving the constrained LTL learning problem through an encoding in first-order relational logic and reduction to an instance of the maximal satisfiability (MaxSAT) problem. An experimental evaluation demonstrates that ATLAS, an implementation of our proposed approach, is able to solve new types of learning problems while performing better than or competitively with the state-of-the-art tools in LTL learning.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {629–641},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00152,
author = {Liu, Qikang and He, Yang and Cai, Yanwen and Kwak, Byeongguk and Wang, Yuepeng},
title = {Synthesizing Document Database Queries Using Collection Abstractions},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00152},
doi = {10.1109/ICSE55347.2025.00152},
abstract = {Document databases are increasingly popular in various applications, but their queries are challenging to write due to the flexible and complex data model underlying document databases. This paper presents a synthesis technique that aims to generate document database queries from input-output examples automatically. A new domain-specific language is designed to express a representative set of document database queries in an algebraic style. Furthermore, the synthesis technique leverages a novel abstraction of collections for deduction to efficiently prune the search space and quickly generate the target query. An evaluation of 110 benchmarks from various sources shows that the proposed technique can synthesize 108 benchmarks successfully. On average, the synthesizer can generate document database queries from a small number of input-output examples within tens of seconds.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {476–488},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00150,
author = {Du, Hang and Palepu, Vijay Krishna and Jones, James A.},
title = {Leveraging Propagated Infection to Crossfire Mutants},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00150},
doi = {10.1109/ICSE55347.2025.00150},
abstract = {Mutation testing was proposed to identify weaknesses in test suites by repeatedly generating artificially faulty versions of the software (i.e., mutants) and determining if the test suite is sufficient to detect them (i.e., kill them). When the tests are insufficient, each surviving mutant provides an opportunity to improve the test suite. We conducted a study and found that many such surviving mutants (up to 84% for the subjects of our study) are detectable by simply augmenting existing tests with additional assertions, or assertion amplification. Moreover, we find that many of these mutants are detectable by multiple existing tests, giving developers options for how to detect them. To help with these challenges, we created a technique that performs memory-state analysis to identify candidate assertions that developers can use to detect the surviving mutants. Additionally, we build upon prior research that identifies "crossfiring" opportunities — tests that coincidentally kill multiple mutants. To this end, we developed a theoretical model that describes the varying granularities that crossfiring can occur in the existing test suite, which provide opportunities and options for how to kill surviving mutants. We operationalize this model to an accompanying technique that optimizes the assertion amplification of the existing tests to crossfire multiple mutants with fewer added assertions, optionally concentrated within fewer tests. Our experiments show that we can kill all surviving mutants that are detectable with existing test data with only 1.1% of the identified assertion candidates, and increasing by a factor of 6x, on average, the number of killed mutants from amplified tests, over tests that do not crossfire.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {3136–3148},
numpages = {13},
keywords = {mutation testing, test amplification},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00137,
author = {Zappin, Jake and Stalnaker, Trevor and Chaparro, Oscar and Poshyvanyk, Denys},
title = {When Quantum Meets Classical: Characterizing Hybrid Quantum-Classical Issues Discussed in Developer Forums},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00137},
doi = {10.1109/ICSE55347.2025.00137},
abstract = {Recent advances in quantum computing have sparked excitement that this new computing paradigm could solve previously intractable problems. However, due to the faulty nature of current quantum hardware and quantum-intrinsic noise, the full potential of quantum computing is still years away. Hybrid quantum-classical computing has emerged as a possible compromise that achieves the best of both worlds. In this paper, we look at hybrid quantum-classical computing from a software engineering perspective and present the first empirical study focused on characterizing and evaluating recurrent issues faced by developers of hybrid quantum-classical applications. The study comprised a thorough analysis of 531 real-world issues faced by developers - including software faults, hardware failures, quantum library errors, and developer mistakes - documented in discussion threads from forums dedicated to quantum computing. By qualitatively analyzing such forum threads, we derive a comprehensive taxonomy of recurring issues in hybrid quantum-classical applications that can be used by both application and platform developers to improve the reliability of hybrid applications. The study considered how these recurring issues manifest and their causes, determining that hybrid applications are crash-dominant (74% of studied issues) and that errors were predominantly introduced by application developers (70% of issues). We conclude by identifying recurring obstacles for developers of hybrid applications and actionable recommendations to overcome them.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2931–2943},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00126,
author = {Steenhoek, Benjamin and Sivaraman, Kalpathy and Gonzalez, Renata Saldivar and Mohylevskyy, Yevhen and Moghaddam, Roshanak Zilouchian and Le, Wei},
title = {Closing the Gap: A User Study on the Real-World Usefulness of AI-Powered Vulnerability Detection &amp; Repair in the IDE},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00126},
doi = {10.1109/ICSE55347.2025.00126},
abstract = {Security vulnerabilities impose significant costs on users and organizations. Detecting and addressing these vulnerabilities early is crucial to avoid exploits and reduce development costs. Recent studies have shown that deep learning models can effectively detect security vulnerabilities. Yet, little research explores how to adapt these models from benchmark tests to practical applications, and whether they can be useful in practice.This paper presents the first empirical study of a vulnerability detection and fix tool with professional software developers on real projects that they own. We implemented DeepVulGuard, an IDE-integrated tool based on state-of-the-art detection and fix models, and show that it has promising performance on benchmarks of historic vulnerability data. DeepVulGuard scans code for vulnerabilities (including identifying the vulnerability type and vulnerable region of code), suggests fixes, provides natural-language explanations for alerts and fixes, leveraging chat interfaces. We recruited 17 professional software developers at Microsoft, observed their usage of the tool on their code, and conducted interviews to assess the tool's usefulness, speed, trust, relevance, and workflow integration. We also gathered detailed qualitative feedback on users' perceptions and their desired features. Study participants scanned a total of 24 projects, 6.9k files, and over 1.7 million lines of source code, and generated 170 alerts and 50 fix suggestions. We find that although state-of-the-art AI-powered detection and fix tools show promise, they are not yet practical for real-world use due to a high rate of false positives and non-applicable fixes. User feedback reveals several actionable pain points, ranging from incomplete context to lack of customization for the user's codebase. Additionally, we explore how AI features, including confidence scores, explanations, and chat interaction, can apply to vulnerability detection and fixing. Based on these insights, we offer practical recommendations for evaluating and deploying AI detection and fix models. Our code and data are available at this link: https://doi.org/10.6084/m9.figshare.26367139.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2650–2662},
numpages = {13},
keywords = {deep learning, vulnerability detection, vulnerability repair, IDE, user study},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00102,
author = {Patel, Smit and Yadavally, Aashish and Dhulipala, Hridya and Nguyen, Tien N.},
title = {Planning a Large Language Model for Static Detection of Runtime Errors in Code Snippets},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00102},
doi = {10.1109/ICSE55347.2025.00102},
abstract = {Large Language Models (LLMs) have been excellent in generating and reasoning about source code and natural-language texts. They can recognize patterns, syntax, and semantics in code, making them effective in several software engineering tasks. However, they exhibit weaknesses in reasoning about the program execution. They primarily operate on static code representations, failing to capture the dynamic behavior and state changes that occur during program execution.In this paper, we advance the capabilities of LLMs in reasoning about dynamic program behaviors. We propose Orca, a novel approach that instructs an LLM to autonomously formulate a plan to navigate through a control flow graph (CFG) for predictive execution of (in)complete code snippets. It acts as a predictive interpreter to "execute" the code. In Orca, we guide the LLM to pause at the branching point, focusing on the state of the symbol tables for variables' values, thus minimizing error propagation in the LLM's computation. We instruct the LLM not to stop at each step in its execution plan, resulting the use of only one prompt for the entire predictive interpreter, thus much cost-saving. As a downstream task, we use Orca to statically identify any runtime errors for online code snippets. Early detection of runtime errors and defects in these snippets is crucial to prevent costly fixes later in the development cycle after they were adapted into a codebase. Our empirical evaluation showed that Orca is effective and improves over the state-of-the-art approaches in predicting the execution traces and in static detection of runtime errors.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {872–884},
numpages = {13},
keywords = {large language model (LLM) planning, execution prediction, runtime error static detection},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00100,
author = {Batole, Fraol and OBrien, David and Nguyen, Tien N. and Dyer, Robert and Rajan, Hridesh},
title = {An LLM-Based Agent-Oriented Approach for Automated Code Design Issue Localization},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00100},
doi = {10.1109/ICSE55347.2025.00100},
abstract = {Maintaining software design quality is crucial for the long-term maintainability and evolution of systems. However, design issues such as poor modularity and excessive complexity often emerge as codebases grow. Developers rely on external tools, such as program analysis techniques, to identify such issues. This work leverages Large Language Models (LLMs) to develop an automated approach for analyzing and localizing design issues.Large language models have demonstrated significant performance on coding tasks, but directly leveraging them for design issue localization is challenging. Large codebases exceed typical LLM context windows, and program analysis tool outputs in non-textual modalities (e.g., graphs or interactive visualizations) are incompatible with LLMs' natural language inputs.To address these challenges, we propose LocalizeAgent, a novel multi-agent framework for effective design issue localization. LocalizeAgent integrates the specialized agents that (1) analyze code to identify potential code design issues, (2) transform program analysis outputs into abstraction-aware LLM-friendly natural language summaries, (3) generate context-aware prompts tailored to specific refactoring types, and (4) leverage LLMs to locate and rank the localized issues based on their relevance.Our evaluation using diverse real-world codebases demonstrates significant improvements over the baseline approaches, with LocalizeAgent achieving 138%, 166%, and 206% relative improvements in exact-match accuracy for localizing information hiding, complexity, and modularity issues, respectively.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1320–1332},
numpages = {13},
keywords = {large language models (LLMS), multi-agent, static program analysis, code design issue localization},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00085,
author = {Kim, Wonhoi and Nam, Hocheol and Tran, Muoi and Jalilov, Amin and Liang, Zhenkai and Cha, Sang Kil and Kang, Min Suk},
title = {Fork State-Aware Differential Fuzzing for Blockchain Consensus Implementations},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00085},
doi = {10.1109/ICSE55347.2025.00085},
abstract = {Blockchain networks allow multiple client implementations of the same consensus algorithm by different developers to coexist in the same system. Ensuring correct implementations among these heterogeneous clients is crucial, as even slight semantic discrepancies in their implementations can lead to safety failures. While existing fuzzing frameworks have discovered implementation flaws in blockchain, they suffer from several challenges in testing them with sequences of conflicting blocks, called forks. Existing tools fail to adequately assess the fork-handling processes in blockchain implementations when relying on traditional code coverage feedback, which lacks the granularity needed to navigate the diverse and complex fork-handling scenarios. This paper introduces Forky, a fork state-aware differential fuzzing framework designed to detect implementation discrepancies within the critical fork-handling process with its novel fork-aware mutation and fork-diversifying feedback mechanisms. We test Forky on the two most influential blockchain projects: Bitcoin and Ethereum, which are the representatives of the two major blockchain consensus algorithm families, Proof-of-Work (PoW) and Proof-of-Stake (PoS) consensus algorithms.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {3048–3059},
numpages = {12},
keywords = {blockchain, consensus, differential fuzzing},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00079,
author = {Silva, Nabson Paiva Souza da and Rodrigues, Eriky and Conte, Tayana},
title = {A Catalog of Micro Frontends Anti-Patterns},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00079},
doi = {10.1109/ICSE55347.2025.00079},
abstract = {Micro frontend (MFE) architectures have gained significant popularity for promoting independence and modularity in development. Despite their widespread adoption, the field remains relatively unexplored, especially concerning identifying problems and documenting best practices. Drawing on both established microservice (MS) anti-patterns and the analysis of real problems faced by software development teams that adopt MFE, this paper presents a catalog of 12 MFE anti-patterns. We composed an initial version of the catalog by recognizing parallels between MS anti-patterns and recurring issues in MFE projects to map and adapt MS anti-patterns to the context of MFE. To validate the identified problems and proposed solutions, we conducted a survey with industry practitioners, collecting valuable feedback to refine the anti-patterns. Additionally, we asked participants if they had encountered these problems in practice and to rate their harmfulness on a 10-point Likert scale. The survey results revealed that participants had encountered all the proposed anti-patterns in real-world MFE architectures, with only one reported by less than 50% of participants. They stated that the catalog can serve as a valuable guide for both new and experienced developers, with the potential to enhance MFE development quality. The collected feedback led to the development of an improved version of the anti-patterns catalog. Furthermore, we developed a web application designed to not only showcase the anti-patterns but also to actively foster collaboration and engagement within the MFE community. The proposed catalog is a valuable resource for identifying and mitigating potential pitfalls in MFE development. It empowers developers of all experience levels to create more robust, maintainable, and well-designed MFE applications.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2151–2162},
numpages = {12},
keywords = {micro frontends, microservices, anti-patterns, software architecture, empirical study},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00075,
author = {Zhang, Chenxi and Liang, Yufei and Tan, Tian and Xu, Chang and Kan, Shuangxiang and Sui, Yulei and Li, Yue},
title = {Interactive Cross-Language Pointer Analysis For Resolving Native Code in Java Programs},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00075},
doi = {10.1109/ICSE55347.2025.00075},
abstract = {Java offers the Java Native Interface (JNI), which allows programs running in the Java Virtual Machine to invoke and be manipulated by native applications and libraries written in other languages, typically C. While JNI mechanism significantly enhances the Java platform's capabilities, it also presents challenges for static analysis of Java programs due to the complex behaviors introduced by native code. Therefore, effectively resolving the interactions between Java and native code is crucial for static analysis. In this paper, we introduce JNIFER, the first interactive cross-language pointer analysis for resolving native code in Java programs. JNIFER integrates both Java and C pointer analyses, equipped with advanced native call and JNI function analyses, enabling the simultaneous analysis of both Java and native code. During the analysis of cross-language interactions, the two analyzers interact with each other, constructing cross-language points-to relations and call graphs, thereby approximating the runtime behavior at the interaction sites. Our evaluation shows that JNIFER outperforms state-of-the-art approaches in terms of soundness while maintaining high precision and comparable efficiency, as evidenced by extensive experiments on OpenJDK and real-world Java applications.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1089–1100},
numpages = {12},
keywords = {java native interface, native code, pointer analysis, cross-language analysis},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00071,
author = {Zhou, Xintong and Xu, Zhenyang and Zhang, Mengxiao and Tian, Yongqiang and Sun, Chengnian},
title = {WDD: Weighted Delta Debugging},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00071},
doi = {10.1109/ICSE55347.2025.00071},
abstract = {Delta Debugging is a widely used family of algorithms (e.g., ddmin and ProbDD) to automatically minimize bugtriggering test inputs, thus to facilitate debugging. It takes a list of elements with each element representing a fragment of the test input, systematically partitions the list at different granularities, identifies and deletes bug-irrelevant partitions.Prior delta debugging algorithms assume there are no differences among the elements in the list, and thus treat them uniformly during partitioning. However, in practice, this assumption usually does not hold, because the size (referred to as weight) of the fragment represented by each element can vary significantly. For example, a single element representing 50% of the test input is much more likely to be bug-relevant than elements representing only 1%. This assumption inevitably impairs the efficiency or even effectiveness of these delta debugging algorithms.This paper proposes Weighted Delta Debugging (WDD), a novel concept to help prior delta debugging algorithms overcome the limitation mentioned above. The key insight of WDD is to assign each element in the list a weight according to its size, and distinguish different elements based on their weights during partitioning. We designed two new minimization algorithms, Wddmin and WProbDD, by applying WDD to ddmin and ProbDD respectively. We extensively evaluated Wddmin and WProbDD in two representative applications, HDD and Perses, on 62 benchmarks across two languages. On average, with Wddmin, HDD and Perses took 51.31% and 7.47% less time to generate 9.12% and 0.96% smaller results than with ddmin, respectively. With WProbDD, HDD and Perses used 11.98% and 9.72% less time to generate 13.40% and 2.20% smaller results than with ProbDD, respectively. The results strongly demonstrate the value of WDD. We firmly believe that WDD opens up a new dimension to improve test input minimization techniques.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1592–1603},
numpages = {12},
keywords = {test input minimization, delta debugging, program reduction},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00221,
author = {Zhang, Lingfeng and Wang, Zhaohui and Zhang, Yueling and Zhang, Min and Wang, Jiangtao},
title = {HIFI: Explaining and Mitigating Algorithmic Bias through the Lens of Game-Theoretic Interactions},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00221},
doi = {10.1109/ICSE55347.2025.00221},
abstract = {Machine Learning (ML) algorithms are increasingly used in decision-making process across various social-critical domains, but they often somewhat inherit and amplify bias from their training data, leading to unfair and unethical outcomes. This issue highlights the urgent need for effective methods to detect, explain, and mitigate bias to ensure the fairness of ML systems. Previous studies are prone to analyze the root causes of algorithmic bias from a statistical perspective. However, to the best of our knowledge, none of them has discussed how sensitive information inducing the final discriminatory decision is encoded by ML models. In this work, we attempt to explain and mitigate algorithmic bias from a game-theoretic view. We mathematically decode an essential and common component of sensitive information implicitly defined by various fairness metrics with Harsanyi interactions, and on this basis, we propose an in-processing method HIFI for bias mitigation. We conduct an extensive evaluation of HIFI with 11 state-of-the-art methods, 5 real-world datasets, 4 fairness criteria, and 5 ML performance metrics, while also considering intersectional fairness for multiple protected attributes. The results show that HIFI surpasses state-of-the-art in-processing methods in terms of fairness improvement and fairness-performance trade-off, and also achieves notable effectiveness in reducing violations of individual fairness simultaneously.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {756–768},
numpages = {13},
keywords = {algorithmic bias, fairness, bias mitigation, game-theoretic interaction, explainable artificial intelligence},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00181,
author = {Chi, Zhiming and Ma, Jianan and Yang, Pengfei and Huang, Cheng-Chao and Li, Renjue and Wang, Jingyi and Huang, Xiaowei and Zhang, Lijun},
title = {Patch Synthesis for Property Repair of Deep Neural Networks},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00181},
doi = {10.1109/ICSE55347.2025.00181},
abstract = {Deep neural networks (DNNs) are prone to various dependability issues, such as adversarial attacks, which hinder their adoption in safety-critical domains. Recently, NN repair techniques have been proposed to address these issues while preserving original performance by locating and modifying guilty neurons and their parameters. However, existing repair approaches are often limited to specific data sets and do not provide theoretical guarantees for the effectiveness of the repairs. To address these limitations, we introduce PatchPro, a novel patch-based approach for property-level repair of DNNs, focusing on local robustness. The key idea behind PatchPro is to construct patch modules that, when integrated with the original network, provide specialized repairs for all samples within the robustness neighborhood while maintaining the network's original performance. Our method incorporates formal verification and a heuristic mechanism for allocating patch modules, enabling it to defend against adversarial attacks and generalize to other inputs. PatchPro demonstrates superior efficiency, scalability, and repair success rates compared to existing DNN repair methods, i.e., realizing provable property-level repair for 100% cases across multiple high-dimensional datasets.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1191–1203},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00171,
author = {Amjad, Abdul Haddi and Danish, Muhammad and Jah, Bless and Gulzar, Muhammad Ali},
title = {Accessibility Issues in Ad-Driven Web Applications},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00171},
doi = {10.1109/ICSE55347.2025.00171},
abstract = {Website accessibility is essential for inclusiveness and regulatory compliance. Although third-party advertisements (ads) are a vital revenue source for free web services, they introduce significant accessibility challenges. Leasing a website's space to ad-serving technologies, like DoubleClick, results in developers losing control over ad content accessibility. Even on highly accessible websites, third-party ads can undermine adherence to Web Content Accessibility Guidelines (WCAG). We conduct the first-of-its-kind large-scale investigation of 430K website elements, including nearly 100K ad elements, to understand the accessibility of ads on websites. We seek to understand the prevalence of inaccessible ads and their overall impact on the accessibility of websites. Our findings show that 67% of websites experience increased accessibility violations due to ads, with common violations including Focus Visible (WCAG 2.4.7) and On Input (WCAG 3.2.2). Popular ad-serving technologies like Taboola, DoubleClick, and RevContent often serve ads that fail to comply with WCAG standards. Even when ads are WCAG compliant, 27% of them have alternative text in ad images that misrepresents information, potentially deceiving users. Manual inspection of a sample of these misleading ads revealed that user-identifiable data is collected on 94% of websites through interactions, such as hovering. Since users with disabilities often rely on tools like screen readers that require hover events to access website content, they have no choice but to compromise their privacy to navigate website ads. Based on our findings, we further dissect the root cause of these violations and provide design guidelines to both website developers and ad-serving technologies to achieve WCAG-compliant ad integration.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2393–2405},
numpages = {13},
keywords = {accessibility, web, ads, privacy, web development},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00142,
author = {Akinotcho, Faridah and Wei, Lili and Rubin, Julia},
title = {Mobile Application Coverage: The 30% Curse and Ways Forward},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00142},
doi = {10.1109/ICSE55347.2025.00142},
abstract = {Testing, security analysis, and other dynamic quality assurance approaches rely on mechanisms that invoke the software under test, aiming to achieve high code coverage. A large number of invocation mechanisms proposed in the literature, in particular for Android mobile applications, employ GUI-driven application exploration. However, studies show that even the most advanced GUI exploration techniques can cover only around 30% of a real-world application. This paper aims to investigate "the remaining 70%". By conducting a large-scale experiment involving two human experts, who thoroughly explored 61 benchmark and 42 popular apps from Google Play, we show that achieving a substantially larger coverage for real-world applications is impractical even if we factor out known GUI-based exploration issues, such as the inability to provide semantic inputs and the right order of events. The main reasons preventing even human analysts from covering the entire application include application dependencies on remote servers and external resources, hard-to-reach app entry points, disabled and erroneous features, and software/hardware properties of the underlying device. Thus, future investment in GUI-based exploration strategies is unlikely to lead to substantial improvements in coverage. To chart possible ways forward and explore approaches to satisfy/bypass these "blockers", we thoroughly analyze code-level properties guarding them. Our analysis shows that a large fraction of the blockers could actually be successfully bypassed with relatively simple beyond-GUI exploration techniques. We hope our study can inspire future work in this area; it also provides a realistic benchmark for evaluating such work.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2751–2763},
numpages = {13},
keywords = {testing, mobile applications, empirical studies},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00095,
author = {Lee, Jaehyeok and Cha, Sooyoung},
title = {TopSeed: Learning Seed Selection Strategies for Symbolic Execution from Scratch},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00095},
doi = {10.1109/ICSE55347.2025.00095},
abstract = {We present TopSeed, a new approach that automatically selects optimal seeds to enhance symbolic execution. Recently, the performance of symbolic execution has significantly improved through various state-of-the-art techniques, including search strategies and state-pruning heuristics. However, these techniques have typically demonstrated their effectiveness without considering "seeding", which efficiently initializes program states for exploration. This paper aims to select valuable seeds from candidate inputs generated during interactions with any symbolic execution technique, without the need for a predefined seed corpus, thereby maximizing the technique's effectiveness. One major challenge is the vast number of candidates, making it difficult to identify promising seeds. To address this, we introduce a customized online learning algorithm that iteratively groups candidate inputs, ranks each group, and selects a seed from the top-ranked group based on data accumulated during symbolic execution. Experimental results on 17 open-source C programs show that TopSeed significantly enhances four distinct cutting-edge techniques, implemented on top of two symbolic executors, in terms of branch coverage and bug-finding abilities.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1604–1615},
numpages = {12},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00089,
author = {Yang, Aidan Z. H. and Kolak, Sophia and Hellendoorn, Vincent and Martins, Ruben and Goues, Claire Le},
title = {Revisiting Unnaturalness for Automated Program Repair in the Era of Large Language Models},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00089},
doi = {10.1109/ICSE55347.2025.00089},
abstract = {The problem of software quality has motivated the development of a variety of techniques for Automatic Program Repair (APR). Meanwhile, recent advances in AI and Large Language Models (LLMs) have produced orders of magnitude performance improvements over previous code generation techniques, affording promising opportunities for program repair and its constituent subproblems (e.g., fault localization, patch generation). Because models are trained on large volumes of code in which defects are relatively rare, they tend to both simultaneously perceive faulty code as unlikely (or "unnatural") and to produce generally correct code (which is more "natural"). This paper comprehensively revisits the idea of (un)naturalness for program repair. We argue that, fundamentally, LLMs can only go so far on their own in reasoning about and fixing buggy code. This motivates the incorporation of traditional tools, which compress useful contextual and analysis information, as a complement to LLMs for repair. We interrogate the role of entropy at every stage of traditional repair, and show that it is indeed usefully complementary to classic techniques. We show that combining measures of naturalness with class Spectrum-Based Fault Localization (SBFL) approaches improves Top-5 scoring by 50% over SBFL alone. We show that entropy delta, or change in entropy induced by a candidate patch, can improve patch generation efficiency by 24 test suite executions per repair, on average, on our dataset. Finally, we show compelling results that entropy delta for patch classification is highly effective at distinguishing correct from overfitting patches. Overall, our results suggest that LLMs can effectively complement classic techniques for analysis and transformation, producing more efficient and effective automated repair techniques overall.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2561–2573},
numpages = {13},
keywords = {program repair, deep learning, large language models},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00083,
author = {Zhang, Mengya and Shukla, Preksha and Zhang, Wuqi and Zhang, Zhuo and Agrawal, Pranav and Lin, Zhiqiang and Zhang, Xiangyu and Zhang, Xiaokuan},
title = {An Empirical Study of Proxy Contracts at the Ethereum Ecosystem Scale},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00083},
doi = {10.1109/ICSE55347.2025.00083},
abstract = {The proxy design pattern separates data and code in smart contracts into proxy and logic contracts. Data resides in proxy contracts, while code is sourced from logic contracts. This pattern allows for flexible smart contract development, enabling upgradeability, extensibility, and code reuse. Despite its popularity and importance, there is currently no systematic study to understand the prevalence, use scenarios, and development pitfalls of proxies. We present the first comprehensive study on Ethereum proxies. To gather a dataset of proxies, we introduce ProxyEX, the first framework to detect proxies from bytecode, achieving over 99% accuracy. Using ProxyEX, we collected a dataset of 2,031,422 Ethereum proxies and conducted the first large-scale empirical study. We analyzed proxy numbers and transaction traffic to understand their current status on Ethereum. We identified four proxy use patterns: upgradeability, extensibility, code-sharing, and code-hiding. We also pinpointed three common issues: proxy-logic storage collision, logic-logic storage collision, and uninitialized contracts, creating checkers for these by replaying historical transactions. Our study reveals that upgradeability isn't the sole reason for proxy adoption in DApps, and many proxies present issues like storage collisions and uninitialized contracts, which enhances the understanding of proxies and guide future smart contract research on the development, usage, quality assurance, and bug detection of proxies.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2996–3008},
numpages = {13},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00072,
author = {Zhong, Chenxing and Feitosa, Daniel and Avgeriou, Paris and Huang, Huang and Li, Yue and Zhang, He},
title = {PairSmell: A Novel Perspective Inspecting Software Modular Structure},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00072},
doi = {10.1109/ICSE55347.2025.00072},
abstract = {Enhancing the modular structure of existing systems has attracted substantial research interest, focusing on two main methods: (1) software modularization and (2) identifying design issues (e.g., smells) as refactoring opportunities. However, re-modularization solutions often require extensive modifications to the original modules, and the design issues identified are generally too coarse to guide refactoring strategies. Combining the above two methods, this paper introduces a novel concept, PairSmell, which exploits modularization to pinpoint design issues necessitating refactoring. We concentrate on a granular but fundamental aspect of modularity principles—modular relation (MR), i.e., whether a pair of entities are separated or collocated. The main assumption is that, if the actual MR of a pair violates its 'apt MR', i.e., an MR agreed on by multiple modularization tools (as raters), it can be deemed likely a flawed architectural decision that necessitates further examination.To quantify and evaluate PairSmell, we conduct an empirical study on 20 C/C++ and Java projects, using 4 established modularization tools to identify two forms of PairSmell: inapt separated pairs InSep and inapt collocated pairs InCol. Our study on 260,003 instances reveals that their architectural impacts are substantial: (1) on average, 14.60% and 20.44% of software entities are involved in InSep and InCol MRs respectively; (2) InSep pairs are associated with 190% more co-changes than properly separated pairs, while InCol pairs are associated with 35% fewer co-changes than properly collocated pairs, both indicating a successful identification of modular structures detrimental to software quality; and (3) both forms of PairSmell persist across software evolution. This evidence strongly suggests that PairSmell can provide meaningful insights for inspecting modular structure, with the identified issues being both granular and fundamental, making the enhancement of modular design more efficient.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {2163–2175},
numpages = {13},
keywords = {modular structure, architectural smell, architecture analysis},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

@inproceedings{10.1109/ICSE55347.2025.00018,
author = {Lee, Seongmin and Minocha, Shreyas and B\"{o}hme, Marcel},
title = {Accounting for Missing Events in Statistical Information Leakage Analysis},
year = {2025},
isbn = {9798331505691},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE55347.2025.00018},
doi = {10.1109/ICSE55347.2025.00018},
abstract = {The leakage of secret information via a public channel is a critical privacy flaw in software systems. The more information is leaked per observation, the less time an attacker needs to learn the secret. Due to the size and complexity of the modern software, and because some empirical facts are not available for a formal analysis of the source code, researchers started investigating statistical methods using program executions as samples. However, current statistical methods require a high sample coverage. Ideally, the sample is large enough to contain every possible combination of secret \texttimes{} observable value to accurately reflect the joint distribution of ⟨secret, observable⟩. Otherwise, the information leakage is severely underestimated, which is problematic as it can lead to overconfidence in the security of an otherwise vulnerable program.In this paper, we introduce an improved estimator for information leakage and propose to use methods from applied statistics to improve our estimate of the joint distribution when sample coverage is low. The key idea is to reconstruct the joint distribution by casting our problem as a multinomial estimation problem in the absence of samples for all classes. We suggest two approaches and demonstrate the effectiveness of each approach on a set of benchmark subjects. We also propose novel refinement heuristics, which help to adjust the joint distribution and gain better estimation accuracy. Compared to existing statistical methods for information leakage estimation, our method can safely overestimate the mutual information and provide a more accurate estimate from a limited number of program executions.},
booktitle = {Proceedings of the IEEE/ACM 47th International Conference on Software Engineering},
pages = {1256–1267},
numpages = {12},
keywords = {information leakage, mutual information, statistical estimation},
location = {Ottawa, Ontario, Canada},
series = {ICSE '25}
}

